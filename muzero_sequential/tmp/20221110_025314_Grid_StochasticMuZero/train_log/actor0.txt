{"date": "2022/11/10 02:53:17", "episode_count": 0, "remote_memory": 40, "train_count": 0, "episode_step": 40.0, "episode_time": 2.9074459075927734, "eval_reward0": 0.7200000062584877, "episode_reward0": -2.559999965131283, "step_time": 0.07249436378479004, "train_time": 2.9623508453369142e-06, "work0_v_min": Infinity, "work0_v_max": -Infinity}
{"date": "2022/11/10 02:53:19", "episode_count": 1, "remote_memory": 57, "train_count": 0, "episode_step": 17.0, "episode_time": 1.1996657848358154, "eval_reward0": -1.119999997317791, "episode_reward0": 0.36000001430511475, "step_time": 0.0701447514926686, "train_time": 3.001269172219669e-06, "work0_v_min": -1.0, "work0_v_max": 0.025000000838190317}
{"date": "2022/11/10 02:53:21", "episode_count": 2, "remote_memory": 88, "train_count": 0, "episode_step": 31.0, "episode_time": 2.2014927864074707, "eval_reward0": -1.239999994635582, "episode_reward0": -2.19999997317791, "step_time": 0.0707806617982926, "train_time": 3.0994415283203125e-06, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:26", "episode_count": 3, "remote_memory": 134, "train_count": 0, "episode_step": 46.0, "episode_time": 3.29017972946167, "eval_reward0": -1.2799999937415123, "episode_reward0": -0.7999999597668648, "step_time": 0.07119309902191162, "train_time": 6.6187070763629414e-06, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:27", "episode_count": 4, "remote_memory": 147, "train_count": 0, "episode_step": 13.0, "episode_time": 0.9264764785766602, "eval_reward0": -1.1999999955296516, "episode_reward0": -1.479999989271164, "step_time": 0.07098190601055439, "train_time": 5.135169396033654e-06, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:28", "episode_count": 5, "remote_memory": 154, "train_count": 0, "episode_step": 7.0, "episode_time": 0.5027132034301758, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.239999994635582, "step_time": 0.07131099700927734, "train_time": 6.335122244698661e-06, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:31", "episode_count": 6, "remote_memory": 191, "train_count": 0, "episode_step": 37.0, "episode_time": 2.6152892112731934, "eval_reward0": 0.640000008046627, "episode_reward0": -2.439999967813492, "step_time": 0.0703844250859441, "train_time": 4.90369023503484e-06, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:36", "episode_count": 7, "remote_memory": 242, "train_count": 1, "episode_step": 51.0, "episode_time": 3.7612104415893555, "eval_reward0": 0.4400000125169754, "episode_reward0": -2.0399999544024467, "step_time": 0.070296703600416, "train_time": 0.0031814154456643495, "train_loss": 11.00560474395752, "train_v_loss": 3.2070748805999756, "train_policy_loss": 2.7728734016418457, "train_reward_loss": 1.7821040153503418, "train_chance_loss": 1.426820993423462, "train_q_loss": 1.6482250690460205, "train_vae_loss": 0.17064665257930756, "train_lr": 0.009999999776482582, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:38", "episode_count": 8, "remote_memory": 255, "train_count": 14, "episode_step": 13.0, "episode_time": 1.8309965133666992, "eval_reward0": -1.239999994635582, "episode_reward0": -1.479999989271164, "step_time": 0.07324805626502404, "train_time": 0.06692039049588717, "train_loss": 7.302719593048096, "train_v_loss": 2.124138355255127, "train_policy_loss": 2.7549173831939697, "train_reward_loss": 0.9409141540527344, "train_chance_loss": 0.2567935287952423, "train_q_loss": 1.095774531364441, "train_vae_loss": 0.019171293824911118, "train_lr": 0.009983898140490055, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:41", "episode_count": 9, "remote_memory": 266, "train_count": 25, "episode_step": 11.0, "episode_time": 1.503436803817749, "eval_reward0": -1.8799999803304672, "episode_reward0": -1.3999999910593033, "step_time": 0.07145380973815918, "train_time": 0.06442132863131436, "train_loss": 5.755749225616455, "train_v_loss": 1.7115299701690674, "train_policy_loss": 2.748418092727661, "train_reward_loss": 0.27611520886421204, "train_chance_loss": 0.0, "train_q_loss": 0.8868460059165955, "train_vae_loss": 0.0, "train_lr": 0.009956348687410355, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:45", "episode_count": 10, "remote_memory": 283, "train_count": 42, "episode_step": 17.0, "episode_time": 2.410336494445801, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.36000001430511475, "step_time": 0.07346428141874425, "train_time": 0.06749224662780762, "train_loss": 5.660728454589844, "train_v_loss": 1.6930603981018066, "train_policy_loss": 2.745929002761841, "train_reward_loss": 0.25691309571266174, "train_chance_loss": 0.0, "train_q_loss": 0.8399245142936707, "train_vae_loss": 0.0, "train_lr": 0.009924309328198433, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:52", "episode_count": 11, "remote_memory": 334, "train_count": 93, "episode_step": 51.0, "episode_time": 7.127939224243164, "eval_reward0": 0.6800000071525574, "episode_reward0": -2.0399999544024467, "step_time": 0.07222313506930482, "train_time": 0.06686440168642531, "train_loss": 5.633099555969238, "train_v_loss": 1.661613941192627, "train_policy_loss": 2.749614953994751, "train_reward_loss": 0.3006904125213623, "train_chance_loss": 0.0, "train_q_loss": 0.8271008729934692, "train_vae_loss": 2.2210462906780554e-13, "train_lr": 0.009846966713666916, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:53:55", "episode_count": 12, "remote_memory": 353, "train_count": 112, "episode_step": 19.0, "episode_time": 2.5191500186920166, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.2800000160932541, "step_time": 0.07072728558590538, "train_time": 0.06121450976321572, "train_loss": 5.536020278930664, "train_v_loss": 1.6521121263504028, "train_policy_loss": 2.7467355728149414, "train_reward_loss": 0.27077674865722656, "train_chance_loss": 0.0, "train_q_loss": 0.7899285554885864, "train_vae_loss": 7.80650033505026e-09, "train_lr": 0.009767880663275719, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:01", "episode_count": 13, "remote_memory": 387, "train_count": 146, "episode_step": 34.0, "episode_time": 4.641546964645386, "eval_reward0": 0.5600000098347664, "episode_reward0": -0.31999997049570084, "step_time": 0.07213504174176384, "train_time": 0.06383903587565702, "train_loss": 5.467525482177734, "train_v_loss": 1.6303960084915161, "train_policy_loss": 2.7453553676605225, "train_reward_loss": 0.23006923496723175, "train_chance_loss": 0.0, "train_q_loss": 0.7929319143295288, "train_vae_loss": 4.48526270702132e-06, "train_lr": 0.009708477184176445, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:02", "episode_count": 14, "remote_memory": 393, "train_count": 152, "episode_step": 6.0, "episode_time": 0.822035551071167, "eval_reward0": 0.640000008046627, "episode_reward0": -1.1999999955296516, "step_time": 0.0710677703221639, "train_time": 0.0652475357055664, "train_loss": 5.759154796600342, "train_v_loss": 1.8273674249649048, "train_policy_loss": 2.743455171585083, "train_reward_loss": 0.23329538106918335, "train_chance_loss": 0.0, "train_q_loss": 0.8914548754692078, "train_vae_loss": 1.113570306188194e-05, "train_lr": 0.009663847275078297, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:04", "episode_count": 15, "remote_memory": 400, "train_count": 159, "episode_step": 7.0, "episode_time": 0.9645333290100098, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.760000005364418, "step_time": 0.07251034464154925, "train_time": 0.06465605327061244, "train_loss": 5.7957234382629395, "train_v_loss": 1.8420969247817993, "train_policy_loss": 2.750060796737671, "train_reward_loss": 0.2562004327774048, "train_chance_loss": 0.0, "train_q_loss": 0.8840979933738708, "train_vae_loss": 1.0896663297899067e-05, "train_lr": 0.009649394080042839, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:11", "episode_count": 16, "remote_memory": 443, "train_count": 202, "episode_step": 43.0, "episode_time": 5.99432897567749, "eval_reward0": -1.4399999901652336, "episode_reward0": -0.6799999624490738, "step_time": 0.0730066133099933, "train_time": 0.06567125542219295, "train_loss": 5.632996082305908, "train_v_loss": 1.7216132879257202, "train_policy_loss": 2.742544174194336, "train_reward_loss": 0.2777571976184845, "train_chance_loss": 0.0, "train_q_loss": 0.8297989368438721, "train_vae_loss": 1.381232596031623e-05, "train_lr": 0.009594045579433441, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:15", "episode_count": 17, "remote_memory": 469, "train_count": 228, "episode_step": 26.0, "episode_time": 3.534268856048584, "eval_reward0": -1.239999994635582, "episode_reward0": 2.2351741790771484e-08, "step_time": 0.07151941152719352, "train_time": 0.06377675900092492, "train_loss": 5.58888578414917, "train_v_loss": 1.7090071439743042, "train_policy_loss": 2.7417256832122803, "train_reward_loss": 0.248622864484787, "train_chance_loss": 0.0, "train_q_loss": 0.8308003544807434, "train_vae_loss": 1.576472641318105e-05, "train_lr": 0.009518108330667019, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:19", "episode_count": 18, "remote_memory": 498, "train_count": 257, "episode_step": 29.0, "episode_time": 4.002862215042114, "eval_reward0": 0.6800000071525574, "episode_reward0": -0.1199999749660492, "step_time": 0.07232583802321861, "train_time": 0.06508807478279903, "train_loss": 5.522013187408447, "train_v_loss": 1.6841014623641968, "train_policy_loss": 2.7390902042388916, "train_reward_loss": 0.22286197543144226, "train_chance_loss": 0.0, "train_q_loss": 0.81915283203125, "train_vae_loss": 1.6086240066215396e-05, "train_lr": 0.009458033367991447, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:27", "episode_count": 19, "remote_memory": 549, "train_count": 308, "episode_step": 51.0, "episode_time": 7.00684118270874, "eval_reward0": 0.4400000125169754, "episode_reward0": -2.0399999544024467, "step_time": 0.07239368850109625, "train_time": 0.06435968361648858, "train_loss": 5.526474475860596, "train_v_loss": 1.6836416721343994, "train_policy_loss": 2.740381956100464, "train_reward_loss": 0.22412510216236115, "train_chance_loss": 8.633917047973227e-08, "train_q_loss": 0.8262921571731567, "train_vae_loss": 1.5628078472218476e-05, "train_lr": 0.009371357969939709, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:30", "episode_count": 20, "remote_memory": 561, "train_count": 320, "episode_step": 12.0, "episode_time": 1.636289358139038, "eval_reward0": 0.5200000107288361, "episode_reward0": -1.4399999901652336, "step_time": 0.07212136189142863, "train_time": 0.06352853775024414, "train_loss": 5.4765801429748535, "train_v_loss": 1.67295503616333, "train_policy_loss": 2.7422990798950195, "train_reward_loss": 0.20313720405101776, "train_chance_loss": 6.208817904251873e-10, "train_q_loss": 0.8053678870201111, "train_vae_loss": 1.4996468053141143e-05, "train_lr": 0.009303580969572067, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:35", "episode_count": 21, "remote_memory": 589, "train_count": 348, "episode_step": 28.0, "episode_time": 3.774458408355713, "eval_reward0": 0.48000001162290573, "episode_reward0": -2.079999975860119, "step_time": 0.07168652330126081, "train_time": 0.0625179580279759, "train_loss": 5.5950703620910645, "train_v_loss": 1.7401448488235474, "train_policy_loss": 2.7415473461151123, "train_reward_loss": 0.22335295379161835, "train_chance_loss": 6.386213780018579e-09, "train_q_loss": 0.8368247151374817, "train_vae_loss": 1.4546819329552818e-05, "train_lr": 0.00926084816455841, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:39", "episode_count": 22, "remote_memory": 618, "train_count": 377, "episode_step": 29.0, "episode_time": 3.99700665473938, "eval_reward0": 0.6800000071525574, "episode_reward0": -0.1199999749660492, "step_time": 0.07263101380446861, "train_time": 0.06458483071162782, "train_loss": 5.467048168182373, "train_v_loss": 1.6594505310058594, "train_policy_loss": 2.7365167140960693, "train_reward_loss": 0.21231162548065186, "train_chance_loss": 2.0347836482415005e-07, "train_q_loss": 0.8058920502662659, "train_vae_loss": 1.3892430615669582e-05, "train_lr": 0.00920027494430542, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:45", "episode_count": 23, "remote_memory": 651, "train_count": 410, "episode_step": 33.0, "episode_time": 4.677920818328857, "eval_reward0": 0.640000008046627, "episode_reward0": -2.2799999713897705, "step_time": 0.07271953062577681, "train_time": 0.06837367288994067, "train_loss": 5.462886333465576, "train_v_loss": 1.648572325706482, "train_policy_loss": 2.7390546798706055, "train_reward_loss": 0.21101057529449463, "train_chance_loss": 1.121203354159661e-06, "train_q_loss": 0.8124237656593323, "train_vae_loss": 1.3188708180678077e-05, "train_lr": 0.00913484301418066, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:47", "episode_count": 24, "remote_memory": 667, "train_count": 426, "episode_step": 16.0, "episode_time": 2.1586577892303467, "eval_reward0": 0.760000005364418, "episode_reward0": -1.599999986588955, "step_time": 0.07207874953746796, "train_time": 0.06230038404464722, "train_loss": 5.454960823059082, "train_v_loss": 1.6246435642242432, "train_policy_loss": 2.741381883621216, "train_reward_loss": 0.23542794585227966, "train_chance_loss": 3.30619656097042e-08, "train_q_loss": 0.8037119507789612, "train_vae_loss": 1.264508409803966e-05, "train_lr": 0.009083437733352184, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:52", "episode_count": 25, "remote_memory": 698, "train_count": 457, "episode_step": 31.0, "episode_time": 4.232837915420532, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.19999997317790985, "step_time": 0.07207540542848649, "train_time": 0.06388638865563177, "train_loss": 5.437600135803223, "train_v_loss": 1.6343646049499512, "train_policy_loss": 2.733823299407959, "train_reward_loss": 0.2225915491580963, "train_chance_loss": 3.605120202365697e-09, "train_q_loss": 0.7996501326560974, "train_vae_loss": 1.2145644177508075e-05, "train_lr": 0.009034433402121067, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:54", "episode_count": 26, "remote_memory": 708, "train_count": 467, "episode_step": 10.0, "episode_time": 1.3900737762451172, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.359999991953373, "step_time": 0.07247109413146972, "train_time": 0.06565806865692139, "train_loss": 5.456360816955566, "train_v_loss": 1.6583070755004883, "train_policy_loss": 2.739356279373169, "train_reward_loss": 0.19251926243305206, "train_chance_loss": 2.0861644145497849e-07, "train_q_loss": 0.8203692436218262, "train_vae_loss": 1.172637530544307e-05, "train_lr": 0.00899187196046114, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:54:59", "episode_count": 27, "remote_memory": 737, "train_count": 496, "episode_step": 29.0, "episode_time": 3.9935190677642822, "eval_reward0": -1.6399999856948853, "episode_reward0": -2.119999974966049, "step_time": 0.07210855648435395, "train_time": 0.06493682696901519, "train_loss": 5.461155414581299, "train_v_loss": 1.6539727449417114, "train_policy_loss": 2.7351231575012207, "train_reward_loss": 0.2173881232738495, "train_chance_loss": 1.0893270996348292e-07, "train_q_loss": 0.8099930286407471, "train_vae_loss": 1.1349990018061362e-05, "train_lr": 0.008951603434979916, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:01", "episode_count": 28, "remote_memory": 748, "train_count": 507, "episode_step": 11.0, "episode_time": 1.5238370895385742, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.6000000089406967, "step_time": 0.07198719544844194, "train_time": 0.06572426449168813, "train_loss": 5.4331865310668945, "train_v_loss": 1.6211535930633545, "train_policy_loss": 2.7301535606384277, "train_reward_loss": 0.22204595804214478, "train_chance_loss": 5.689535953479208e-08, "train_q_loss": 0.8143641948699951, "train_vae_loss": 1.0980284969264176e-05, "train_lr": 0.008910460397601128, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:03", "episode_count": 29, "remote_memory": 757, "train_count": 516, "episode_step": 9.0, "episode_time": 1.1980657577514648, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.3199999928474426, "step_time": 0.071201933754815, "train_time": 0.061407380633884005, "train_loss": 5.400367736816406, "train_v_loss": 1.6156535148620605, "train_policy_loss": 2.731779098510742, "train_reward_loss": 0.2254467010498047, "train_chance_loss": 1.158979401338911e-08, "train_q_loss": 0.7816316485404968, "train_vae_loss": 1.0805451893247664e-05, "train_lr": 0.008889964781701565, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:06", "episode_count": 30, "remote_memory": 778, "train_count": 537, "episode_step": 21.0, "episode_time": 2.8333449363708496, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.20000001788139343, "step_time": 0.07160095941452753, "train_time": 0.0627134641011556, "train_loss": 5.401490211486816, "train_v_loss": 1.5923826694488525, "train_policy_loss": 2.740139961242676, "train_reward_loss": 0.24580790102481842, "train_chance_loss": 1.0998478572332715e-08, "train_q_loss": 0.7779968976974487, "train_vae_loss": 1.0552247658779379e-05, "train_lr": 0.008859321475028992, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:10", "episode_count": 31, "remote_memory": 801, "train_count": 560, "episode_step": 23.0, "episode_time": 3.1490814685821533, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.8799999803304672, "step_time": 0.07211384565933891, "train_time": 0.06418930965921153, "train_loss": 5.4305830001831055, "train_v_loss": 1.626509428024292, "train_policy_loss": 2.7374727725982666, "train_reward_loss": 0.23316818475723267, "train_chance_loss": 1.2342069055648608e-07, "train_q_loss": 0.7871405482292175, "train_vae_loss": 1.0201627446804196e-05, "train_lr": 0.008814559318125248, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:12", "episode_count": 32, "remote_memory": 810, "train_count": 569, "episode_step": 9.0, "episode_time": 1.2790892124176025, "eval_reward0": 0.3200000151991844, "episode_reward0": -1.3199999928474426, "step_time": 0.07207587030198839, "train_time": 0.06904859013027614, "train_loss": 5.531983375549316, "train_v_loss": 1.728499174118042, "train_policy_loss": 2.7345242500305176, "train_reward_loss": 0.1900964379310608, "train_chance_loss": 4.4455288161771023e-07, "train_q_loss": 0.8319699764251709, "train_vae_loss": 9.961053365259431e-06, "train_lr": 0.00878213532269001, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:18", "episode_count": 33, "remote_memory": 843, "train_count": 602, "episode_step": 33.0, "episode_time": 4.44902777671814, "eval_reward0": 0.6800000071525574, "episode_reward0": -0.2799999713897705, "step_time": 0.07155010916969994, "train_time": 0.06262024966153232, "train_loss": 5.4938530921936035, "train_v_loss": 1.673056721687317, "train_policy_loss": 2.7285521030426025, "train_reward_loss": 0.23120175302028656, "train_chance_loss": 4.901605734630721e-07, "train_q_loss": 0.8146653771400452, "train_vae_loss": 9.667664926382713e-06, "train_lr": 0.008739790879189968, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:19", "episode_count": 34, "remote_memory": 850, "train_count": 609, "episode_step": 7.0, "episode_time": 0.934086799621582, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.239999994635582, "step_time": 0.0711897441319057, "train_time": 0.061580044882638116, "train_loss": 5.5173258781433105, "train_v_loss": 1.7180263996124268, "train_policy_loss": 2.7248356342315674, "train_reward_loss": 0.19677650928497314, "train_chance_loss": 9.387788963977073e-07, "train_q_loss": 0.8331159353256226, "train_vae_loss": 9.402245268574916e-06, "train_lr": 0.008699615485966206, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:22", "episode_count": 35, "remote_memory": 867, "train_count": 626, "episode_step": 17.0, "episode_time": 2.33219313621521, "eval_reward0": -1.4399999901652336, "episode_reward0": -1.6399999856948853, "step_time": 0.0715932846069336, "train_time": 0.06479705081266515, "train_loss": 5.471673011779785, "train_v_loss": 1.630200982093811, "train_policy_loss": 2.732374429702759, "train_reward_loss": 0.2567305564880371, "train_chance_loss": 9.628823818275123e-07, "train_q_loss": 0.8090653419494629, "train_vae_loss": 9.253904863726348e-06, "train_lr": 0.00867561437189579, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:25", "episode_count": 36, "remote_memory": 876, "train_count": 635, "episode_step": 9.0, "episode_time": 1.2288079261779785, "eval_reward0": 0.3200000151991844, "episode_reward0": 0.6800000071525574, "step_time": 0.07214000489976671, "train_time": 0.06381773948669434, "train_loss": 5.384190559387207, "train_v_loss": 1.605055332183838, "train_policy_loss": 2.7407519817352295, "train_reward_loss": 0.21324266493320465, "train_chance_loss": 5.265095524009666e-07, "train_q_loss": 0.782108724117279, "train_vae_loss": 9.097739166463725e-06, "train_lr": 0.008649680763483047, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:30", "episode_count": 37, "remote_memory": 885, "train_count": 644, "episode_step": 9.0, "episode_time": 1.2568392753601074, "eval_reward0": -2.0399999544024467, "episode_reward0": 0.6800000071525574, "step_time": 0.07262863053215875, "train_time": 0.06609278255038792, "train_loss": 5.377697467803955, "train_v_loss": 1.6256052255630493, "train_policy_loss": 2.7347192764282227, "train_reward_loss": 0.18797296285629272, "train_chance_loss": 1.2078287454642123e-06, "train_q_loss": 0.7864706516265869, "train_vae_loss": 8.994046766019892e-06, "train_lr": 0.008631774224340916, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:33", "episode_count": 38, "remote_memory": 902, "train_count": 661, "episode_step": 17.0, "episode_time": 2.365969657897949, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.36000001430511475, "step_time": 0.07220000379225787, "train_time": 0.06610821275150075, "train_loss": 5.446877956390381, "train_v_loss": 1.6544981002807617, "train_policy_loss": 2.7342777252197266, "train_reward_loss": 0.20385420322418213, "train_chance_loss": 4.533971605269471e-06, "train_q_loss": 0.8118146657943726, "train_vae_loss": 8.849549885781016e-06, "train_lr": 0.00860597938299179, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:37", "episode_count": 39, "remote_memory": 928, "train_count": 687, "episode_step": 26.0, "episode_time": 3.601748466491699, "eval_reward0": 0.8000000044703484, "episode_reward0": 2.2351741790771484e-08, "step_time": 0.07266758038447453, "train_time": 0.06528780093559852, "train_loss": 5.430470943450928, "train_v_loss": 1.6248304843902588, "train_policy_loss": 2.726417303085327, "train_reward_loss": 0.24377594888210297, "train_chance_loss": 8.169890293174831e-07, "train_q_loss": 0.7932065725326538, "train_vae_loss": 8.623721441836096e-06, "train_lr": 0.008563486859202385, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:42", "episode_count": 40, "remote_memory": 959, "train_count": 718, "episode_step": 31.0, "episode_time": 4.403781414031982, "eval_reward0": 0.6800000071525574, "episode_reward0": -0.19999997317790985, "step_time": 0.07224738213323778, "train_time": 0.06917948107565602, "train_loss": 5.489408016204834, "train_v_loss": 1.6720035076141357, "train_policy_loss": 2.730456590652466, "train_reward_loss": 0.220172718167305, "train_chance_loss": 8.207690029848891e-07, "train_q_loss": 0.8249732851982117, "train_vae_loss": 8.345904461748432e-06, "train_lr": 0.008507480844855309, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:44", "episode_count": 41, "remote_memory": 970, "train_count": 729, "episode_step": 11.0, "episode_time": 1.4800572395324707, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.6000000089406967, "step_time": 0.0716492696241899, "train_time": 0.062178308313543144, "train_loss": 5.39842414855957, "train_v_loss": 1.6299091577529907, "train_policy_loss": 2.7147152423858643, "train_reward_loss": 0.23524221777915955, "train_chance_loss": 7.145802101149457e-07, "train_q_loss": 0.7773452997207642, "train_vae_loss": 8.154936040227767e-06, "train_lr": 0.008466426283121109, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:47", "episode_count": 42, "remote_memory": 989, "train_count": 748, "episode_step": 19.0, "episode_time": 2.6058077812194824, "eval_reward0": 0.760000005364418, "episode_reward0": 0.2800000160932541, "step_time": 0.07230419861642938, "train_time": 0.06416382287677966, "train_loss": 5.543050765991211, "train_v_loss": 1.6953433752059937, "train_policy_loss": 2.725038766860962, "train_reward_loss": 0.23278339207172394, "train_chance_loss": 1.0987723726429977e-06, "train_q_loss": 0.8486482501029968, "train_vae_loss": 8.02627437224146e-06, "train_lr": 0.00843723863363266, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:53", "episode_count": 43, "remote_memory": 1027, "train_count": 786, "episode_step": 38.0, "episode_time": 5.131634712219238, "eval_reward0": 0.36000001430511475, "episode_reward0": -0.47999996691942215, "step_time": 0.0716067113374409, "train_time": 0.06283632077668842, "train_loss": 5.470569133758545, "train_v_loss": 1.660083293914795, "train_policy_loss": 2.721083402633667, "train_reward_loss": 0.2391120046377182, "train_chance_loss": 1.0795553180287243e-06, "train_q_loss": 0.8089008331298828, "train_vae_loss": 7.796908903401345e-06, "train_lr": 0.008382071740925312, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:56", "episode_count": 44, "remote_memory": 1036, "train_count": 795, "episode_step": 9.0, "episode_time": 1.2569224834442139, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.6800000071525574, "step_time": 0.07295605871412489, "train_time": 0.06568397416008843, "train_loss": 5.603439807891846, "train_v_loss": 1.7517077922821045, "train_policy_loss": 2.7305550575256348, "train_reward_loss": 0.22457759082317352, "train_chance_loss": 5.420029538072413e-06, "train_q_loss": 0.853851318359375, "train_vae_loss": 7.6187984632269945e-06, "train_lr": 0.008336814120411873, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:55:59", "episode_count": 45, "remote_memory": 1056, "train_count": 815, "episode_step": 20.0, "episode_time": 2.730271577835083, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.24000001698732376, "step_time": 0.07207589149475098, "train_time": 0.06379492282867431, "train_loss": 5.437012672424316, "train_v_loss": 1.6641089916229248, "train_policy_loss": 2.7207984924316406, "train_reward_loss": 0.20108875632286072, "train_chance_loss": 3.063013309656526e-06, "train_q_loss": 0.8083987236022949, "train_vae_loss": 7.515119705203688e-06, "train_lr": 0.008309030905365944, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:00", "episode_count": 46, "remote_memory": 1066, "train_count": 825, "episode_step": 10.0, "episode_time": 1.3839528560638428, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.640000008046627, "step_time": 0.07215509414672852, "train_time": 0.06574404239654541, "train_loss": 5.513908386230469, "train_v_loss": 1.7114967107772827, "train_policy_loss": 2.7251365184783936, "train_reward_loss": 0.21106524765491486, "train_chance_loss": 3.5912376006308477e-06, "train_q_loss": 0.8240720629692078, "train_vae_loss": 7.411383649014169e-06, "train_lr": 0.00828037690371275, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:05", "episode_count": 47, "remote_memory": 1086, "train_count": 845, "episode_step": 20.0, "episode_time": 2.8029048442840576, "eval_reward0": 2.2351741790771484e-08, "episode_reward0": 0.24000001698732376, "step_time": 0.0727103590965271, "train_time": 0.06675843000411988, "train_loss": 5.488329887390137, "train_v_loss": 1.670792579650879, "train_policy_loss": 2.7182936668395996, "train_reward_loss": 0.24275004863739014, "train_chance_loss": 1.2104075722163543e-05, "train_q_loss": 0.8152621984481812, "train_vae_loss": 7.311904482776299e-06, "train_lr": 0.00825183279812336, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:13", "episode_count": 48, "remote_memory": 1137, "train_count": 896, "episode_step": 51.0, "episode_time": 6.974927186965942, "eval_reward0": 0.7200000062584877, "episode_reward0": -2.0399999544024467, "step_time": 0.07210609492133646, "train_time": 0.06405469483020258, "train_loss": 5.479763031005859, "train_v_loss": 1.6807258129119873, "train_policy_loss": 2.722590208053589, "train_reward_loss": 0.21858114004135132, "train_chance_loss": 1.289764441025909e-05, "train_q_loss": 0.816076397895813, "train_vae_loss": 7.090915005392162e-06, "train_lr": 0.008184694685041904, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:15", "episode_count": 49, "remote_memory": 1153, "train_count": 912, "episode_step": 16.0, "episode_time": 2.2166788578033447, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.07237651944160461, "train_time": 0.06560096144676208, "train_loss": 5.441701889038086, "train_v_loss": 1.660245656967163, "train_policy_loss": 2.716080665588379, "train_reward_loss": 0.21509037911891937, "train_chance_loss": 3.0268001438571446e-08, "train_q_loss": 0.8082623481750488, "train_vae_loss": 6.895671958773164e-06, "train_lr": 0.008121761493384838, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:21", "episode_count": 50, "remote_memory": 1191, "train_count": 950, "episode_step": 38.0, "episode_time": 5.182067155838013, "eval_reward0": 0.8000000044703484, "episode_reward0": -0.47999996691942215, "step_time": 0.07191272785789088, "train_time": 0.06389161160117701, "train_loss": 5.454824447631836, "train_v_loss": 1.6710697412490845, "train_policy_loss": 2.7168192863464355, "train_reward_loss": 0.20673240721225739, "train_chance_loss": 2.4744065285631223e-06, "train_q_loss": 0.8201357126235962, "train_vae_loss": 6.749980002496159e-06, "train_lr": 0.008071445859968662, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:22", "episode_count": 51, "remote_memory": 1196, "train_count": 955, "episode_step": 5.0, "episode_time": 0.7001123428344727, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8400000035762787, "step_time": 0.07334160804748535, "train_time": 0.06584763526916504, "train_loss": 5.568270206451416, "train_v_loss": 1.7635958194732666, "train_policy_loss": 2.720247507095337, "train_reward_loss": 0.18884578347206116, "train_chance_loss": 9.715639635032858e-07, "train_q_loss": 0.8560150265693665, "train_vae_loss": 6.638777904299786e-06, "train_lr": 0.008031561970710754, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:24", "episode_count": 52, "remote_memory": 1203, "train_count": 962, "episode_step": 7.0, "episode_time": 0.9530010223388672, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.760000005364418, "step_time": 0.07159427234104701, "train_time": 0.06394219398498535, "train_loss": 5.45900297164917, "train_v_loss": 1.6773931980133057, "train_policy_loss": 2.716308116912842, "train_reward_loss": 0.2060491293668747, "train_chance_loss": 6.103275609348202e-06, "train_q_loss": 0.8198379874229431, "train_vae_loss": 6.608502644667169e-06, "train_lr": 0.008020474575459957, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:27", "episode_count": 53, "remote_memory": 1223, "train_count": 982, "episode_step": 20.0, "episode_time": 2.7382326126098633, "eval_reward0": 0.640000008046627, "episode_reward0": 0.24000001698732376, "step_time": 0.07228653430938721, "train_time": 0.06394754648208618, "train_loss": 5.519580841064453, "train_v_loss": 1.7050940990447998, "train_policy_loss": 2.7201972007751465, "train_reward_loss": 0.22675089538097382, "train_chance_loss": 1.2409269402269274e-05, "train_q_loss": 0.8275415301322937, "train_vae_loss": 6.542360551975435e-06, "train_lr": 0.007995586842298508, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:29", "episode_count": 54, "remote_memory": 1231, "train_count": 990, "episode_step": 8.0, "episode_time": 1.1182146072387695, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.7200000062584877, "step_time": 0.0733228325843811, "train_time": 0.06585302948951721, "train_loss": 5.451406478881836, "train_v_loss": 1.6601996421813965, "train_policy_loss": 2.7195286750793457, "train_reward_loss": 0.2227400243282318, "train_chance_loss": 9.617084288038313e-06, "train_q_loss": 0.8078221082687378, "train_vae_loss": 6.475323061749805e-06, "train_lr": 0.007969848811626434, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:32", "episode_count": 55, "remote_memory": 1250, "train_count": 1009, "episode_step": 19.0, "episode_time": 2.747002601623535, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.2800000160932541, "step_time": 0.07278463715001156, "train_time": 0.07107601667705335, "train_loss": 5.4017534255981445, "train_v_loss": 1.6392079591751099, "train_policy_loss": 2.716440200805664, "train_reward_loss": 0.20915256440639496, "train_chance_loss": 7.128790912247496e-06, "train_q_loss": 0.7958385348320007, "train_vae_loss": 6.412424227164593e-06, "train_lr": 0.00794511754065752, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:34", "episode_count": 56, "remote_memory": 1263, "train_count": 1022, "episode_step": 13.0, "episode_time": 1.7798216342926025, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.5200000107288361, "step_time": 0.07259356058560885, "train_time": 0.0636139466212346, "train_loss": 5.458761215209961, "train_v_loss": 1.6566828489303589, "train_policy_loss": 2.717944860458374, "train_reward_loss": 0.23481933772563934, "train_chance_loss": 2.0964935174561106e-06, "train_q_loss": 0.8086195588111877, "train_vae_loss": 6.3398842939932365e-06, "train_lr": 0.00791589729487896, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:37", "episode_count": 57, "remote_memory": 1275, "train_count": 1034, "episode_step": 12.0, "episode_time": 1.6554327011108398, "eval_reward0": 0.48000001162290573, "episode_reward0": 0.5600000098347664, "step_time": 0.0716659426689148, "train_time": 0.06551220019658406, "train_loss": 5.524814128875732, "train_v_loss": 1.708433747291565, "train_policy_loss": 2.7229321002960205, "train_reward_loss": 0.22715604305267334, "train_chance_loss": 1.0092170668940526e-05, "train_q_loss": 0.82663494348526, "train_vae_loss": 6.284639312070794e-06, "train_lr": 0.007893146015703678, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:40", "episode_count": 58, "remote_memory": 1286, "train_count": 1045, "episode_step": 11.0, "episode_time": 1.5193665027618408, "eval_reward0": 0.20000001788139343, "episode_reward0": 0.6000000089406967, "step_time": 0.07269083369861949, "train_time": 0.0646209716796875, "train_loss": 5.435086727142334, "train_v_loss": 1.6654763221740723, "train_policy_loss": 2.7090423107147217, "train_reward_loss": 0.22570005059242249, "train_chance_loss": 7.965540135046467e-06, "train_q_loss": 0.7948880791664124, "train_vae_loss": 6.234934971871553e-06, "train_lr": 0.007872272282838821, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:43", "episode_count": 59, "remote_memory": 1300, "train_count": 1059, "episode_step": 14.0, "episode_time": 1.914642333984375, "eval_reward0": 0.760000005364418, "episode_reward0": 0.48000001162290573, "step_time": 0.07225550924028669, "train_time": 0.0638714177267892, "train_loss": 5.382420539855957, "train_v_loss": 1.6490579843521118, "train_policy_loss": 2.695478677749634, "train_reward_loss": 0.19347520172595978, "train_chance_loss": 4.877559604210546e-06, "train_q_loss": 0.804008424282074, "train_vae_loss": 6.1820546761737205e-06, "train_lr": 0.007849647663533688, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:44", "episode_count": 60, "remote_memory": 1307, "train_count": 1066, "episode_step": 7.0, "episode_time": 0.9855496883392334, "eval_reward0": 0.760000005364418, "episode_reward0": -1.239999994635582, "step_time": 0.07278473036629814, "train_time": 0.06730014937264579, "train_loss": 5.621459484100342, "train_v_loss": 1.7849342823028564, "train_policy_loss": 2.6945528984069824, "train_reward_loss": 0.22011305391788483, "train_chance_loss": 6.468283572758082e-06, "train_q_loss": 0.8821021914482117, "train_vae_loss": 6.138376193121076e-06, "train_lr": 0.00783069059252739, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:48", "episode_count": 61, "remote_memory": 1323, "train_count": 1082, "episode_step": 16.0, "episode_time": 2.176415205001831, "eval_reward0": 0.20000001788139343, "episode_reward0": 0.4000000134110451, "step_time": 0.07149296998977661, "train_time": 0.06390900909900665, "train_loss": 5.517668724060059, "train_v_loss": 1.7138400077819824, "train_policy_loss": 2.709451675415039, "train_reward_loss": 0.2135864794254303, "train_chance_loss": 6.974813004489988e-06, "train_q_loss": 0.8414801955223083, "train_vae_loss": 6.0917545852134936e-06, "train_lr": 0.007809985429048538, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:53", "episode_count": 62, "remote_memory": 1356, "train_count": 1115, "episode_step": 33.0, "episode_time": 4.573625326156616, "eval_reward0": 0.5200000107288361, "episode_reward0": -0.2799999713897705, "step_time": 0.07275264913385565, "train_time": 0.0651875553709088, "train_loss": 5.480370044708252, "train_v_loss": 1.691705346107483, "train_policy_loss": 2.711000919342041, "train_reward_loss": 0.21120300889015198, "train_chance_loss": 5.950013928668341e-06, "train_q_loss": 0.8282951712608337, "train_vae_loss": 5.995180345053086e-06, "train_lr": 0.007766065187752247, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:56:58", "episode_count": 63, "remote_memory": 1384, "train_count": 1143, "episode_step": 28.0, "episode_time": 3.764775037765503, "eval_reward0": 0.6800000071525574, "episode_reward0": -0.07999997586011887, "step_time": 0.07114866801670619, "train_time": 0.06271907261439733, "train_loss": 5.3604278564453125, "train_v_loss": 1.6286096572875977, "train_policy_loss": 2.7011561393737793, "train_reward_loss": 0.20653793215751648, "train_chance_loss": 9.770376891538035e-06, "train_q_loss": 0.78743976354599, "train_vae_loss": 5.8799255384656135e-06, "train_lr": 0.007711711805313826, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:00", "episode_count": 64, "remote_memory": 1398, "train_count": 1157, "episode_step": 14.0, "episode_time": 1.938455581665039, "eval_reward0": 0.640000008046627, "episode_reward0": 0.48000001162290573, "step_time": 0.0725151811327253, "train_time": 0.06526735850742885, "train_loss": 5.297123908996582, "train_v_loss": 1.6022495031356812, "train_policy_loss": 2.702624559402466, "train_reward_loss": 0.183040052652359, "train_chance_loss": 8.753542715567164e-06, "train_q_loss": 0.7727797627449036, "train_vae_loss": 5.8036280279338825e-06, "train_lr": 0.007674501743167639, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:03", "episode_count": 65, "remote_memory": 1408, "train_count": 1167, "episode_step": 10.0, "episode_time": 1.382615327835083, "eval_reward0": -1.1999999955296516, "episode_reward0": -1.359999991953373, "step_time": 0.07199962139129638, "train_time": 0.06541309356689454, "train_loss": 5.511970520019531, "train_v_loss": 1.723533272743225, "train_policy_loss": 2.702695369720459, "train_reward_loss": 0.2255413830280304, "train_chance_loss": 2.2844858904136345e-05, "train_q_loss": 0.8242524862289429, "train_vae_loss": 5.761268312198808e-06, "train_lr": 0.007653324399143457, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:06", "episode_count": 66, "remote_memory": 1433, "train_count": 1192, "episode_step": 25.0, "episode_time": 3.4169540405273438, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.9599999785423279, "step_time": 0.07173225402832031, "train_time": 0.0644040584564209, "train_loss": 5.49053955078125, "train_v_loss": 1.7003309726715088, "train_policy_loss": 2.7162795066833496, "train_reward_loss": 0.21496239304542542, "train_chance_loss": 2.6561790946288966e-05, "train_q_loss": 0.823758065700531, "train_vae_loss": 5.700829206034541e-06, "train_lr": 0.007622555363923311, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:10", "episode_count": 67, "remote_memory": 1455, "train_count": 1214, "episode_step": 22.0, "episode_time": 2.9965367317199707, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.1600000187754631, "step_time": 0.0717361948706887, "train_time": 0.06388012929396196, "train_loss": 5.39009952545166, "train_v_loss": 1.6574863195419312, "train_policy_loss": 2.709620475769043, "train_reward_loss": 0.18616312742233276, "train_chance_loss": 5.626652182399994e-06, "train_q_loss": 0.8010389804840088, "train_vae_loss": 5.6219987527583726e-06, "train_lr": 0.007581418380141258, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:14", "episode_count": 68, "remote_memory": 1482, "train_count": 1241, "episode_step": 27.0, "episode_time": 3.8095052242279053, "eval_reward0": 0.8000000044703484, "episode_reward0": -2.0399999767541885, "step_time": 0.07362809004607024, "train_time": 0.06671272383795844, "train_loss": 5.431521892547607, "train_v_loss": 1.6554375886917114, "train_policy_loss": 2.7123453617095947, "train_reward_loss": 0.20160941779613495, "train_chance_loss": 9.889933608064894e-06, "train_q_loss": 0.8270172476768494, "train_vae_loss": 5.542687176784966e-06, "train_lr": 0.00753877405077219, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:18", "episode_count": 69, "remote_memory": 1503, "train_count": 1262, "episode_step": 21.0, "episode_time": 2.8912055492401123, "eval_reward0": 0.12000001966953278, "episode_reward0": 0.20000001788139343, "step_time": 0.07281961895170666, "train_time": 0.06423595973423549, "train_loss": 5.458806037902832, "train_v_loss": 1.694144606590271, "train_policy_loss": 2.6956088542938232, "train_reward_loss": 0.20597605407238007, "train_chance_loss": 1.3938200936536305e-05, "train_q_loss": 0.8281570672988892, "train_vae_loss": 5.467478331411257e-06, "train_lr": 0.007497222628444433, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:21", "episode_count": 70, "remote_memory": 1517, "train_count": 1276, "episode_step": 14.0, "episode_time": 1.9072327613830566, "eval_reward0": 0.640000008046627, "episode_reward0": -1.5199999883770943, "step_time": 0.07183342320578438, "train_time": 0.06380447319575719, "train_loss": 5.474255084991455, "train_v_loss": 1.6940972805023193, "train_policy_loss": 2.7192139625549316, "train_reward_loss": 0.21558548510074615, "train_chance_loss": 6.575080624315888e-05, "train_q_loss": 0.8106988072395325, "train_vae_loss": 5.414196948549943e-06, "train_lr": 0.007467069663107395, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:26", "episode_count": 71, "remote_memory": 1548, "train_count": 1307, "episode_step": 31.0, "episode_time": 4.493152379989624, "eval_reward0": 0.760000005364418, "episode_reward0": -0.19999997317790985, "step_time": 0.07275955907760127, "train_time": 0.0715908081300797, "train_loss": 5.460416793823242, "train_v_loss": 1.7058066129684448, "train_policy_loss": 2.7032299041748047, "train_reward_loss": 0.20668663084506989, "train_chance_loss": 2.017613223870285e-05, "train_q_loss": 0.8103497624397278, "train_vae_loss": 5.347662408894394e-06, "train_lr": 0.007428495679050684, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:29", "episode_count": 72, "remote_memory": 1569, "train_count": 1328, "episode_step": 21.0, "episode_time": 2.9112887382507324, "eval_reward0": 0.760000005364418, "episode_reward0": -1.7999999821186066, "step_time": 0.07354006313142322, "train_time": 0.06446297963460286, "train_loss": 5.43162202835083, "train_v_loss": 1.6739126443862915, "train_policy_loss": 2.7062973976135254, "train_reward_loss": 0.20902758836746216, "train_chance_loss": 4.73081036034273e-06, "train_q_loss": 0.8076207041740417, "train_vae_loss": 5.272952876111958e-06, "train_lr": 0.007384147495031357, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:32", "episode_count": 73, "remote_memory": 1579, "train_count": 1338, "episode_step": 10.0, "episode_time": 1.3871023654937744, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.359999991953373, "step_time": 0.0728196382522583, "train_time": 0.06504459381103515, "train_loss": 5.306854248046875, "train_v_loss": 1.612833023071289, "train_policy_loss": 2.715191125869751, "train_reward_loss": 0.18808268010616302, "train_chance_loss": 4.252831331541529e-06, "train_q_loss": 0.7557678818702698, "train_vae_loss": 5.229559519648319e-06, "train_lr": 0.00735783576965332, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:34", "episode_count": 74, "remote_memory": 1595, "train_count": 1354, "episode_step": 16.0, "episode_time": 2.259875535964966, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.07251709699630737, "train_time": 0.06812453269958496, "train_loss": 5.648684024810791, "train_v_loss": 1.7873866558074951, "train_policy_loss": 2.708530902862549, "train_reward_loss": 0.23881399631500244, "train_chance_loss": 1.9456831068964675e-05, "train_q_loss": 0.8793272376060486, "train_vae_loss": 5.1938668548245914e-06, "train_lr": 0.0073358467780053616, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:36", "episode_count": 75, "remote_memory": 1606, "train_count": 1365, "episode_step": 11.0, "episode_time": 1.5178520679473877, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.6000000089406967, "step_time": 0.072668964212591, "train_time": 0.06447978453202681, "train_loss": 5.504223346710205, "train_v_loss": 1.678078055381775, "train_policy_loss": 2.711479663848877, "train_reward_loss": 0.24175353348255157, "train_chance_loss": 8.705291293154005e-06, "train_q_loss": 0.8378061056137085, "train_vae_loss": 5.157458872417919e-06, "train_lr": 0.007313076872378588, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:38", "episode_count": 76, "remote_memory": 1617, "train_count": 1376, "episode_step": 11.0, "episode_time": 1.5473556518554688, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07338482683355158, "train_time": 0.06644571911204945, "train_loss": 5.4661712646484375, "train_v_loss": 1.6927177906036377, "train_policy_loss": 2.701974630355835, "train_reward_loss": 0.21179825067520142, "train_chance_loss": 4.750166681333212e-06, "train_q_loss": 0.8241495490074158, "train_vae_loss": 5.128108568897005e-06, "train_lr": 0.007294577080756426, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:43", "episode_count": 77, "remote_memory": 1639, "train_count": 1398, "episode_step": 22.0, "episode_time": 3.034454345703125, "eval_reward0": 0.1600000187754631, "episode_reward0": -1.839999981224537, "step_time": 0.07213614203713158, "train_time": 0.06518583947961981, "train_loss": 5.544527053833008, "train_v_loss": 1.752003788948059, "train_policy_loss": 2.6962363719940186, "train_reward_loss": 0.19715386629104614, "train_chance_loss": 3.8520058296853676e-05, "train_q_loss": 0.8635978698730469, "train_vae_loss": 5.085021257400513e-06, "train_lr": 0.0072669219225645065, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:49", "episode_count": 78, "remote_memory": 1687, "train_count": 1446, "episode_step": 48.0, "episode_time": 6.4731128215789795, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.8799999579787254, "step_time": 0.0714853157599767, "train_time": 0.06281746923923492, "train_loss": 5.545244216918945, "train_v_loss": 1.7499340772628784, "train_policy_loss": 2.7080886363983154, "train_reward_loss": 0.20449143648147583, "train_chance_loss": 1.669640369073022e-05, "train_q_loss": 0.8487610220909119, "train_vae_loss": 4.9964000936597586e-06, "train_lr": 0.007208621129393578, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:52", "episode_count": 79, "remote_memory": 1699, "train_count": 1458, "episode_step": 12.0, "episode_time": 1.6478955745697021, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.5600000098347664, "step_time": 0.07262237866719563, "train_time": 0.06398894389470418, "train_loss": 5.483278751373291, "train_v_loss": 1.7193876504898071, "train_policy_loss": 2.7075204849243164, "train_reward_loss": 0.18860763311386108, "train_chance_loss": 1.3723030861001462e-05, "train_q_loss": 0.8347058296203613, "train_vae_loss": 4.922791504213819e-06, "train_lr": 0.00715896300971508, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:55", "episode_count": 80, "remote_memory": 1717, "train_count": 1476, "episode_step": 18.0, "episode_time": 2.4688923358917236, "eval_reward0": -1.1999999955296516, "episode_reward0": 0.3200000151991844, "step_time": 0.0725387069914076, "train_time": 0.06390343772040473, "train_loss": 5.396659851074219, "train_v_loss": 1.6687604188919067, "train_policy_loss": 2.6918554306030273, "train_reward_loss": 0.20014765858650208, "train_chance_loss": 1.2292005521885585e-05, "train_q_loss": 0.8029067516326904, "train_vae_loss": 4.887085651716916e-06, "train_lr": 0.00713428296148777, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:56", "episode_count": 81, "remote_memory": 1723, "train_count": 1482, "episode_step": 6.0, "episode_time": 0.8394191265106201, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.8000000044703484, "step_time": 0.07322430610656738, "train_time": 0.06587636470794678, "train_loss": 5.366552352905273, "train_v_loss": 1.6386321783065796, "train_policy_loss": 2.687819480895996, "train_reward_loss": 0.2056524008512497, "train_chance_loss": 6.12817484579864e-06, "train_q_loss": 0.8007693886756897, "train_vae_loss": 4.858886768488446e-06, "train_lr": 0.00711459293961525, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:57:58", "episode_count": 82, "remote_memory": 1730, "train_count": 1489, "episode_step": 7.0, "episode_time": 1.0651822090148926, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.239999994635582, "step_time": 0.07298639842442103, "train_time": 0.07851672172546387, "train_loss": 5.563807487487793, "train_v_loss": 1.7447530031204224, "train_policy_loss": 2.6985771656036377, "train_reward_loss": 0.24916884303092957, "train_chance_loss": 5.3527778618445154e-06, "train_q_loss": 0.8375569581985474, "train_vae_loss": 4.843751867156243e-06, "train_lr": 0.0071039521135389805, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:00", "episode_count": 83, "remote_memory": 1735, "train_count": 1494, "episode_step": 5.0, "episode_time": 0.6792750358581543, "eval_reward0": 2.2351741790771484e-08, "episode_reward0": 0.8400000035762787, "step_time": 0.07156734466552735, "train_time": 0.06329555511474609, "train_loss": 5.59214448928833, "train_v_loss": 1.771480917930603, "train_policy_loss": 2.694830894470215, "train_reward_loss": 0.2317064255475998, "train_chance_loss": 8.858932233124506e-06, "train_q_loss": 0.8607015609741211, "train_vae_loss": 4.829872978007188e-06, "train_lr": 0.007094144821166992, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:02", "episode_count": 84, "remote_memory": 1746, "train_count": 1505, "episode_step": 11.0, "episode_time": 1.5122272968292236, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07206301255659624, "train_time": 0.06458258628845215, "train_loss": 5.525504112243652, "train_v_loss": 1.7418521642684937, "train_policy_loss": 2.69478178024292, "train_reward_loss": 0.20862837135791779, "train_chance_loss": 1.0847702469618525e-05, "train_q_loss": 0.8467385768890381, "train_vae_loss": 4.811587587028043e-06, "train_lr": 0.00708109000697732, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:05", "episode_count": 85, "remote_memory": 1761, "train_count": 1520, "episode_step": 15.0, "episode_time": 2.074523687362671, "eval_reward0": 0.760000005364418, "episode_reward0": 0.4400000125169754, "step_time": 0.07413447697957357, "train_time": 0.06357433001200358, "train_loss": 5.445790767669678, "train_v_loss": 1.6661747694015503, "train_policy_loss": 2.710576295852661, "train_reward_loss": 0.2266951948404312, "train_chance_loss": 1.5305569831980392e-05, "train_q_loss": 0.808829665184021, "train_vae_loss": 4.782162704941584e-06, "train_lr": 0.007059928495436907, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:10", "episode_count": 86, "remote_memory": 1793, "train_count": 1552, "episode_step": 32.0, "episode_time": 4.351137399673462, "eval_reward0": 0.6800000071525574, "episode_reward0": -0.23999997228384018, "step_time": 0.07216064631938934, "train_time": 0.06326181441545486, "train_loss": 5.398064136505127, "train_v_loss": 1.6472017765045166, "train_policy_loss": 2.697887420654297, "train_reward_loss": 0.21008095145225525, "train_chance_loss": 7.897264367784373e-06, "train_q_loss": 0.8094357252120972, "train_vae_loss": 4.730021373688942e-06, "train_lr": 0.007021840661764145, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:14", "episode_count": 87, "remote_memory": 1798, "train_count": 1557, "episode_step": 5.0, "episode_time": 0.7173423767089844, "eval_reward0": -2.9199999570846558, "episode_reward0": 0.8400000035762787, "step_time": 0.07505784034729004, "train_time": 0.06750779151916504, "train_loss": 5.266806125640869, "train_v_loss": 1.5326989889144897, "train_policy_loss": 2.6833035945892334, "train_reward_loss": 0.2584002614021301, "train_chance_loss": 2.9180508136050776e-05, "train_q_loss": 0.7593337297439575, "train_vae_loss": 4.6897534957679454e-06, "train_lr": 0.006991977337747812, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:16", "episode_count": 88, "remote_memory": 1805, "train_count": 1564, "episode_step": 7.0, "episode_time": 0.9536740779876709, "eval_reward0": 0.760000005364418, "episode_reward0": 0.760000005364418, "step_time": 0.07256415912083217, "train_time": 0.06307448659624372, "train_loss": 5.485524654388428, "train_v_loss": 1.6735180616378784, "train_policy_loss": 2.7115931510925293, "train_reward_loss": 0.24252918362617493, "train_chance_loss": 4.03805825044401e-05, "train_q_loss": 0.8250131607055664, "train_vae_loss": 4.676813659898471e-06, "train_lr": 0.006982324179261923, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:18", "episode_count": 89, "remote_memory": 1813, "train_count": 1572, "episode_step": 8.0, "episode_time": 1.1381006240844727, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.7200000062584877, "step_time": 0.07389131188392639, "train_time": 0.06734892725944519, "train_loss": 5.351214408874512, "train_v_loss": 1.6091800928115845, "train_policy_loss": 2.681971788406372, "train_reward_loss": 0.24776944518089294, "train_chance_loss": 1.5580575563944876e-05, "train_q_loss": 0.7794000506401062, "train_vae_loss": 4.6608706725237425e-06, "train_lr": 0.006970277056097984, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:25", "episode_count": 90, "remote_memory": 1864, "train_count": 1623, "episode_step": 51.0, "episode_time": 7.2813146114349365, "eval_reward0": 0.760000005364418, "episode_reward0": -0.9999999552965164, "step_time": 0.07295801125320733, "train_time": 0.06919668235030829, "train_loss": 5.492592811584473, "train_v_loss": 1.7211250066757202, "train_policy_loss": 2.696610450744629, "train_reward_loss": 0.21368150413036346, "train_chance_loss": 8.544499905838165e-06, "train_q_loss": 0.8284686803817749, "train_vae_loss": 4.5993610910954885e-06, "train_lr": 0.00692312978208065, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:26", "episode_count": 91, "remote_memory": 1871, "train_count": 1630, "episode_step": 7.0, "episode_time": 0.9753096103668213, "eval_reward0": 0.760000005364418, "episode_reward0": 0.760000005364418, "step_time": 0.07408973148890904, "train_time": 0.06456882613045829, "train_loss": 5.394994258880615, "train_v_loss": 1.6679352521896362, "train_policy_loss": 2.7019083499908447, "train_reward_loss": 0.1718086451292038, "train_chance_loss": 4.1904463614628185e-06, "train_q_loss": 0.8204383254051208, "train_vae_loss": 4.540245299722301e-06, "train_lr": 0.0068770162761211395, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:31", "episode_count": 92, "remote_memory": 1896, "train_count": 1655, "episode_step": 25.0, "episode_time": 3.6186962127685547, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.04000002145767212, "step_time": 0.0733119773864746, "train_time": 0.07072893142700196, "train_loss": 5.506373405456543, "train_v_loss": 1.7424885034561157, "train_policy_loss": 2.707566499710083, "train_reward_loss": 0.1940811723470688, "train_chance_loss": 4.8769015847938135e-06, "train_q_loss": 0.8296298980712891, "train_vae_loss": 4.5084725570632145e-06, "train_lr": 0.006851735524833202, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:33", "episode_count": 93, "remote_memory": 1911, "train_count": 1670, "episode_step": 15.0, "episode_time": 2.0342836380004883, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.5599999874830246, "step_time": 0.07197863260904948, "train_time": 0.06289024353027343, "train_loss": 5.508342266082764, "train_v_loss": 1.7212120294570923, "train_policy_loss": 2.6919376850128174, "train_reward_loss": 0.2303805947303772, "train_chance_loss": 1.1212397112103645e-05, "train_q_loss": 0.8328260183334351, "train_vae_loss": 4.469361556402873e-06, "train_lr": 0.006820248905569315, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:36", "episode_count": 94, "remote_memory": 1932, "train_count": 1691, "episode_step": 21.0, "episode_time": 2.9390511512756348, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.20000001788139343, "step_time": 0.07412293979099818, "train_time": 0.06513857841491699, "train_loss": 5.54533052444458, "train_v_loss": 1.744012713432312, "train_policy_loss": 2.6892762184143066, "train_reward_loss": 0.22362439334392548, "train_chance_loss": 1.7642436432652175e-05, "train_q_loss": 0.8571513891220093, "train_vae_loss": 4.434853053680854e-06, "train_lr": 0.006792042870074511, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:38", "episode_count": 95, "remote_memory": 1941, "train_count": 1700, "episode_step": 9.0, "episode_time": 1.2266690731048584, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6800000071525574, "step_time": 0.07196206516689724, "train_time": 0.06341926256815593, "train_loss": 5.508850574493408, "train_v_loss": 1.7624688148498535, "train_policy_loss": 2.6709349155426025, "train_reward_loss": 0.20190539956092834, "train_chance_loss": 6.399352969310712e-06, "train_q_loss": 0.8422059416770935, "train_vae_loss": 4.406494554132223e-06, "train_lr": 0.006768619176000357, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:42", "episode_count": 96, "remote_memory": 1966, "train_count": 1725, "episode_step": 25.0, "episode_time": 3.4732675552368164, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.04000002145767212, "step_time": 0.07326793670654297, "train_time": 0.0651081657409668, "train_loss": 5.481557846069336, "train_v_loss": 1.7067886590957642, "train_policy_loss": 2.69036865234375, "train_reward_loss": 0.22601374983787537, "train_chance_loss": 1.7786112948670052e-05, "train_q_loss": 0.8271048069000244, "train_vae_loss": 4.374871423351578e-06, "train_lr": 0.006742183584719896, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:44", "episode_count": 97, "remote_memory": 1976, "train_count": 1735, "episode_step": 10.0, "episode_time": 1.371769905090332, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.640000008046627, "step_time": 0.07339005470275879, "train_time": 0.06289277076721192, "train_loss": 5.38009786605835, "train_v_loss": 1.662500023841858, "train_policy_loss": 2.6945722103118896, "train_reward_loss": 0.19753727316856384, "train_chance_loss": 8.876041647454258e-06, "train_q_loss": 0.7941700220108032, "train_vae_loss": 4.34277944805217e-06, "train_lr": 0.006715063005685806, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:46", "episode_count": 98, "remote_memory": 1985, "train_count": 1744, "episode_step": 9.0, "episode_time": 1.2126686573028564, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6800000071525574, "step_time": 0.07192383872138129, "train_time": 0.06190901332431369, "train_loss": 5.496058940887451, "train_v_loss": 1.6503024101257324, "train_policy_loss": 2.6983554363250732, "train_reward_loss": 0.28922784328460693, "train_chance_loss": 1.0512109838600736e-05, "train_q_loss": 0.8270730972290039, "train_vae_loss": 4.3255859054625034e-06, "train_lr": 0.006700390018522739, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:50", "episode_count": 99, "remote_memory": 2010, "train_count": 1769, "episode_step": 25.0, "episode_time": 3.435075521469116, "eval_reward0": 0.640000008046627, "episode_reward0": 0.04000002145767212, "step_time": 0.07265273094177246, "train_time": 0.064199800491333, "train_loss": 5.414783477783203, "train_v_loss": 1.6498926877975464, "train_policy_loss": 2.680105209350586, "train_reward_loss": 0.25872907042503357, "train_chance_loss": 1.5580466424580663e-05, "train_q_loss": 0.7944378852844238, "train_vae_loss": 4.295196958992165e-06, "train_lr": 0.006674221251159906, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:58", "episode_count": 100, "remote_memory": 2061, "train_count": 1820, "episode_step": 51.0, "episode_time": 7.0417702198028564, "eval_reward0": 0.6000000089406967, "episode_reward0": -2.0399999544024467, "step_time": 0.07260997155133415, "train_time": 0.06485282206067852, "train_loss": 5.463826656341553, "train_v_loss": 1.7073025703430176, "train_policy_loss": 2.6849427223205566, "train_reward_loss": 0.21263296902179718, "train_chance_loss": 3.0138851798255928e-05, "train_q_loss": 0.8269834518432617, "train_vae_loss": 4.228986654197797e-06, "train_lr": 0.0066161067225039005, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:58:59", "episode_count": 101, "remote_memory": 2069, "train_count": 1828, "episode_step": 8.0, "episode_time": 1.069016933441162, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.7200000062584877, "step_time": 0.07196405529975891, "train_time": 0.061106324195861816, "train_loss": 5.432000160217285, "train_v_loss": 1.7017841339111328, "train_policy_loss": 2.680842161178589, "train_reward_loss": 0.1805289387702942, "train_chance_loss": 4.6484921767842025e-05, "train_q_loss": 0.8377953767776489, "train_vae_loss": 4.178808012511581e-06, "train_lr": 0.006571281235665083, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:01", "episode_count": 102, "remote_memory": 2075, "train_count": 1834, "episode_step": 6.0, "episode_time": 0.8224775791168213, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07253917058308919, "train_time": 0.06384686628977458, "train_loss": 5.488845348358154, "train_v_loss": 1.7351268529891968, "train_policy_loss": 2.6937296390533447, "train_reward_loss": 0.1860109120607376, "train_chance_loss": 3.092569750151597e-05, "train_q_loss": 0.8430004119873047, "train_vae_loss": 4.167110546404729e-06, "train_lr": 0.006560697685927153, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:03", "episode_count": 103, "remote_memory": 2086, "train_count": 1845, "episode_step": 11.0, "episode_time": 1.5352144241333008, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.6000000089406967, "step_time": 0.0735918175090443, "train_time": 0.06519113887440074, "train_loss": 5.42503547668457, "train_v_loss": 1.697808027267456, "train_policy_loss": 2.6775476932525635, "train_reward_loss": 0.1908016800880432, "train_chance_loss": 2.6446574338478968e-05, "train_q_loss": 0.8278687000274658, "train_vae_loss": 4.153022473474266e-06, "train_lr": 0.006547871045768261, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:08", "episode_count": 104, "remote_memory": 2111, "train_count": 1870, "episode_step": 25.0, "episode_time": 3.479902982711792, "eval_reward0": 0.24000001698732376, "episode_reward0": 0.04000002145767212, "step_time": 0.07296457290649414, "train_time": 0.06551423072814941, "train_loss": 5.383963108062744, "train_v_loss": 1.6567039489746094, "train_policy_loss": 2.686073064804077, "train_reward_loss": 0.1991889923810959, "train_chance_loss": 3.344220749568194e-05, "train_q_loss": 0.8110421895980835, "train_vae_loss": 4.123547114431858e-06, "train_lr": 0.00652079563587904, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:11", "episode_count": 105, "remote_memory": 2130, "train_count": 1889, "episode_step": 19.0, "episode_time": 2.6750495433807373, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.2800000160932541, "step_time": 0.07473577951130114, "train_time": 0.06526009660018117, "train_loss": 5.460043907165527, "train_v_loss": 1.7197097539901733, "train_policy_loss": 2.680194139480591, "train_reward_loss": 0.2025083303451538, "train_chance_loss": 1.4103861758485436e-05, "train_q_loss": 0.8266218900680542, "train_vae_loss": 4.088043169758748e-06, "train_lr": 0.006487843114882708, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:17", "episode_count": 106, "remote_memory": 2169, "train_count": 1928, "episode_step": 39.0, "episode_time": 5.476244926452637, "eval_reward0": 0.6000000089406967, "episode_reward0": -0.5199999660253525, "step_time": 0.07294670129433656, "train_time": 0.066894347851093, "train_loss": 5.433027267456055, "train_v_loss": 1.6923235654830933, "train_policy_loss": 2.6871402263641357, "train_reward_loss": 0.21760307252407074, "train_chance_loss": 1.725704532873351e-05, "train_q_loss": 0.8050694465637207, "train_vae_loss": 4.042287400807254e-06, "train_lr": 0.006444680970162153, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:19", "episode_count": 107, "remote_memory": 2180, "train_count": 1939, "episode_step": 11.0, "episode_time": 1.523510217666626, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.3999999910593033, "step_time": 0.07251867381009189, "train_time": 0.06515409729697487, "train_loss": 5.326704025268555, "train_v_loss": 1.5772018432617188, "train_policy_loss": 2.6837542057037354, "train_reward_loss": 0.24035850167274475, "train_chance_loss": 1.1927971172553953e-05, "train_q_loss": 0.7941770553588867, "train_vae_loss": 4.003581580036553e-06, "train_lr": 0.006407670211046934, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:24", "episode_count": 108, "remote_memory": 2205, "train_count": 1964, "episode_step": 25.0, "episode_time": 3.4698593616485596, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.04000002145767212, "step_time": 0.07311342239379882, "train_time": 0.06497165679931641, "train_loss": 5.467777252197266, "train_v_loss": 1.7048629522323608, "train_policy_loss": 2.6801156997680664, "train_reward_loss": 0.2204611450433731, "train_chance_loss": 2.9186026949901134e-05, "train_q_loss": 0.8318355083465576, "train_vae_loss": 3.976245352532715e-06, "train_lr": 0.006381174549460411, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:26", "episode_count": 109, "remote_memory": 2216, "train_count": 1975, "episode_step": 11.0, "episode_time": 1.5286176204681396, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07347254319624467, "train_time": 0.0647023157639937, "train_loss": 5.512949466705322, "train_v_loss": 1.7176254987716675, "train_policy_loss": 2.6656112670898438, "train_reward_loss": 0.24087749421596527, "train_chance_loss": 3.915501292794943e-05, "train_q_loss": 0.8577911853790283, "train_vae_loss": 3.949272468162235e-06, "train_lr": 0.006354774348437786, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:27", "episode_count": 110, "remote_memory": 2222, "train_count": 1981, "episode_step": 6.0, "episode_time": 0.8614556789398193, "eval_reward0": 0.640000008046627, "episode_reward0": 0.8000000044703484, "step_time": 0.07499237855275472, "train_time": 0.06782805919647217, "train_loss": 5.532682418823242, "train_v_loss": 1.7680859565734863, "train_policy_loss": 2.697293996810913, "train_reward_loss": 0.17810659110546112, "train_chance_loss": 1.9883798813680187e-05, "train_q_loss": 0.8582644462585449, "train_vae_loss": 3.936640496249311e-06, "train_lr": 0.006342347711324692, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:30", "episode_count": 111, "remote_memory": 2237, "train_count": 1996, "episode_step": 15.0, "episode_time": 2.08613657951355, "eval_reward0": 0.36000001430511475, "episode_reward0": 0.4400000125169754, "step_time": 0.07361203829447428, "train_time": 0.06487464904785156, "train_loss": 5.358931541442871, "train_v_loss": 1.6428757905960083, "train_policy_loss": 2.6927411556243896, "train_reward_loss": 0.2033843994140625, "train_chance_loss": 1.6428979506599717e-05, "train_q_loss": 0.7890417575836182, "train_vae_loss": 3.92121455661254e-06, "train_lr": 0.006327034439891577, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:35", "episode_count": 112, "remote_memory": 2263, "train_count": 2022, "episode_step": 26.0, "episode_time": 3.604367733001709, "eval_reward0": 0.6800000071525574, "episode_reward0": 2.2351741790771484e-08, "step_time": 0.0726234087577233, "train_time": 0.06531147773449238, "train_loss": 5.504323959350586, "train_v_loss": 1.7509822845458984, "train_policy_loss": 2.678844690322876, "train_reward_loss": 0.19620943069458008, "train_chance_loss": 1.0335831575503107e-05, "train_q_loss": 0.8474394083023071, "train_vae_loss": 3.891407686751336e-06, "train_lr": 0.006297246087342501, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:37", "episode_count": 113, "remote_memory": 2276, "train_count": 2035, "episode_step": 13.0, "episode_time": 1.749626636505127, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.479999989271164, "step_time": 0.07162842383751503, "train_time": 0.062300847126887396, "train_loss": 5.565059185028076, "train_v_loss": 1.7712892293930054, "train_policy_loss": 2.6728360652923584, "train_reward_loss": 0.23399224877357483, "train_chance_loss": 1.0745618965302128e-05, "train_q_loss": 0.8568524122238159, "train_vae_loss": 3.863454367092345e-06, "train_lr": 0.006269027944654226, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:39", "episode_count": 114, "remote_memory": 2286, "train_count": 2045, "episode_step": 10.0, "episode_time": 1.358255386352539, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.640000008046627, "step_time": 0.07120964527130128, "train_time": 0.06376469135284424, "train_loss": 5.4328083992004395, "train_v_loss": 1.6890398263931274, "train_policy_loss": 2.6841371059417725, "train_reward_loss": 0.20085358619689941, "train_chance_loss": 1.1173039638379123e-05, "train_q_loss": 0.8291792869567871, "train_vae_loss": 3.84717486667796e-06, "train_lr": 0.006252448074519634, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:43", "episode_count": 115, "remote_memory": 2309, "train_count": 2068, "episode_step": 23.0, "episode_time": 3.176797866821289, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.12000001966953278, "step_time": 0.07245826721191406, "train_time": 0.06506757114244544, "train_loss": 5.419137001037598, "train_v_loss": 1.6935290098190308, "train_policy_loss": 2.6738698482513428, "train_reward_loss": 0.20037148892879486, "train_chance_loss": 6.303237569227349e-06, "train_q_loss": 0.8218989372253418, "train_vae_loss": 3.824081431957893e-06, "train_lr": 0.006228744518011808, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:45", "episode_count": 116, "remote_memory": 2317, "train_count": 2076, "episode_step": 8.0, "episode_time": 1.10599946975708, "eval_reward0": 0.3200000151991844, "episode_reward0": -1.2799999937415123, "step_time": 0.0722661018371582, "train_time": 0.0653863251209259, "train_loss": 5.498894214630127, "train_v_loss": 1.74560546875, "train_policy_loss": 2.680415630340576, "train_reward_loss": 0.20977358520030975, "train_chance_loss": 1.1219759471714497e-05, "train_q_loss": 0.8335477113723755, "train_vae_loss": 3.8025596040824894e-06, "train_lr": 0.006206546910107136, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:47", "episode_count": 117, "remote_memory": 2326, "train_count": 2085, "episode_step": 9.0, "episode_time": 1.2400200366973877, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.6800000071525574, "step_time": 0.07313349511888292, "train_time": 0.0637626118130154, "train_loss": 5.378615856170654, "train_v_loss": 1.6804509162902832, "train_policy_loss": 2.665358304977417, "train_reward_loss": 0.20726805925369263, "train_chance_loss": 1.0941743312287144e-05, "train_q_loss": 0.7960918545722961, "train_vae_loss": 3.7909458114882e-06, "train_lr": 0.006194411776959896, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:49", "episode_count": 118, "remote_memory": 2336, "train_count": 2095, "episode_step": 10.0, "episode_time": 1.3291704654693604, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.640000008046627, "step_time": 0.07188911437988281, "train_time": 0.06061921119689941, "train_loss": 5.4073638916015625, "train_v_loss": 1.6962283849716187, "train_policy_loss": 2.681290864944458, "train_reward_loss": 0.1960069239139557, "train_chance_loss": 1.67187081387965e-05, "train_q_loss": 0.8043335676193237, "train_vae_loss": 3.7779834656248568e-06, "train_lr": 0.006180877331644297, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:52", "episode_count": 119, "remote_memory": 2353, "train_count": 2112, "episode_step": 17.0, "episode_time": 2.4677648544311523, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.36000001430511475, "step_time": 0.07269595651065602, "train_time": 0.07171036215389476, "train_loss": 5.447765827178955, "train_v_loss": 1.6912533044815063, "train_policy_loss": 2.6570725440979004, "train_reward_loss": 0.22041328251361847, "train_chance_loss": 2.0983510694350116e-05, "train_q_loss": 0.8495516777038574, "train_vae_loss": 3.7597371829178883e-06, "train_lr": 0.006161695811897516, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:53", "episode_count": 120, "remote_memory": 2360, "train_count": 2119, "episode_step": 7.0, "episode_time": 0.9841837882995605, "eval_reward0": 0.640000008046627, "episode_reward0": 0.760000005364418, "step_time": 0.07429102488926478, "train_time": 0.06565124647957939, "train_loss": 5.443814754486084, "train_v_loss": 1.687011480331421, "train_policy_loss": 2.661345958709717, "train_reward_loss": 0.2590979337692261, "train_chance_loss": 1.4834328794677276e-05, "train_q_loss": 0.806921660900116, "train_vae_loss": 3.7436500406329287e-06, "train_lr": 0.006144690793007612, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:56", "episode_count": 121, "remote_memory": 2371, "train_count": 2130, "episode_step": 11.0, "episode_time": 1.5128943920135498, "eval_reward0": 0.48000001162290573, "episode_reward0": -1.3999999910593033, "step_time": 0.07208631255409935, "train_time": 0.06465671279213646, "train_loss": 5.468640327453613, "train_v_loss": 1.7140910625457764, "train_policy_loss": 2.684265375137329, "train_reward_loss": 0.20509348809719086, "train_chance_loss": 2.0472614778555e-05, "train_q_loss": 0.8359888195991516, "train_vae_loss": 3.731697461262229e-06, "train_lr": 0.006131971254944801, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 02:59:59", "episode_count": 122, "remote_memory": 2387, "train_count": 2146, "episode_step": 16.0, "episode_time": 2.2357091903686523, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.07450748980045319, "train_time": 0.06442758440971375, "train_loss": 5.418749809265137, "train_v_loss": 1.6819703578948975, "train_policy_loss": 2.682676315307617, "train_reward_loss": 0.21115750074386597, "train_chance_loss": 2.6191059077973478e-05, "train_q_loss": 0.8139668107032776, "train_vae_loss": 3.7138822790439008e-06, "train_lr": 0.006112941540777683, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:03", "episode_count": 123, "remote_memory": 2412, "train_count": 2171, "episode_step": 25.0, "episode_time": 3.4813950061798096, "eval_reward0": 0.640000008046627, "episode_reward0": 0.04000002145767212, "step_time": 0.0736868667602539, "train_time": 0.06504481315612792, "train_loss": 5.3073811531066895, "train_v_loss": 1.6145347356796265, "train_policy_loss": 2.6809568405151367, "train_reward_loss": 0.19604095816612244, "train_chance_loss": 1.3598802979686297e-05, "train_q_loss": 0.7868728637695312, "train_vae_loss": 3.6872179407509975e-06, "train_lr": 0.006084159482270479, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:05", "episode_count": 124, "remote_memory": 2428, "train_count": 2187, "episode_step": 16.0, "episode_time": 2.2266130447387695, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.4000000134110451, "step_time": 0.07320764660835266, "train_time": 0.06535311043262482, "train_loss": 5.401632785797119, "train_v_loss": 1.6505438089370728, "train_policy_loss": 2.6779446601867676, "train_reward_loss": 0.2307765930891037, "train_chance_loss": 2.142439188901335e-05, "train_q_loss": 0.813654899597168, "train_vae_loss": 3.660865786514478e-06, "train_lr": 0.006055503152310848, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:10", "episode_count": 125, "remote_memory": 2454, "train_count": 2213, "episode_step": 26.0, "episode_time": 3.7842774391174316, "eval_reward0": 0.6000000089406967, "episode_reward0": 2.2351741790771484e-08, "step_time": 0.07394939202528733, "train_time": 0.07088922537290133, "train_loss": 5.565908432006836, "train_v_loss": 1.781840205192566, "train_policy_loss": 2.6825735569000244, "train_reward_loss": 0.21011056005954742, "train_chance_loss": 1.6591453459113836e-05, "train_q_loss": 0.8628820180892944, "train_vae_loss": 3.634289896581322e-06, "train_lr": 0.006026298739016056, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:13", "episode_count": 126, "remote_memory": 2468, "train_count": 2227, "episode_step": 14.0, "episode_time": 1.941716194152832, "eval_reward0": 0.3200000151991844, "episode_reward0": 0.48000001162290573, "step_time": 0.07372103418622698, "train_time": 0.06430244445800781, "train_loss": 5.447268009185791, "train_v_loss": 1.7236261367797852, "train_policy_loss": 2.657472848892212, "train_reward_loss": 0.20589123666286469, "train_chance_loss": 8.02646445663413e-06, "train_q_loss": 0.8317052125930786, "train_vae_loss": 3.609331315601594e-06, "train_lr": 0.005998604465276003, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:17", "episode_count": 127, "remote_memory": 2493, "train_count": 2252, "episode_step": 25.0, "episode_time": 3.452195405960083, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.9599999785423279, "step_time": 0.07303442955017089, "train_time": 0.06436915397644043, "train_loss": 5.426778793334961, "train_v_loss": 1.6949410438537598, "train_policy_loss": 2.679797649383545, "train_reward_loss": 0.21294553577899933, "train_chance_loss": 1.0481898243597243e-05, "train_q_loss": 0.8104643821716309, "train_vae_loss": 3.585321337595815e-06, "train_lr": 0.005971735808998346, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:20", "episode_count": 128, "remote_memory": 2510, "train_count": 2269, "episode_step": 17.0, "episode_time": 2.3465282917022705, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.6399999856948853, "step_time": 0.07331735947552849, "train_time": 0.06418383822721593, "train_loss": 5.451556205749512, "train_v_loss": 1.7148442268371582, "train_policy_loss": 2.6749074459075928, "train_reward_loss": 0.21140383183956146, "train_chance_loss": 2.2557023839908652e-05, "train_q_loss": 0.8218961954116821, "train_vae_loss": 3.5597972782852594e-06, "train_lr": 0.0059429253451526165, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:22", "episode_count": 129, "remote_memory": 2526, "train_count": 2285, "episode_step": 16.0, "episode_time": 2.2138845920562744, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.0732019692659378, "train_time": 0.06452351808547974, "train_loss": 5.512547016143799, "train_v_loss": 1.7409603595733643, "train_policy_loss": 2.6714377403259277, "train_reward_loss": 0.23315222561359406, "train_chance_loss": 2.338699960091617e-05, "train_q_loss": 0.8386906981468201, "train_vae_loss": 3.540020770742558e-06, "train_lr": 0.005920389201492071, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:28", "episode_count": 130, "remote_memory": 2562, "train_count": 2321, "episode_step": 36.0, "episode_time": 4.976414203643799, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.3999999687075615, "step_time": 0.07295960187911987, "train_time": 0.06465558873282538, "train_loss": 5.46619987487793, "train_v_loss": 1.7098407745361328, "train_policy_loss": 2.665491819381714, "train_reward_loss": 0.2282102108001709, "train_chance_loss": 2.1522950191865675e-05, "train_q_loss": 0.8348629474639893, "train_vae_loss": 3.509304406179581e-06, "train_lr": 0.005885064601898193, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:30", "episode_count": 131, "remote_memory": 2569, "train_count": 2328, "episode_step": 7.0, "episode_time": 0.957761287689209, "eval_reward0": 0.36000001430511475, "episode_reward0": 0.760000005364418, "step_time": 0.07251238822937012, "train_time": 0.06367032868521554, "train_loss": 5.345026969909668, "train_v_loss": 1.644052505493164, "train_policy_loss": 2.6746668815612793, "train_reward_loss": 0.21006546914577484, "train_chance_loss": 1.127074210671708e-05, "train_q_loss": 0.7887415885925293, "train_vae_loss": 3.4842539662349736e-06, "train_lr": 0.005855985917150974, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:33", "episode_count": 132, "remote_memory": 2585, "train_count": 2344, "episode_step": 16.0, "episode_time": 2.2233803272247314, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.07281115651130676, "train_time": 0.06559190154075623, "train_loss": 5.489520072937012, "train_v_loss": 1.7165017127990723, "train_policy_loss": 2.6696414947509766, "train_reward_loss": 0.24303552508354187, "train_chance_loss": 1.4886976714478806e-05, "train_q_loss": 0.8324223756790161, "train_vae_loss": 3.471011268629809e-06, "train_lr": 0.005840502679347992, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:35", "episode_count": 133, "remote_memory": 2599, "train_count": 2358, "episode_step": 14.0, "episode_time": 1.950786828994751, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.48000001162290573, "step_time": 0.07328454085758754, "train_time": 0.06538074357169014, "train_loss": 5.384936332702637, "train_v_loss": 1.66728937625885, "train_policy_loss": 2.65000581741333, "train_reward_loss": 0.23332515358924866, "train_chance_loss": 2.1686922991648316e-05, "train_q_loss": 0.8059278726577759, "train_vae_loss": 3.453886620263802e-06, "train_lr": 0.005820364225655794, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:39", "episode_count": 134, "remote_memory": 2617, "train_count": 2376, "episode_step": 18.0, "episode_time": 2.546224594116211, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.3200000151991844, "step_time": 0.07378155655331081, "train_time": 0.0669749445385403, "train_loss": 5.3988518714904785, "train_v_loss": 1.6830986738204956, "train_policy_loss": 2.6663827896118164, "train_reward_loss": 0.20640937983989716, "train_chance_loss": 1.532570786366705e-05, "train_q_loss": 0.8140528798103333, "train_vae_loss": 3.4357815366092836e-06, "train_lr": 0.005798962898552418, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:41", "episode_count": 135, "remote_memory": 2629, "train_count": 2388, "episode_step": 12.0, "episode_time": 1.7062788009643555, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.5600000098347664, "step_time": 0.07379420598347981, "train_time": 0.06765868266423543, "train_loss": 5.451981067657471, "train_v_loss": 1.6926201581954956, "train_policy_loss": 2.671508550643921, "train_reward_loss": 0.22475571930408478, "train_chance_loss": 1.6675943697919138e-05, "train_q_loss": 0.8343221545219421, "train_vae_loss": 3.418982259972836e-06, "train_lr": 0.005778966471552849, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:44", "episode_count": 136, "remote_memory": 2647, "train_count": 2406, "episode_step": 18.0, "episode_time": 2.458493709564209, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.3200000151991844, "step_time": 0.07250854704115126, "train_time": 0.06352864371405707, "train_loss": 5.5191874504089355, "train_v_loss": 1.7337154150009155, "train_policy_loss": 2.6713547706604004, "train_reward_loss": 0.23410876095294952, "train_chance_loss": 1.8125483620679006e-05, "train_q_loss": 0.851630687713623, "train_vae_loss": 3.4023626085399883e-06, "train_lr": 0.005759043153375387, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:46", "episode_count": 137, "remote_memory": 2657, "train_count": 2416, "episode_step": 10.0, "episode_time": 1.3978867530822754, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.359999991953373, "step_time": 0.07264325618743897, "train_time": 0.06626324653625489, "train_loss": 5.459109306335449, "train_v_loss": 1.7120214700698853, "train_policy_loss": 2.6645359992980957, "train_reward_loss": 0.22851219773292542, "train_chance_loss": 2.0985700757591985e-05, "train_q_loss": 0.8258992433547974, "train_vae_loss": 3.3869903290906223e-06, "train_lr": 0.005740504711866379, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:49", "episode_count": 138, "remote_memory": 2680, "train_count": 2439, "episode_step": 23.0, "episode_time": 3.149444103240967, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.12000001966953278, "step_time": 0.07285855127417523, "train_time": 0.06347275816875955, "train_loss": 5.405651569366455, "train_v_loss": 1.6793615818023682, "train_policy_loss": 2.6750757694244385, "train_reward_loss": 0.2116500586271286, "train_chance_loss": 1.5958734365995042e-05, "train_q_loss": 0.811729907989502, "train_vae_loss": 3.369026217114879e-06, "train_lr": 0.005718741565942764, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:51", "episode_count": 139, "remote_memory": 2687, "train_count": 2446, "episode_step": 7.0, "episode_time": 0.9749844074249268, "eval_reward0": 0.4000000134110451, "episode_reward0": 0.760000005364418, "step_time": 0.07423530306134905, "train_time": 0.06437356131417411, "train_loss": 5.501719951629639, "train_v_loss": 1.753811001777649, "train_policy_loss": 2.6495883464813232, "train_reward_loss": 0.20536863803863525, "train_chance_loss": 9.693289939605165e-06, "train_q_loss": 0.8652259111404419, "train_vae_loss": 3.3528708627272863e-06, "train_lr": 0.005699018482118845, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:53", "episode_count": 140, "remote_memory": 2692, "train_count": 2451, "episode_step": 5.0, "episode_time": 0.7025842666625977, "eval_reward0": 0.760000005364418, "episode_reward0": 0.8400000035762787, "step_time": 0.07437710762023926, "train_time": 0.06529412269592286, "train_loss": 5.290128231048584, "train_v_loss": 1.6082890033721924, "train_policy_loss": 2.6546082496643066, "train_reward_loss": 0.20527029037475586, "train_chance_loss": 1.5299277947633527e-05, "train_q_loss": 0.7943798303604126, "train_vae_loss": 3.3464889384049457e-06, "train_lr": 0.005691149737685919, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:56", "episode_count": 141, "remote_memory": 2708, "train_count": 2467, "episode_step": 16.0, "episode_time": 2.2619590759277344, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.07545052468776703, "train_time": 0.06511728465557098, "train_loss": 5.3485307693481445, "train_v_loss": 1.6674940586090088, "train_policy_loss": 2.654665946960449, "train_reward_loss": 0.2021201103925705, "train_chance_loss": 1.1698520211211871e-05, "train_q_loss": 0.7964661717414856, "train_vae_loss": 3.335267365400796e-06, "train_lr": 0.005677409470081329, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:00:59", "episode_count": 142, "remote_memory": 2720, "train_count": 2479, "episode_step": 12.0, "episode_time": 1.6568660736083984, "eval_reward0": 0.08000002056360245, "episode_reward0": -1.4399999901652336, "step_time": 0.0726292332013448, "train_time": 0.06496165196100871, "train_loss": 5.5111260414123535, "train_v_loss": 1.7486299276351929, "train_policy_loss": 2.6725330352783203, "train_reward_loss": 0.20884931087493896, "train_chance_loss": 1.4119723346084356e-05, "train_q_loss": 0.8533597588539124, "train_vae_loss": 3.3204457849933533e-06, "train_lr": 0.005659135524183512, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:06", "episode_count": 143, "remote_memory": 2771, "train_count": 2530, "episode_step": 51.0, "episode_time": 7.25164270401001, "eval_reward0": 0.8400000035762787, "episode_reward0": -2.0399999544024467, "step_time": 0.07274568314645805, "train_time": 0.06883757722144034, "train_loss": 5.468219757080078, "train_v_loss": 1.714158058166504, "train_policy_loss": 2.6630799770355225, "train_reward_loss": 0.22117801010608673, "train_chance_loss": 8.76941794558661e-06, "train_q_loss": 0.8425710201263428, "train_vae_loss": 3.2876873774512205e-06, "train_lr": 0.00561826815828681, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:09", "episode_count": 144, "remote_memory": 2783, "train_count": 2542, "episode_step": 12.0, "episode_time": 1.711629867553711, "eval_reward0": 0.4000000134110451, "episode_reward0": 0.5600000098347664, "step_time": 0.07611093918482463, "train_time": 0.06574271122614543, "train_loss": 5.373235702514648, "train_v_loss": 1.6515899896621704, "train_policy_loss": 2.669229745864868, "train_reward_loss": 0.22548286616802216, "train_chance_loss": 1.5509247532463633e-05, "train_q_loss": 0.7994207739830017, "train_vae_loss": 3.2553941764490446e-06, "train_lr": 0.005577635485678911, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:13", "episode_count": 145, "remote_memory": 2804, "train_count": 2563, "episode_step": 21.0, "episode_time": 2.8904733657836914, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.20000001788139343, "step_time": 0.07289782024565197, "train_time": 0.06415759949457078, "train_loss": 5.414246082305908, "train_v_loss": 1.6966562271118164, "train_policy_loss": 2.657240629196167, "train_reward_loss": 0.218361034989357, "train_chance_loss": 1.7693653717287816e-05, "train_q_loss": 0.8146616816520691, "train_vae_loss": 3.238785211578943e-06, "train_lr": 0.005556488409638405, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:17", "episode_count": 146, "remote_memory": 2829, "train_count": 2588, "episode_step": 25.0, "episode_time": 3.524538993835449, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.04000002145767212, "step_time": 0.07397076606750488, "train_time": 0.06624855041503906, "train_loss": 5.354633331298828, "train_v_loss": 1.6543726921081543, "train_policy_loss": 2.6658997535705566, "train_reward_loss": 0.20859868824481964, "train_chance_loss": 1.3272345313453116e-05, "train_q_loss": 0.7985619306564331, "train_vae_loss": 3.2158548037841683e-06, "train_lr": 0.0055271415039896965, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:18", "episode_count": 147, "remote_memory": 2837, "train_count": 2596, "episode_step": 8.0, "episode_time": 1.1178960800170898, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.2799999937415123, "step_time": 0.07361429929733276, "train_time": 0.06554695963859558, "train_loss": 5.334170341491699, "train_v_loss": 1.6364374160766602, "train_policy_loss": 2.6703312397003174, "train_reward_loss": 0.21129724383354187, "train_chance_loss": 1.472162693971768e-05, "train_q_loss": 0.7892270088195801, "train_vae_loss": 3.1995916742744157e-06, "train_lr": 0.005506175570189953, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:19", "episode_count": 148, "remote_memory": 2843, "train_count": 2602, "episode_step": 6.0, "episode_time": 0.8300693035125732, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.8000000044703484, "step_time": 0.07353965441385905, "train_time": 0.06403092543284099, "train_loss": 5.201512813568115, "train_v_loss": 1.5641382932662964, "train_policy_loss": 2.64575457572937, "train_reward_loss": 0.2344045639038086, "train_chance_loss": 8.004481969692279e-06, "train_q_loss": 0.7302973866462708, "train_vae_loss": 3.192762960679829e-06, "train_lr": 0.005497307050973177, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:22", "episode_count": 149, "remote_memory": 2855, "train_count": 2614, "episode_step": 12.0, "episode_time": 1.6582512855529785, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.4399999901652336, "step_time": 0.07250118255615234, "train_time": 0.06499312321345012, "train_loss": 5.353996753692627, "train_v_loss": 1.6304198503494263, "train_policy_loss": 2.6695716381073, "train_reward_loss": 0.23922540247440338, "train_chance_loss": 8.065320798777975e-06, "train_q_loss": 0.7879138588905334, "train_vae_loss": 3.1839806524658343e-06, "train_lr": 0.005485928151756525, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:24", "episode_count": 150, "remote_memory": 2866, "train_count": 2625, "episode_step": 11.0, "episode_time": 1.5946650505065918, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6000000089406967, "step_time": 0.07364355434070934, "train_time": 0.07051955569874156, "train_loss": 5.3584208488464355, "train_v_loss": 1.654253363609314, "train_policy_loss": 2.6647531986236572, "train_reward_loss": 0.21727052330970764, "train_chance_loss": 1.2048417374899145e-05, "train_q_loss": 0.7955335974693298, "train_vae_loss": 3.1728545764053706e-06, "train_lr": 0.00547142094001174, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:26", "episode_count": 151, "remote_memory": 2878, "train_count": 2637, "episode_step": 12.0, "episode_time": 1.6486244201660156, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.5600000098347664, "step_time": 0.07328593730926514, "train_time": 0.06330233812332153, "train_loss": 5.436779022216797, "train_v_loss": 1.6857095956802368, "train_policy_loss": 2.6583592891693115, "train_reward_loss": 0.23301178216934204, "train_chance_loss": 2.281041997775901e-05, "train_q_loss": 0.8329636454582214, "train_vae_loss": 3.1618021694157505e-06, "train_lr": 0.005456951912492514, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:28", "episode_count": 152, "remote_memory": 2885, "train_count": 2644, "episode_step": 7.0, "episode_time": 0.973651647567749, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.760000005364418, "step_time": 0.0740734509059361, "train_time": 0.064361572265625, "train_loss": 5.356112003326416, "train_v_loss": 1.6653376817703247, "train_policy_loss": 2.651245594024658, "train_reward_loss": 0.20983387529850006, "train_chance_loss": 1.843415157054551e-05, "train_q_loss": 0.8028720021247864, "train_vae_loss": 3.152723593302653e-06, "train_lr": 0.00544502679258585, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:30", "episode_count": 153, "remote_memory": 2899, "train_count": 2658, "episode_step": 14.0, "episode_time": 1.969858169555664, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.48000001162290573, "step_time": 0.07448763506753105, "train_time": 0.06556342329297747, "train_loss": 5.355074882507324, "train_v_loss": 1.6555107831954956, "train_policy_loss": 2.6684000492095947, "train_reward_loss": 0.20059800148010254, "train_chance_loss": 9.667777703725733e-06, "train_q_loss": 0.8037549257278442, "train_vae_loss": 3.1427296107722213e-06, "train_lr": 0.005431880243122578, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:33", "episode_count": 154, "remote_memory": 2912, "train_count": 2671, "episode_step": 13.0, "episode_time": 1.8561162948608398, "eval_reward0": -1.3999999910593033, "episode_reward0": 0.5200000107288361, "step_time": 0.07433687723599948, "train_time": 0.06778029295114371, "train_loss": 5.40472936630249, "train_v_loss": 1.680335283279419, "train_policy_loss": 2.6854379177093506, "train_reward_loss": 0.20284594595432281, "train_chance_loss": 1.3387199942371808e-05, "train_q_loss": 0.8097217082977295, "train_vae_loss": 3.1299957754526986e-06, "train_lr": 0.005415020510554314, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:35", "episode_count": 155, "remote_memory": 2923, "train_count": 2682, "episode_step": 11.0, "episode_time": 1.5260672569274902, "eval_reward0": -1.3199999928474426, "episode_reward0": 0.6000000089406967, "step_time": 0.0732536099173806, "train_time": 0.064641995863481, "train_loss": 5.2362213134765625, "train_v_loss": 1.5988472700119019, "train_policy_loss": 2.6399343013763428, "train_reward_loss": 0.20889128744602203, "train_chance_loss": 1.1266790352237877e-05, "train_q_loss": 0.7623575329780579, "train_vae_loss": 3.1187703370960662e-06, "train_lr": 0.00540007883682847, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:37", "episode_count": 156, "remote_memory": 2933, "train_count": 2692, "episode_step": 10.0, "episode_time": 1.3954486846923828, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.640000008046627, "step_time": 0.07406949996948242, "train_time": 0.06454169750213623, "train_loss": 5.605381488800049, "train_v_loss": 1.8044401407241821, "train_policy_loss": 2.647028923034668, "train_reward_loss": 0.2393496334552765, "train_chance_loss": 1.538352262286935e-05, "train_q_loss": 0.8883708119392395, "train_vae_loss": 3.1089734875422437e-06, "train_lr": 0.005387038923799992, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:40", "episode_count": 157, "remote_memory": 2944, "train_count": 2703, "episode_step": 11.0, "episode_time": 1.529982089996338, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.3999999910593033, "step_time": 0.07283941182223233, "train_time": 0.06540268117731268, "train_loss": 5.271179676055908, "train_v_loss": 1.6008319854736328, "train_policy_loss": 2.6543331146240234, "train_reward_loss": 0.21813148260116577, "train_chance_loss": 2.0883117031189613e-05, "train_q_loss": 0.7718328237533569, "train_vae_loss": 3.09925803776423e-06, "train_lr": 0.00537403067573905, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:42", "episode_count": 158, "remote_memory": 2954, "train_count": 2713, "episode_step": 10.0, "episode_time": 1.3731389045715332, "eval_reward0": 0.2800000160932541, "episode_reward0": 0.640000008046627, "step_time": 0.07371978759765625, "train_time": 0.06314902305603028, "train_loss": 5.454878330230713, "train_v_loss": 1.7327258586883545, "train_policy_loss": 2.6571552753448486, "train_reward_loss": 0.20207278430461884, "train_chance_loss": 8.212134162022267e-06, "train_q_loss": 0.8368032574653625, "train_vae_loss": 3.089616029683384e-06, "train_lr": 0.0053610531613230705, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:45", "episode_count": 159, "remote_memory": 2969, "train_count": 2728, "episode_step": 15.0, "episode_time": 2.087667226791382, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.4400000125169754, "step_time": 0.07359542846679687, "train_time": 0.06500280698140462, "train_loss": 5.422118186950684, "train_v_loss": 1.708912968635559, "train_policy_loss": 2.6500282287597656, "train_reward_loss": 0.22507034242153168, "train_chance_loss": 1.1528727554832585e-05, "train_q_loss": 0.81191486120224, "train_vae_loss": 3.0781616260355804e-06, "train_lr": 0.005345647223293781, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:48", "episode_count": 160, "remote_memory": 2981, "train_count": 2740, "episode_step": 12.0, "episode_time": 1.6688592433929443, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.5600000098347664, "step_time": 0.07373305161794026, "train_time": 0.06454720099767049, "train_loss": 5.465684413909912, "train_v_loss": 1.7060565948486328, "train_policy_loss": 2.6510441303253174, "train_reward_loss": 0.26379433274269104, "train_chance_loss": 2.201701863668859e-05, "train_q_loss": 0.8184089660644531, "train_vae_loss": 3.065912324018427e-06, "train_lr": 0.005329053848981857, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:51", "episode_count": 161, "remote_memory": 3001, "train_count": 2760, "episode_step": 20.0, "episode_time": 2.770812749862671, "eval_reward0": 0.4400000125169754, "episode_reward0": -1.7599999830126762, "step_time": 0.07256395816802978, "train_time": 0.06528974771499634, "train_loss": 5.433460235595703, "train_v_loss": 1.7300302982330322, "train_policy_loss": 2.6363377571105957, "train_reward_loss": 0.21072037518024445, "train_chance_loss": 2.6409277779748663e-05, "train_q_loss": 0.8299665451049805, "train_vae_loss": 3.0515134312736336e-06, "train_lr": 0.0053094602189958096, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:54", "episode_count": 162, "remote_memory": 3017, "train_count": 2776, "episode_step": 16.0, "episode_time": 2.196380376815796, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.4000000134110451, "step_time": 0.07304425537586212, "train_time": 0.06364698708057404, "train_loss": 5.41478157043457, "train_v_loss": 1.6904652118682861, "train_policy_loss": 2.642512083053589, "train_reward_loss": 0.2171882838010788, "train_chance_loss": 9.659338502387982e-06, "train_q_loss": 0.8381506204605103, "train_vae_loss": 3.0354747195815435e-06, "train_lr": 0.005287498235702515, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:01:56", "episode_count": 163, "remote_memory": 3026, "train_count": 2785, "episode_step": 9.0, "episode_time": 1.2269301414489746, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.6800000071525574, "step_time": 0.07232374615139431, "train_time": 0.06296104855007595, "train_loss": 5.435613632202148, "train_v_loss": 1.7135350704193115, "train_policy_loss": 2.64385986328125, "train_reward_loss": 0.21722356975078583, "train_chance_loss": 1.678977787378244e-05, "train_q_loss": 0.8350201845169067, "train_vae_loss": 3.024411398655502e-06, "train_lr": 0.005272299516946077, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:00", "episode_count": 164, "remote_memory": 3049, "train_count": 2808, "episode_step": 23.0, "episode_time": 3.2077066898345947, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.12000001966953278, "step_time": 0.07350767177084218, "train_time": 0.06536386324011761, "train_loss": 5.3361992835998535, "train_v_loss": 1.6619720458984375, "train_policy_loss": 2.6574127674102783, "train_reward_loss": 0.1985202431678772, "train_chance_loss": 1.5615412849001586e-05, "train_q_loss": 0.79198157787323, "train_vae_loss": 3.0103772132861195e-06, "train_lr": 0.005252915900200605, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:02", "episode_count": 165, "remote_memory": 3059, "train_count": 2818, "episode_step": 10.0, "episode_time": 1.3794357776641846, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.359999991953373, "step_time": 0.07238922119140626, "train_time": 0.06464192867279053, "train_loss": 5.407142162322998, "train_v_loss": 1.676465392112732, "train_policy_loss": 2.658773899078369, "train_reward_loss": 0.23954007029533386, "train_chance_loss": 2.099330049532e-05, "train_q_loss": 0.8062087893486023, "train_vae_loss": 2.995999921040493e-06, "train_lr": 0.005232992582023144, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:04", "episode_count": 166, "remote_memory": 3069, "train_count": 2828, "episode_step": 10.0, "episode_time": 1.3731324672698975, "eval_reward0": 0.760000005364418, "episode_reward0": -1.359999991953373, "step_time": 0.0723862886428833, "train_time": 0.06442112922668457, "train_loss": 5.292436122894287, "train_v_loss": 1.626633882522583, "train_policy_loss": 2.630012273788452, "train_reward_loss": 0.22661754488945007, "train_chance_loss": 1.2509774933278095e-05, "train_q_loss": 0.7831199765205383, "train_vae_loss": 2.987389962072484e-06, "train_lr": 0.005220956634730101, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:08", "episode_count": 167, "remote_memory": 3095, "train_count": 2854, "episode_step": 26.0, "episode_time": 3.5867276191711426, "eval_reward0": 0.640000008046627, "episode_reward0": 2.2351741790771484e-08, "step_time": 0.07264905709486741, "train_time": 0.0646129296376155, "train_loss": 5.38054895401001, "train_v_loss": 1.6640886068344116, "train_policy_loss": 2.6713016033172607, "train_reward_loss": 0.2076331079006195, "train_chance_loss": 7.36699485059944e-06, "train_q_loss": 0.8114904165267944, "train_vae_loss": 2.971965841425117e-06, "train_lr": 0.0051993695087730885, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:12", "episode_count": 168, "remote_memory": 3122, "train_count": 2881, "episode_step": 27.0, "episode_time": 3.882483959197998, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.03999997675418854, "step_time": 0.07315395496509693, "train_time": 0.0699656362886782, "train_loss": 5.495713233947754, "train_v_loss": 1.7600905895233154, "train_policy_loss": 2.6609551906585693, "train_reward_loss": 0.20180165767669678, "train_chance_loss": 1.3106859114486724e-05, "train_q_loss": 0.8469029664993286, "train_vae_loss": 2.9495088256226154e-06, "train_lr": 0.005167740397155285, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:13", "episode_count": 169, "remote_memory": 3128, "train_count": 2887, "episode_step": 6.0, "episode_time": 0.8352856636047363, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.8000000044703484, "step_time": 0.07450215021769206, "train_time": 0.06386848290761311, "train_loss": 5.228531360626221, "train_v_loss": 1.6057519912719727, "train_policy_loss": 2.6501331329345703, "train_reward_loss": 0.1730944663286209, "train_chance_loss": 1.4125243069429416e-05, "train_q_loss": 0.7736424803733826, "train_vae_loss": 2.9356851882766932e-06, "train_lr": 0.005148136522620916, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:16", "episode_count": 170, "remote_memory": 3143, "train_count": 2902, "episode_step": 15.0, "episode_time": 2.1305689811706543, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4400000125169754, "step_time": 0.07447264989217123, "train_time": 0.06689591407775879, "train_loss": 5.2826738357543945, "train_v_loss": 1.6133064031600952, "train_policy_loss": 2.6500399112701416, "train_reward_loss": 0.21385714411735535, "train_chance_loss": 7.380595889117103e-06, "train_q_loss": 0.7794799208641052, "train_vae_loss": 2.926958586613182e-06, "train_lr": 0.005135706625878811, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:18", "episode_count": 171, "remote_memory": 3151, "train_count": 2910, "episode_step": 8.0, "episode_time": 1.1474487781524658, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.7200000062584877, "step_time": 0.07576531171798706, "train_time": 0.06700032949447632, "train_loss": 5.452055931091309, "train_v_loss": 1.7272326946258545, "train_policy_loss": 2.654757499694824, "train_reward_loss": 0.21539972722530365, "train_chance_loss": 1.3239856343716383e-05, "train_q_loss": 0.8290382027626038, "train_vae_loss": 2.917460506068892e-06, "train_lr": 0.0051221237517893314, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:20", "episode_count": 172, "remote_memory": 3165, "train_count": 2924, "episode_step": 14.0, "episode_time": 1.9582726955413818, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.48000001162290573, "step_time": 0.07316480364118304, "train_time": 0.06601076466696602, "train_loss": 5.287564754486084, "train_v_loss": 1.6232978105545044, "train_policy_loss": 2.643789768218994, "train_reward_loss": 0.22049029171466827, "train_chance_loss": 1.2937048268213402e-05, "train_q_loss": 0.7745646834373474, "train_vae_loss": 2.9083928438922158e-06, "train_lr": 0.0051091681234538555, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:23", "episode_count": 173, "remote_memory": 3175, "train_count": 2934, "episode_step": 10.0, "episode_time": 1.389857530593872, "eval_reward0": 0.640000008046627, "episode_reward0": 0.640000008046627, "step_time": 0.07334303855895996, "train_time": 0.06477456092834473, "train_loss": 5.449033260345459, "train_v_loss": 1.7032705545425415, "train_policy_loss": 2.6553616523742676, "train_reward_loss": 0.23281511664390564, "train_chance_loss": 1.3336085430637468e-05, "train_q_loss": 0.8319367170333862, "train_vae_loss": 2.8986228244320955e-06, "train_lr": 0.005095069296658039, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:25", "episode_count": 174, "remote_memory": 3184, "train_count": 2943, "episode_step": 9.0, "episode_time": 1.287703514099121, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6800000071525574, "step_time": 0.07481990920172797, "train_time": 0.0671891901228163, "train_loss": 5.455102920532227, "train_v_loss": 1.7223399877548218, "train_policy_loss": 2.660877227783203, "train_reward_loss": 0.2139478325843811, "train_chance_loss": 2.245104406028986e-05, "train_q_loss": 0.832165539264679, "train_vae_loss": 2.8908716558362357e-06, "train_lr": 0.005083935800939798, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:27", "episode_count": 175, "remote_memory": 3197, "train_count": 2956, "episode_step": 13.0, "episode_time": 1.8181421756744385, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.5200000107288361, "step_time": 0.0746156802544227, "train_time": 0.06452056077810434, "train_loss": 5.456746578216553, "train_v_loss": 1.6800905466079712, "train_policy_loss": 2.6439895629882812, "train_reward_loss": 0.2816508412361145, "train_chance_loss": 3.584832666092552e-05, "train_q_loss": 0.8254173994064331, "train_vae_loss": 2.8819918043154757e-06, "train_lr": 0.005071076564490795, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:29", "episode_count": 176, "remote_memory": 3209, "train_count": 2968, "episode_step": 12.0, "episode_time": 1.7082912921905518, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.5600000098347664, "step_time": 0.0743470589319865, "train_time": 0.06725728511810303, "train_loss": 5.35717248916626, "train_v_loss": 1.652960181236267, "train_policy_loss": 2.6561410427093506, "train_reward_loss": 0.21090465784072876, "train_chance_loss": 2.2763992092222907e-05, "train_q_loss": 0.8115194439888, "train_vae_loss": 2.87192665382463e-06, "train_lr": 0.005056501366198063, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:33", "episode_count": 177, "remote_memory": 3231, "train_count": 2990, "episode_step": 22.0, "episode_time": 3.1255970001220703, "eval_reward0": 0.760000005364418, "episode_reward0": 0.1600000187754631, "step_time": 0.07600424506447533, "train_time": 0.06544736298647794, "train_loss": 5.416012287139893, "train_v_loss": 1.696743130683899, "train_policy_loss": 2.6380081176757812, "train_reward_loss": 0.23879055678844452, "train_chance_loss": 1.4653852304036263e-05, "train_q_loss": 0.8166897296905518, "train_vae_loss": 2.8584029223566176e-06, "train_lr": 0.0050367508083581924, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:35", "episode_count": 178, "remote_memory": 3244, "train_count": 3003, "episode_step": 13.0, "episode_time": 1.8095202445983887, "eval_reward0": 0.640000008046627, "episode_reward0": 0.5200000107288361, "step_time": 0.07393266604496883, "train_time": 0.06454627330486591, "train_loss": 5.370377540588379, "train_v_loss": 1.6897591352462769, "train_policy_loss": 2.6289286613464355, "train_reward_loss": 0.20554505288600922, "train_chance_loss": 2.0525090803857893e-05, "train_q_loss": 0.8204468488693237, "train_vae_loss": 2.8445870157156605e-06, "train_lr": 0.005016491748392582, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:40", "episode_count": 179, "remote_memory": 3274, "train_count": 3033, "episode_step": 30.0, "episode_time": 4.05722975730896, "eval_reward0": 0.5600000098347664, "episode_reward0": -0.15999997407197952, "step_time": 0.07174522876739502, "train_time": 0.06290137767791748, "train_loss": 5.410315036773682, "train_v_loss": 1.7091784477233887, "train_policy_loss": 2.6515934467315674, "train_reward_loss": 0.20196397602558136, "train_chance_loss": 1.3711979590880219e-05, "train_q_loss": 0.8221387267112732, "train_vae_loss": 2.8277604542381596e-06, "train_lr": 0.004991727881133556, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:43", "episode_count": 180, "remote_memory": 3290, "train_count": 3049, "episode_step": 16.0, "episode_time": 2.216324806213379, "eval_reward0": 0.2800000160932541, "episode_reward0": 0.4000000134110451, "step_time": 0.07359273731708527, "train_time": 0.06436416506767273, "train_loss": 5.370326519012451, "train_v_loss": 1.6650620698928833, "train_policy_loss": 2.628260374069214, "train_reward_loss": 0.24253962934017181, "train_chance_loss": 1.2599087312992197e-05, "train_q_loss": 0.8094021081924438, "train_vae_loss": 2.809951183735393e-06, "train_lr": 0.004965354688465595, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:46", "episode_count": 181, "remote_memory": 3302, "train_count": 3061, "episode_step": 12.0, "episode_time": 1.6785898208618164, "eval_reward0": 0.760000005364418, "episode_reward0": 0.5600000098347664, "step_time": 0.07363102833429973, "train_time": 0.0655101736386617, "train_loss": 5.504703044891357, "train_v_loss": 1.775194525718689, "train_policy_loss": 2.651571750640869, "train_reward_loss": 0.2044229954481125, "train_chance_loss": 1.0071425094793085e-05, "train_q_loss": 0.8483096957206726, "train_vae_loss": 2.799231197059271e-06, "train_lr": 0.004949372727423906, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:48", "episode_count": 182, "remote_memory": 3311, "train_count": 3070, "episode_step": 9.0, "episode_time": 1.2683789730072021, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6800000071525574, "step_time": 0.07497660319010417, "train_time": 0.06499165958828396, "train_loss": 5.477632522583008, "train_v_loss": 1.718479871749878, "train_policy_loss": 2.6675333976745605, "train_reward_loss": 0.22270338237285614, "train_chance_loss": 2.648082227096893e-05, "train_q_loss": 0.843860387802124, "train_vae_loss": 2.791208544294932e-06, "train_lr": 0.004937420133501291, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:52", "episode_count": 183, "remote_memory": 3340, "train_count": 3099, "episode_step": 29.0, "episode_time": 4.001100063323975, "eval_reward0": 0.6800000071525574, "episode_reward0": -0.1199999749660492, "step_time": 0.07302701062169568, "train_time": 0.06430846247179754, "train_loss": 5.332717418670654, "train_v_loss": 1.6564645767211914, "train_policy_loss": 2.6434268951416016, "train_reward_loss": 0.21260450780391693, "train_chance_loss": 1.1839410035463516e-05, "train_q_loss": 0.7950794100761414, "train_vae_loss": 2.7768594463850604e-06, "train_lr": 0.0049158744513988495, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:54", "episode_count": 184, "remote_memory": 3353, "train_count": 3112, "episode_step": 13.0, "episode_time": 1.7985882759094238, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.5200000107288361, "step_time": 0.07342061629662147, "train_time": 0.06423845657935509, "train_loss": 5.544663429260254, "train_v_loss": 1.7723500728607178, "train_policy_loss": 2.653817653656006, "train_reward_loss": 0.2336052805185318, "train_chance_loss": 1.7876538549899124e-05, "train_q_loss": 0.8598557114601135, "train_vae_loss": 2.7611290533968713e-06, "train_lr": 0.004892154596745968, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:02:58", "episode_count": 185, "remote_memory": 3373, "train_count": 3132, "episode_step": 20.0, "episode_time": 2.834639549255371, "eval_reward0": -1.3999999910593033, "episode_reward0": 0.24000001698732376, "step_time": 0.07492172718048096, "train_time": 0.0661472201347351, "train_loss": 5.4190449714660645, "train_v_loss": 1.6878411769866943, "train_policy_loss": 2.638274669647217, "train_reward_loss": 0.2420380562543869, "train_chance_loss": 2.4791224859654903e-05, "train_q_loss": 0.8256367444992065, "train_vae_loss": 2.7488733849168057e-06, "train_lr": 0.004873605445027351, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:00", "episode_count": 186, "remote_memory": 3382, "train_count": 3141, "episode_step": 9.0, "episode_time": 1.255446434020996, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6800000071525574, "step_time": 0.07365526093377008, "train_time": 0.06483165423075359, "train_loss": 5.37917423248291, "train_v_loss": 1.6756716966629028, "train_policy_loss": 2.62750506401062, "train_reward_loss": 0.2374672293663025, "train_chance_loss": 1.3095841495669447e-05, "train_q_loss": 0.812755823135376, "train_vae_loss": 2.7382129701436497e-06, "train_lr": 0.00485735759139061, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:02", "episode_count": 187, "remote_memory": 3395, "train_count": 3154, "episode_step": 13.0, "episode_time": 1.8085048198699951, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.5200000107288361, "step_time": 0.07326681797321026, "train_time": 0.06508016586303711, "train_loss": 5.471578121185303, "train_v_loss": 1.75677490234375, "train_policy_loss": 2.611628532409668, "train_reward_loss": 0.24772238731384277, "train_chance_loss": 1.7906393622979522e-05, "train_q_loss": 0.8297783732414246, "train_vae_loss": 2.7301441605231958e-06, "train_lr": 0.004845071118324995, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:03", "episode_count": 188, "remote_memory": 3403, "train_count": 3162, "episode_step": 8.0, "episode_time": 1.1470623016357422, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.7200000062584877, "step_time": 0.07688215374946594, "train_time": 0.06591254472732544, "train_loss": 5.305577754974365, "train_v_loss": 1.6381397247314453, "train_policy_loss": 2.64565372467041, "train_reward_loss": 0.20486441254615784, "train_chance_loss": 2.658525772858411e-05, "train_q_loss": 0.7910990118980408, "train_vae_loss": 2.7224939458392328e-06, "train_lr": 0.004833369981497526, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:07", "episode_count": 189, "remote_memory": 3421, "train_count": 3180, "episode_step": 18.0, "episode_time": 2.6724603176116943, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.3200000151991844, "step_time": 0.0744688245985243, "train_time": 0.07331542174021403, "train_loss": 5.388111591339111, "train_v_loss": 1.6894614696502686, "train_policy_loss": 2.6323328018188477, "train_reward_loss": 0.22718143463134766, "train_chance_loss": 1.569241430843249e-05, "train_q_loss": 0.8132787346839905, "train_vae_loss": 2.713098183448892e-06, "train_lr": 0.004818926099687815, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:09", "episode_count": 190, "remote_memory": 3434, "train_count": 3193, "episode_step": 13.0, "episode_time": 1.8396580219268799, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.5200000107288361, "step_time": 0.07518377670874962, "train_time": 0.06552998836223896, "train_loss": 5.366801738739014, "train_v_loss": 1.6824634075164795, "train_policy_loss": 2.6384236812591553, "train_reward_loss": 0.20109055936336517, "train_chance_loss": 9.750620847626124e-06, "train_q_loss": 0.8190169930458069, "train_vae_loss": 2.701956418604823e-06, "train_lr": 0.004801757168024778, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:12", "episode_count": 191, "remote_memory": 3450, "train_count": 3209, "episode_step": 16.0, "episode_time": 2.220268964767456, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.4000000134110451, "step_time": 0.07330118119716644, "train_time": 0.06491036713123322, "train_loss": 5.348451614379883, "train_v_loss": 1.6693756580352783, "train_policy_loss": 2.6513519287109375, "train_reward_loss": 0.19928869605064392, "train_chance_loss": 7.891633686085697e-06, "train_q_loss": 0.8025650978088379, "train_vae_loss": 2.691581357794348e-06, "train_lr": 0.004785752855241299, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:14", "episode_count": 192, "remote_memory": 3458, "train_count": 3217, "episode_step": 8.0, "episode_time": 1.1083314418792725, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.7200000062584877, "step_time": 0.07289966940879822, "train_time": 0.0650193989276886, "train_loss": 5.186837196350098, "train_v_loss": 1.5509963035583496, "train_policy_loss": 2.636657238006592, "train_reward_loss": 0.21735282242298126, "train_chance_loss": 7.477651706722099e-06, "train_q_loss": 0.7558057904243469, "train_vae_loss": 2.683093953237403e-06, "train_lr": 0.004772545304149389, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:16", "episode_count": 193, "remote_memory": 3474, "train_count": 3233, "episode_step": 16.0, "episode_time": 2.215634822845459, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.07259668409824371, "train_time": 0.065257728099823, "train_loss": 5.303536415100098, "train_v_loss": 1.633658766746521, "train_policy_loss": 2.6297216415405273, "train_reward_loss": 0.2228802591562271, "train_chance_loss": 8.470473403576761e-06, "train_q_loss": 0.7912402749061584, "train_vae_loss": 2.6746204184746603e-06, "train_lr": 0.004759378265589476, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:18", "episode_count": 194, "remote_memory": 3481, "train_count": 3240, "episode_step": 7.0, "episode_time": 0.977696418762207, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.07326568875994001, "train_time": 0.06571674346923828, "train_loss": 5.383114814758301, "train_v_loss": 1.6761229038238525, "train_policy_loss": 2.6340107917785645, "train_reward_loss": 0.22968165576457977, "train_chance_loss": 1.7398515410604887e-05, "train_q_loss": 0.8177176713943481, "train_vae_loss": 2.666546379259671e-06, "train_lr": 0.004746790509670973, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:20", "episode_count": 195, "remote_memory": 3496, "train_count": 3255, "episode_step": 15.0, "episode_time": 2.084557294845581, "eval_reward0": -1.2799999937415123, "episode_reward0": 0.4400000125169754, "step_time": 0.07290517489115397, "train_time": 0.06544189453125, "train_loss": 5.4356231689453125, "train_v_loss": 1.7264305353164673, "train_policy_loss": 2.6258132457733154, "train_reward_loss": 0.22006617486476898, "train_chance_loss": 1.4639632354374044e-05, "train_q_loss": 0.837913453578949, "train_vae_loss": 2.6588891159917694e-06, "train_lr": 0.004734784364700317, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:26", "episode_count": 196, "remote_memory": 3531, "train_count": 3290, "episode_step": 35.0, "episode_time": 4.776819229125977, "eval_reward0": 0.8000000044703484, "episode_reward0": -0.35999996960163116, "step_time": 0.07247775622776577, "train_time": 0.06333349091666085, "train_loss": 5.396245002746582, "train_v_loss": 1.6984968185424805, "train_policy_loss": 2.628190279006958, "train_reward_loss": 0.2175964117050171, "train_chance_loss": 1.738914943416603e-05, "train_q_loss": 0.8266317248344421, "train_vae_loss": 2.6415887077746447e-06, "train_lr": 0.004707617685198784, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:27", "episode_count": 197, "remote_memory": 3538, "train_count": 3297, "episode_step": 7.0, "episode_time": 1.0064146518707275, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.760000005364418, "step_time": 0.07512470654078893, "train_time": 0.06789752415248326, "train_loss": 5.317108154296875, "train_v_loss": 1.6209207773208618, "train_policy_loss": 2.669903516769409, "train_reward_loss": 0.22115419805049896, "train_chance_loss": 2.0663052055169828e-05, "train_q_loss": 0.7800033688545227, "train_vae_loss": 2.6272027753293514e-06, "train_lr": 0.004684896674007177, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:29", "episode_count": 198, "remote_memory": 3553, "train_count": 3312, "episode_step": 15.0, "episode_time": 2.0686981678009033, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.4400000125169754, "step_time": 0.07415808041890462, "train_time": 0.0631497065226237, "train_loss": 5.3679728507995605, "train_v_loss": 1.6958305835723877, "train_policy_loss": 2.632876396179199, "train_reward_loss": 0.20382894575595856, "train_chance_loss": 9.428555131307803e-06, "train_q_loss": 0.8103750944137573, "train_vae_loss": 2.6197296847385587e-06, "train_lr": 0.004673047456890345, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:33", "episode_count": 199, "remote_memory": 3573, "train_count": 3332, "episode_step": 20.0, "episode_time": 2.794410228729248, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.24000001698732376, "step_time": 0.07370057106018066, "train_time": 0.06535875797271729, "train_loss": 5.327282905578613, "train_v_loss": 1.6622339487075806, "train_policy_loss": 2.64119291305542, "train_reward_loss": 0.20581674575805664, "train_chance_loss": 8.308977157867048e-06, "train_q_loss": 0.7929447293281555, "train_vae_loss": 2.60791625805723e-06, "train_lr": 0.004654257092624903, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:37", "episode_count": 200, "remote_memory": 3598, "train_count": 3357, "episode_step": 25.0, "episode_time": 3.418275833129883, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.04000002145767212, "step_time": 0.07296015739440918, "train_time": 0.06304818153381347, "train_loss": 5.4317402839660645, "train_v_loss": 1.7231626510620117, "train_policy_loss": 2.640157461166382, "train_reward_loss": 0.20888380706310272, "train_chance_loss": 2.1008225303376094e-05, "train_q_loss": 0.8346453905105591, "train_vae_loss": 2.5928800369001692e-06, "train_lr": 0.0046302094124257565, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:39", "episode_count": 201, "remote_memory": 3607, "train_count": 3366, "episode_step": 9.0, "episode_time": 1.2602622509002686, "eval_reward0": -1.1599999964237213, "episode_reward0": 0.6800000071525574, "step_time": 0.07427448696560329, "train_time": 0.06524740325080024, "train_loss": 5.288484573364258, "train_v_loss": 1.6067471504211426, "train_policy_loss": 2.6352248191833496, "train_reward_loss": 0.245038241147995, "train_chance_loss": 2.1913598175160587e-05, "train_q_loss": 0.776803195476532, "train_vae_loss": 2.581601393103483e-06, "train_lr": 0.004612114280462265, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:41", "episode_count": 202, "remote_memory": 3617, "train_count": 3376, "episode_step": 10.0, "episode_time": 1.4028844833374023, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.640000008046627, "step_time": 0.0733565092086792, "train_time": 0.06597387790679932, "train_loss": 5.386416912078857, "train_v_loss": 1.653742790222168, "train_policy_loss": 2.646315813064575, "train_reward_loss": 0.2565594017505646, "train_chance_loss": 1.7427222701371647e-05, "train_q_loss": 0.8050782084465027, "train_vae_loss": 2.575359758338891e-06, "train_lr": 0.004602036438882351, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:44", "episode_count": 203, "remote_memory": 3637, "train_count": 3396, "episode_step": 20.0, "episode_time": 2.79046630859375, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.24000001698732376, "step_time": 0.07387367486953736, "train_time": 0.06497458219528199, "train_loss": 5.423905372619629, "train_v_loss": 1.7374101877212524, "train_policy_loss": 2.6175484657287598, "train_reward_loss": 0.20203308761119843, "train_chance_loss": 2.459539973642677e-05, "train_q_loss": 0.8424934148788452, "train_vae_loss": 2.565524255260243e-06, "train_lr": 0.004586172290146351, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:48", "episode_count": 204, "remote_memory": 3660, "train_count": 3419, "episode_step": 23.0, "episode_time": 3.1813158988952637, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.12000001966953278, "step_time": 0.07293535315472147, "train_time": 0.06476238499517026, "train_loss": 5.527279376983643, "train_v_loss": 1.7821604013442993, "train_policy_loss": 2.621075391769409, "train_reward_loss": 0.23215755820274353, "train_chance_loss": 2.6078409064211883e-05, "train_q_loss": 0.8676409721374512, "train_vae_loss": 2.5515516881569056e-06, "train_lr": 0.004563525784760714, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:50", "episode_count": 205, "remote_memory": 3666, "train_count": 3425, "episode_step": 6.0, "episode_time": 0.8295960426330566, "eval_reward0": 0.36000001430511475, "episode_reward0": 0.8000000044703484, "step_time": 0.07284855842590332, "train_time": 0.06450458367665608, "train_loss": 5.31442928314209, "train_v_loss": 1.6488827466964722, "train_policy_loss": 2.615999460220337, "train_reward_loss": 0.21999359130859375, "train_chance_loss": 2.9454145987983793e-05, "train_q_loss": 0.8053105473518372, "train_vae_loss": 2.542190259191557e-06, "train_lr": 0.004548309836536646, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:52", "episode_count": 206, "remote_memory": 3675, "train_count": 3434, "episode_step": 9.0, "episode_time": 1.2804572582244873, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6800000071525574, "step_time": 0.07530509101019965, "train_time": 0.06577163272433811, "train_loss": 5.413449287414551, "train_v_loss": 1.713818073272705, "train_policy_loss": 2.6157870292663574, "train_reward_loss": 0.22416111826896667, "train_chance_loss": 2.5931110940291546e-05, "train_q_loss": 0.8354721069335938, "train_vae_loss": 2.537399950597319e-06, "train_lr": 0.004540462512522936, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:56", "episode_count": 207, "remote_memory": 3703, "train_count": 3462, "episode_step": 28.0, "episode_time": 3.946347951889038, "eval_reward0": 0.8000000044703484, "episode_reward0": -0.07999997586011887, "step_time": 0.07386342116764613, "train_time": 0.06636680024010795, "train_loss": 5.29605770111084, "train_v_loss": 1.6344720125198364, "train_policy_loss": 2.6256039142608643, "train_reward_loss": 0.22165100276470184, "train_chance_loss": 1.1291477676422801e-05, "train_q_loss": 0.789967954158783, "train_vae_loss": 2.5256126718886662e-06, "train_lr": 0.004521168768405914, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:03:57", "episode_count": 208, "remote_memory": 3712, "train_count": 3471, "episode_step": 9.0, "episode_time": 1.2785980701446533, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6800000071525574, "step_time": 0.07394541634453668, "train_time": 0.06757916344536676, "train_loss": 5.4233293533325195, "train_v_loss": 1.7189496755599976, "train_policy_loss": 2.6446056365966797, "train_reward_loss": 0.21655914187431335, "train_chance_loss": 9.699949259811547e-06, "train_q_loss": 0.8187264204025269, "train_vae_loss": 2.5139011086139362e-06, "train_lr": 0.004501944407820702, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:01", "episode_count": 209, "remote_memory": 3729, "train_count": 3488, "episode_step": 17.0, "episode_time": 2.3972725868225098, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.36000001430511475, "step_time": 0.07573317078983083, "train_time": 0.06446524227366728, "train_loss": 5.400944709777832, "train_v_loss": 1.7135697603225708, "train_policy_loss": 2.636214017868042, "train_reward_loss": 0.2038637101650238, "train_chance_loss": 1.4127404028840829e-05, "train_q_loss": 0.822944164276123, "train_vae_loss": 2.505753627701779e-06, "train_lr": 0.004488490056246519, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:03", "episode_count": 210, "remote_memory": 3744, "train_count": 3503, "episode_step": 15.0, "episode_time": 2.078212261199951, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4400000125169754, "step_time": 0.07361319859822592, "train_time": 0.06434268951416015, "train_loss": 5.333416938781738, "train_v_loss": 1.6718411445617676, "train_policy_loss": 2.6146507263183594, "train_reward_loss": 0.19566205143928528, "train_chance_loss": 1.8469811038812622e-05, "train_q_loss": 0.8271904587745667, "train_vae_loss": 2.495761236787075e-06, "train_lr": 0.004471984691917896, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:05", "episode_count": 211, "remote_memory": 3755, "train_count": 3514, "episode_step": 11.0, "episode_time": 1.5367112159729004, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.6000000089406967, "step_time": 0.07357640699906783, "train_time": 0.06529580463062633, "train_loss": 5.251672744750977, "train_v_loss": 1.650410771369934, "train_policy_loss": 2.585022211074829, "train_reward_loss": 0.19617004692554474, "train_chance_loss": 1.0323240530851763e-05, "train_q_loss": 0.7961789965629578, "train_vae_loss": 2.48771243605006e-06, "train_lr": 0.004458616953343153, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:07", "episode_count": 212, "remote_memory": 3766, "train_count": 3525, "episode_step": 11.0, "episode_time": 1.5287270545959473, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.6000000089406967, "step_time": 0.07465145804665306, "train_time": 0.0635026368227872, "train_loss": 5.427279472351074, "train_v_loss": 1.7311304807662964, "train_policy_loss": 2.650052547454834, "train_reward_loss": 0.1922171264886856, "train_chance_loss": 1.152617551269941e-05, "train_q_loss": 0.8299133777618408, "train_vae_loss": 2.480916236891062e-06, "train_lr": 0.004447337705641985, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:12", "episode_count": 213, "remote_memory": 3794, "train_count": 3553, "episode_step": 28.0, "episode_time": 3.863909959793091, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.07999997586011887, "step_time": 0.0734333906854902, "train_time": 0.06393828562327794, "train_loss": 5.352914333343506, "train_v_loss": 1.6941642761230469, "train_policy_loss": 2.6085662841796875, "train_reward_loss": 0.219442218542099, "train_chance_loss": 7.969266334839631e-06, "train_q_loss": 0.806517481803894, "train_vae_loss": 2.4689838937774766e-06, "train_lr": 0.004427420441061258, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:14", "episode_count": 214, "remote_memory": 3806, "train_count": 3565, "episode_step": 12.0, "episode_time": 1.6915910243988037, "eval_reward0": -1.1999999955296516, "episode_reward0": 0.5600000098347664, "step_time": 0.07499055067698161, "train_time": 0.06519548098246257, "train_loss": 5.308981418609619, "train_v_loss": 1.6596431732177734, "train_policy_loss": 2.6127307415008545, "train_reward_loss": 0.20168514549732208, "train_chance_loss": 8.688079105922952e-06, "train_q_loss": 0.8110241293907166, "train_vae_loss": 2.4568291792093078e-06, "train_lr": 0.004407071974128485, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:17", "episode_count": 215, "remote_memory": 3816, "train_count": 3575, "episode_step": 10.0, "episode_time": 1.4169626235961914, "eval_reward0": 0.24000001698732376, "episode_reward0": 0.640000008046627, "step_time": 0.07425084114074706, "train_time": 0.06654677391052247, "train_loss": 5.278294563293457, "train_v_loss": 1.6536937952041626, "train_policy_loss": 2.5817055702209473, "train_reward_loss": 0.21309316158294678, "train_chance_loss": 8.110766430036165e-06, "train_q_loss": 0.8061017990112305, "train_vae_loss": 2.4501919142494444e-06, "train_lr": 0.004395923111587763, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:19", "episode_count": 216, "remote_memory": 3825, "train_count": 3584, "episode_step": 9.0, "episode_time": 1.2592132091522217, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.6800000071525574, "step_time": 0.0748849974738227, "train_time": 0.06411390834384495, "train_loss": 5.35091495513916, "train_v_loss": 1.6670022010803223, "train_policy_loss": 2.6095614433288574, "train_reward_loss": 0.25731220841407776, "train_chance_loss": 1.1263802662142552e-05, "train_q_loss": 0.7936705946922302, "train_vae_loss": 2.4444834707537666e-06, "train_lr": 0.004386317916214466, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:21", "episode_count": 217, "remote_memory": 3835, "train_count": 3594, "episode_step": 10.0, "episode_time": 1.3887031078338623, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.640000008046627, "step_time": 0.07302610874176026, "train_time": 0.06491732597351074, "train_loss": 5.365149974822998, "train_v_loss": 1.6699635982513428, "train_policy_loss": 2.6521079540252686, "train_reward_loss": 0.2073606699705124, "train_chance_loss": 1.3649735592480283e-05, "train_q_loss": 0.8124348521232605, "train_vae_loss": 2.4388057227042736e-06, "train_lr": 0.004376733209937811, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:23", "episode_count": 218, "remote_memory": 3843, "train_count": 3602, "episode_step": 8.0, "episode_time": 1.0978484153747559, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.7200000062584877, "step_time": 0.07290822267532349, "train_time": 0.06367525458335876, "train_loss": 5.31477165222168, "train_v_loss": 1.6410034894943237, "train_policy_loss": 2.607788562774658, "train_reward_loss": 0.2335992157459259, "train_chance_loss": 1.4163821106194519e-05, "train_q_loss": 0.8091679215431213, "train_vae_loss": 2.433437430227059e-06, "train_lr": 0.004367672838270664, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:25", "episode_count": 219, "remote_memory": 3855, "train_count": 3614, "episode_step": 12.0, "episode_time": 1.635352373123169, "eval_reward0": 0.4400000125169754, "episode_reward0": 0.5600000098347664, "step_time": 0.07318198680877686, "train_time": 0.062288105487823486, "train_loss": 5.3237481117248535, "train_v_loss": 1.6760088205337524, "train_policy_loss": 2.6284148693084717, "train_reward_loss": 0.19415517151355743, "train_chance_loss": 1.7280732208746485e-05, "train_q_loss": 0.8020954728126526, "train_vae_loss": 2.4275054784084205e-06, "train_lr": 0.004357628058642149, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:29", "episode_count": 220, "remote_memory": 3878, "train_count": 3637, "episode_step": 23.0, "episode_time": 3.1752734184265137, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.12000001966953278, "step_time": 0.07295161744822627, "train_time": 0.0645143985748291, "train_loss": 5.281946659088135, "train_v_loss": 1.6415176391601562, "train_policy_loss": 2.6321094036102295, "train_reward_loss": 0.1901334673166275, "train_chance_loss": 1.720507862046361e-05, "train_q_loss": 0.7948570847511292, "train_vae_loss": 2.4171954464691225e-06, "train_lr": 0.004340108018368483, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:31", "episode_count": 221, "remote_memory": 3889, "train_count": 3648, "episode_step": 11.0, "episode_time": 1.5223989486694336, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6000000089406967, "step_time": 0.07270635258067738, "train_time": 0.06484920328313654, "train_loss": 5.249801158905029, "train_v_loss": 1.6038535833358765, "train_policy_loss": 2.5743472576141357, "train_reward_loss": 0.2559766471385956, "train_chance_loss": 9.3208254838828e-06, "train_q_loss": 0.7922746539115906, "train_vae_loss": 2.4072207907011034e-06, "train_lr": 0.004323148634284735, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:35", "episode_count": 222, "remote_memory": 3909, "train_count": 3668, "episode_step": 20.0, "episode_time": 2.7576844692230225, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.24000001698732376, "step_time": 0.07327402830123901, "train_time": 0.06393195390701294, "train_loss": 5.370388031005859, "train_v_loss": 1.7006105184555054, "train_policy_loss": 2.621166944503784, "train_reward_loss": 0.21394483745098114, "train_chance_loss": 1.383371272822842e-05, "train_q_loss": 0.8114746809005737, "train_vae_loss": 2.3982233869901393e-06, "train_lr": 0.004307748284190893, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:38", "episode_count": 223, "remote_memory": 3932, "train_count": 3691, "episode_step": 23.0, "episode_time": 3.199251413345337, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.12000001966953278, "step_time": 0.07351002485855766, "train_time": 0.06499224123747452, "train_loss": 5.382853031158447, "train_v_loss": 1.6984041929244995, "train_policy_loss": 2.6073014736175537, "train_reward_loss": 0.22237789630889893, "train_chance_loss": 1.6727488400647417e-05, "train_q_loss": 0.8317538499832153, "train_vae_loss": 2.385814013905474e-06, "train_lr": 0.004286476876586676, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:40", "episode_count": 224, "remote_memory": 3938, "train_count": 3697, "episode_step": 6.0, "episode_time": 0.8254923820495605, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.1999999955296516, "step_time": 0.07214876015981038, "train_time": 0.06467171510060628, "train_loss": 5.1587419509887695, "train_v_loss": 1.5635238885879517, "train_policy_loss": 2.636934518814087, "train_reward_loss": 0.18228261172771454, "train_chance_loss": 1.4044550880498718e-05, "train_q_loss": 0.7531352639198303, "train_vae_loss": 2.377507598794182e-06, "train_lr": 0.004272185266017914, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:42", "episode_count": 225, "remote_memory": 3950, "train_count": 3709, "episode_step": 12.0, "episode_time": 1.6387403011322021, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.5600000098347664, "step_time": 0.07306464513142903, "train_time": 0.06277239322662354, "train_loss": 5.422264575958252, "train_v_loss": 1.7035349607467651, "train_policy_loss": 2.6113035678863525, "train_reward_loss": 0.24282817542552948, "train_chance_loss": 1.6296582543873228e-05, "train_q_loss": 0.8417407870292664, "train_vae_loss": 2.3723703179712174e-06, "train_lr": 0.0042633418925106525, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:45", "episode_count": 226, "remote_memory": 3964, "train_count": 3723, "episode_step": 14.0, "episode_time": 1.9132611751556396, "eval_reward0": 0.640000008046627, "episode_reward0": 0.48000001162290573, "step_time": 0.07226227010999407, "train_time": 0.06374876839773995, "train_loss": 5.391689777374268, "train_v_loss": 1.720990538597107, "train_policy_loss": 2.593379259109497, "train_reward_loss": 0.23777537047863007, "train_chance_loss": 3.485533670755103e-05, "train_q_loss": 0.8172024488449097, "train_vae_loss": 2.365000909776427e-06, "train_lr": 0.004250600002706051, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:47", "episode_count": 227, "remote_memory": 3973, "train_count": 3732, "episode_step": 9.0, "episode_time": 1.2622742652893066, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.6800000071525574, "step_time": 0.07382520039876302, "train_time": 0.06550420655144586, "train_loss": 5.358774662017822, "train_v_loss": 1.6950864791870117, "train_policy_loss": 2.5872888565063477, "train_reward_loss": 0.22543668746948242, "train_chance_loss": 2.1429066691780463e-05, "train_q_loss": 0.8287603855133057, "train_vae_loss": 2.3585066628584173e-06, "train_lr": 0.004239358007907867, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:50", "episode_count": 228, "remote_memory": 3988, "train_count": 3747, "episode_step": 15.0, "episode_time": 2.0961410999298096, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4400000125169754, "step_time": 0.07383402188618977, "train_time": 0.06527400016784668, "train_loss": 5.248498439788818, "train_v_loss": 1.6197565793991089, "train_policy_loss": 2.6129872798919678, "train_reward_loss": 0.20553632080554962, "train_chance_loss": 1.120679826271953e-05, "train_q_loss": 0.787903368473053, "train_vae_loss": 2.351772991460166e-06, "train_lr": 0.004227661062031984, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:52", "episode_count": 229, "remote_memory": 4001, "train_count": 3760, "episode_step": 13.0, "episode_time": 1.7942607402801514, "eval_reward0": 0.760000005364418, "episode_reward0": 0.5200000107288361, "step_time": 0.07369140478280875, "train_time": 0.06365251541137695, "train_loss": 5.252847671508789, "train_v_loss": 1.6247488260269165, "train_policy_loss": 2.6181509494781494, "train_reward_loss": 0.20565031468868256, "train_chance_loss": 7.026525963738095e-06, "train_q_loss": 0.7818751931190491, "train_vae_loss": 2.343958612982533e-06, "train_lr": 0.0042140549048781395, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:55", "episode_count": 230, "remote_memory": 4019, "train_count": 3778, "episode_step": 18.0, "episode_time": 2.4907891750335693, "eval_reward0": 0.760000005364418, "episode_reward0": -1.6799999848008156, "step_time": 0.07343357139163548, "train_time": 0.06422903802659777, "train_loss": 5.2178778648376465, "train_v_loss": 1.6143324375152588, "train_policy_loss": 2.5888500213623047, "train_reward_loss": 0.2142934501171112, "train_chance_loss": 9.165550181933213e-06, "train_q_loss": 0.7777810096740723, "train_vae_loss": 2.335346152904094e-06, "train_lr": 0.004199042916297913, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:57", "episode_count": 231, "remote_memory": 4026, "train_count": 3785, "episode_step": 7.0, "episode_time": 0.9636440277099609, "eval_reward0": 0.5200000107288361, "episode_reward0": -1.239999994635582, "step_time": 0.07276020731244769, "train_time": 0.06426031248910087, "train_loss": 5.218490123748779, "train_v_loss": 1.6034399271011353, "train_policy_loss": 2.629075288772583, "train_reward_loss": 0.19160649180412292, "train_chance_loss": 1.525481366115855e-05, "train_q_loss": 0.771713137626648, "train_vae_loss": 2.328448999833199e-06, "train_lr": 0.004186972044408321, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:04:59", "episode_count": 232, "remote_memory": 4035, "train_count": 3794, "episode_step": 9.0, "episode_time": 1.2316992282867432, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.3199999928474426, "step_time": 0.0719361040327284, "train_time": 0.06392084227667914, "train_loss": 5.400449752807617, "train_v_loss": 1.7326738834381104, "train_policy_loss": 2.5922703742980957, "train_reward_loss": 0.20627257227897644, "train_chance_loss": 1.3746597687713802e-05, "train_q_loss": 0.8466648459434509, "train_vae_loss": 2.324038632650627e-06, "train_lr": 0.00417926674708724, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:00", "episode_count": 233, "remote_memory": 4045, "train_count": 3804, "episode_step": 10.0, "episode_time": 1.3867027759552002, "eval_reward0": 0.760000005364418, "episode_reward0": 0.640000008046627, "step_time": 0.0747157096862793, "train_time": 0.06341369152069092, "train_loss": 5.3661298751831055, "train_v_loss": 1.6943762302398682, "train_policy_loss": 2.6140921115875244, "train_reward_loss": 0.21970656514167786, "train_chance_loss": 1.4925230061635375e-05, "train_q_loss": 0.8154374361038208, "train_vae_loss": 2.3188408704299945e-06, "train_lr": 0.004170134663581848, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:07", "episode_count": 234, "remote_memory": 4081, "train_count": 3840, "episode_step": 36.0, "episode_time": 4.872034311294556, "eval_reward0": 0.3200000151991844, "episode_reward0": -0.3999999687075615, "step_time": 0.07201557026969062, "train_time": 0.06272329886754353, "train_loss": 5.348508358001709, "train_v_loss": 1.6831437349319458, "train_policy_loss": 2.593491315841675, "train_reward_loss": 0.24390952289104462, "train_chance_loss": 1.7222737369593233e-05, "train_q_loss": 0.8052628636360168, "train_vae_loss": 2.306343731106608e-06, "train_lr": 0.0041481195949018, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:08", "episode_count": 235, "remote_memory": 4086, "train_count": 3845, "episode_step": 5.0, "episode_time": 0.6933929920196533, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.8400000035762787, "step_time": 0.07395048141479492, "train_time": 0.06384687423706055, "train_loss": 5.142409324645996, "train_v_loss": 1.5464773178100586, "train_policy_loss": 2.61625337600708, "train_reward_loss": 0.229531928896904, "train_chance_loss": 1.7722226402838714e-05, "train_q_loss": 0.727392315864563, "train_vae_loss": 2.2952585823077243e-06, "train_lr": 0.0041285729967057705, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:13", "episode_count": 236, "remote_memory": 4114, "train_count": 3873, "episode_step": 28.0, "episode_time": 4.019768238067627, "eval_reward0": 0.6000000089406967, "episode_reward0": -0.07999997586011887, "step_time": 0.07417564732687813, "train_time": 0.0687620895249503, "train_loss": 5.4018096923828125, "train_v_loss": 1.7161904573440552, "train_policy_loss": 2.6223316192626953, "train_reward_loss": 0.22248895466327667, "train_chance_loss": 2.112971560563892e-05, "train_q_loss": 0.818103015422821, "train_vae_loss": 2.2864389848109568e-06, "train_lr": 0.004112924449145794, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:16", "episode_count": 237, "remote_memory": 4127, "train_count": 3886, "episode_step": 13.0, "episode_time": 1.7989046573638916, "eval_reward0": 0.36000001430511475, "episode_reward0": 0.5200000107288361, "step_time": 0.07422280311584473, "train_time": 0.06348230288578914, "train_loss": 5.400595664978027, "train_v_loss": 1.7112808227539062, "train_policy_loss": 2.632117986679077, "train_reward_loss": 0.20254088938236237, "train_chance_loss": 1.4760955309611745e-05, "train_q_loss": 0.8320626020431519, "train_vae_loss": 2.275540055052261e-06, "train_lr": 0.004093550611287355, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:18", "episode_count": 238, "remote_memory": 4136, "train_count": 3895, "episode_step": 9.0, "episode_time": 1.2064549922943115, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.6800000071525574, "step_time": 0.07201584180196126, "train_time": 0.06111386087205675, "train_loss": 5.361347198486328, "train_v_loss": 1.6881403923034668, "train_policy_loss": 2.624229907989502, "train_reward_loss": 0.20242390036582947, "train_chance_loss": 1.5053708921186626e-05, "train_q_loss": 0.8240720629692078, "train_vae_loss": 2.269729066028958e-06, "train_lr": 0.004083194769918919, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:19", "episode_count": 239, "remote_memory": 4144, "train_count": 3903, "episode_step": 8.0, "episode_time": 1.1223232746124268, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.7200000062584877, "step_time": 0.07468003034591675, "train_time": 0.06504935026168823, "train_loss": 5.386962890625, "train_v_loss": 1.7140594720840454, "train_policy_loss": 2.6206891536712646, "train_reward_loss": 0.20268362760543823, "train_chance_loss": 1.3394468624028377e-05, "train_q_loss": 0.8270102739334106, "train_vae_loss": 2.265280272695236e-06, "train_lr": 0.00407521054148674, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:22", "episode_count": 240, "remote_memory": 4164, "train_count": 3923, "episode_step": 20.0, "episode_time": 2.7385408878326416, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.24000001698732376, "step_time": 0.07294619083404541, "train_time": 0.06329091787338256, "train_loss": 5.279038429260254, "train_v_loss": 1.6236692667007446, "train_policy_loss": 2.605733871459961, "train_reward_loss": 0.24742262065410614, "train_chance_loss": 1.2090590644220356e-05, "train_q_loss": 0.7797874808311462, "train_vae_loss": 2.257914729852928e-06, "train_lr": 0.0040620979852974415, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:27", "episode_count": 241, "remote_memory": 4193, "train_count": 3952, "episode_step": 29.0, "episode_time": 4.05085301399231, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.1199999749660492, "step_time": 0.07400037502420359, "train_time": 0.06503834395573058, "train_loss": 5.406716346740723, "train_v_loss": 1.6973170042037964, "train_policy_loss": 2.625528573989868, "train_reward_loss": 0.23923549056053162, "train_chance_loss": 1.4513400856230874e-05, "train_q_loss": 0.8224824666976929, "train_vae_loss": 2.24521409109002e-06, "train_lr": 0.0040392507798969746, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:30", "episode_count": 242, "remote_memory": 4209, "train_count": 3968, "episode_step": 16.0, "episode_time": 2.2451512813568115, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.4000000134110451, "step_time": 0.0744062215089798, "train_time": 0.065318763256073, "train_loss": 5.354188919067383, "train_v_loss": 1.686513900756836, "train_policy_loss": 2.6136348247528076, "train_reward_loss": 0.21187137067317963, "train_chance_loss": 1.5890947906882502e-05, "train_q_loss": 0.8200467824935913, "train_vae_loss": 2.2336153051583096e-06, "train_lr": 0.004018372856080532, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:33", "episode_count": 243, "remote_memory": 4223, "train_count": 3982, "episode_step": 14.0, "episode_time": 1.9881229400634766, "eval_reward0": 0.4400000125169754, "episode_reward0": -1.5199999883770943, "step_time": 0.07594093254634313, "train_time": 0.06538403034210205, "train_loss": 5.31821870803833, "train_v_loss": 1.6696946620941162, "train_policy_loss": 2.58079195022583, "train_reward_loss": 0.24922020733356476, "train_chance_loss": 1.395673280057963e-05, "train_q_loss": 0.7963696122169495, "train_vae_loss": 2.225977596026496e-06, "train_lr": 0.00400451710447669, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:36", "episode_count": 244, "remote_memory": 4242, "train_count": 4001, "episode_step": 19.0, "episode_time": 2.7010233402252197, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.2800000160932541, "step_time": 0.0755216447930587, "train_time": 0.06591390308580901, "train_loss": 5.308615207672119, "train_v_loss": 1.6511765718460083, "train_policy_loss": 2.5969643592834473, "train_reward_loss": 0.23897404968738556, "train_chance_loss": 1.4954324797145091e-05, "train_q_loss": 0.7992205023765564, "train_vae_loss": 2.217557266703807e-06, "train_lr": 0.0039893328212201595, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:37", "episode_count": 245, "remote_memory": 4248, "train_count": 4007, "episode_step": 6.0, "episode_time": 0.8630833625793457, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07618308067321777, "train_time": 0.06686421235402425, "train_loss": 5.1929097175598145, "train_v_loss": 1.5873489379882812, "train_policy_loss": 2.59260630607605, "train_reward_loss": 0.22279028594493866, "train_chance_loss": 1.8929747966467403e-05, "train_q_loss": 0.7678795456886292, "train_vae_loss": 2.2112474198365817e-06, "train_lr": 0.003977864980697632, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:39", "episode_count": 246, "remote_memory": 4258, "train_count": 4017, "episode_step": 10.0, "episode_time": 1.408412218093872, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.640000008046627, "step_time": 0.07545769214630127, "train_time": 0.06450138092041016, "train_loss": 5.305599689483643, "train_v_loss": 1.6460098028182983, "train_policy_loss": 2.6203019618988037, "train_reward_loss": 0.21833913028240204, "train_chance_loss": 2.0630304788937792e-05, "train_q_loss": 0.7987543344497681, "train_vae_loss": 2.2072797492000973e-06, "train_lr": 0.003970544785261154, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:42", "episode_count": 247, "remote_memory": 4278, "train_count": 4037, "episode_step": 20.0, "episode_time": 2.930670738220215, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.24000001698732376, "step_time": 0.07538673877716065, "train_time": 0.070423424243927, "train_loss": 5.26651668548584, "train_v_loss": 1.6323518753051758, "train_policy_loss": 2.627018451690674, "train_reward_loss": 0.20193931460380554, "train_chance_loss": 1.7904054402606562e-05, "train_q_loss": 0.7829989194869995, "train_vae_loss": 2.1997245767124696e-06, "train_lr": 0.003956858068704605, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:46", "episode_count": 248, "remote_memory": 4299, "train_count": 4058, "episode_step": 21.0, "episode_time": 2.922086238861084, "eval_reward0": 0.640000008046627, "episode_reward0": 0.20000001788139343, "step_time": 0.07305038542974562, "train_time": 0.06550668534778413, "train_loss": 5.39465856552124, "train_v_loss": 1.713507890701294, "train_policy_loss": 2.6057679653167725, "train_reward_loss": 0.22632256150245667, "train_chance_loss": 1.0584220035525504e-05, "train_q_loss": 0.8266726136207581, "train_vae_loss": 2.189537326557911e-06, "train_lr": 0.003938224166631699, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:47", "episode_count": 249, "remote_memory": 4306, "train_count": 4065, "episode_step": 7.0, "episode_time": 0.9687700271606445, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.07345856939043317, "train_time": 0.06433217866080147, "train_loss": 5.240481376647949, "train_v_loss": 1.629306435585022, "train_policy_loss": 2.5854618549346924, "train_reward_loss": 0.21752071380615234, "train_chance_loss": 1.9508152035996318e-05, "train_q_loss": 0.7859727740287781, "train_vae_loss": 2.1826028842042433e-06, "train_lr": 0.003925546072423458, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:50", "episode_count": 250, "remote_memory": 4317, "train_count": 4076, "episode_step": 11.0, "episode_time": 1.4891719818115234, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07226018472151323, "train_time": 0.062332413413307884, "train_loss": 5.38158655166626, "train_v_loss": 1.7000701427459717, "train_policy_loss": 2.598066568374634, "train_reward_loss": 0.2433108687400818, "train_chance_loss": 1.4903434930602089e-05, "train_q_loss": 0.8179324865341187, "train_vae_loss": 2.178190015911241e-06, "train_lr": 0.003917419817298651, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:52", "episode_count": 251, "remote_memory": 4328, "train_count": 4087, "episode_step": 11.0, "episode_time": 1.5514121055603027, "eval_reward0": -1.4399999901652336, "episode_reward0": 0.6000000089406967, "step_time": 0.07545785470442339, "train_time": 0.06481768868186256, "train_loss": 5.1624226570129395, "train_v_loss": 1.5598942041397095, "train_policy_loss": 2.6223931312561035, "train_reward_loss": 0.21458476781845093, "train_chance_loss": 9.415629392606206e-06, "train_q_loss": 0.7435061931610107, "train_vae_loss": 2.1728008050558856e-06, "train_lr": 0.003907510079443455, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:54", "episode_count": 252, "remote_memory": 4339, "train_count": 4098, "episode_step": 11.0, "episode_time": 1.537036418914795, "eval_reward0": 0.760000005364418, "episode_reward0": -1.3999999910593033, "step_time": 0.07304560054432262, "train_time": 0.06589733470569957, "train_loss": 5.344045639038086, "train_v_loss": 1.6591137647628784, "train_policy_loss": 2.645998239517212, "train_reward_loss": 0.21742209792137146, "train_chance_loss": 9.406817298440728e-06, "train_q_loss": 0.7994508743286133, "train_vae_loss": 2.167446837120224e-06, "train_lr": 0.003897625720128417, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:56", "episode_count": 253, "remote_memory": 4349, "train_count": 4108, "episode_step": 10.0, "episode_time": 1.3658034801483154, "eval_reward0": 0.36000001430511475, "episode_reward0": -1.359999991953373, "step_time": 0.07243580818176269, "train_time": 0.06369740962982177, "train_loss": 5.519718647003174, "train_v_loss": 1.7684533596038818, "train_policy_loss": 2.6249613761901855, "train_reward_loss": 0.24207739531993866, "train_chance_loss": 1.8957634893013164e-05, "train_q_loss": 0.8622886538505554, "train_vae_loss": 2.1623495740641374e-06, "train_lr": 0.0038882133085280657, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:05:59", "episode_count": 254, "remote_memory": 4359, "train_count": 4118, "episode_step": 10.0, "episode_time": 1.4030694961547852, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.359999991953373, "step_time": 0.0729895830154419, "train_time": 0.06644172668457031, "train_loss": 5.40474796295166, "train_v_loss": 1.7264007329940796, "train_policy_loss": 2.6197972297668457, "train_reward_loss": 0.20709657669067383, "train_chance_loss": 1.623213211132679e-05, "train_q_loss": 0.8295493125915527, "train_vae_loss": 2.15747490983631e-06, "train_lr": 0.003879270749166608, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:01", "episode_count": 255, "remote_memory": 4373, "train_count": 4132, "episode_step": 14.0, "episode_time": 1.9397802352905273, "eval_reward0": 0.760000005364418, "episode_reward0": 0.48000001162290573, "step_time": 0.07456016540527344, "train_time": 0.0633795942578997, "train_loss": 5.364753723144531, "train_v_loss": 1.7084892988204956, "train_policy_loss": 2.592982053756714, "train_reward_loss": 0.2223833054304123, "train_chance_loss": 9.335174581792671e-06, "train_q_loss": 0.8190824389457703, "train_vae_loss": 2.151715079889982e-06, "train_lr": 0.0038685679901391268, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:02", "episode_count": 256, "remote_memory": 4382, "train_count": 4141, "episode_step": 9.0, "episode_time": 1.2478628158569336, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.6800000071525574, "step_time": 0.07305301560295953, "train_time": 0.065043396419949, "train_loss": 5.339007377624512, "train_v_loss": 1.6542160511016846, "train_policy_loss": 2.6311659812927246, "train_reward_loss": 0.2311219573020935, "train_chance_loss": 1.3927870895713568e-05, "train_q_loss": 0.8007758855819702, "train_vae_loss": 2.1462074073497206e-06, "train_lr": 0.003858336480334401, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:04", "episode_count": 257, "remote_memory": 4388, "train_count": 4147, "episode_step": 6.0, "episode_time": 0.8362007141113281, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07339239120483398, "train_time": 0.06525210539499919, "train_loss": 5.240030765533447, "train_v_loss": 1.5897563695907593, "train_policy_loss": 2.5709712505340576, "train_reward_loss": 0.2888648211956024, "train_chance_loss": 1.5956991774146445e-05, "train_q_loss": 0.7688471674919128, "train_vae_loss": 2.1426101284305332e-06, "train_lr": 0.003851678455248475, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:06", "episode_count": 258, "remote_memory": 4401, "train_count": 4160, "episode_step": 13.0, "episode_time": 1.8480660915374756, "eval_reward0": 0.760000005364418, "episode_reward0": 0.5200000107288361, "step_time": 0.07507034448476937, "train_time": 0.0662976411672739, "train_loss": 5.201666831970215, "train_v_loss": 1.5847251415252686, "train_policy_loss": 2.5918667316436768, "train_reward_loss": 0.24072808027267456, "train_chance_loss": 1.871909262263216e-05, "train_q_loss": 0.7628863453865051, "train_vae_loss": 2.1380724319897126e-06, "train_lr": 0.0038432632572948933, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:07", "episode_count": 259, "remote_memory": 4408, "train_count": 4167, "episode_step": 7.0, "episode_time": 0.9854798316955566, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.760000005364418, "step_time": 0.07482961245945521, "train_time": 0.0653066635131836, "train_loss": 5.321727275848389, "train_v_loss": 1.6780922412872314, "train_policy_loss": 2.615009307861328, "train_reward_loss": 0.19835087656974792, "train_chance_loss": 1.6380854503950104e-05, "train_q_loss": 0.8087837100028992, "train_vae_loss": 2.1333119093469577e-06, "train_lr": 0.003834423143416643, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:11", "episode_count": 260, "remote_memory": 4425, "train_count": 4184, "episode_step": 17.0, "episode_time": 2.3143932819366455, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.36000001430511475, "step_time": 0.07256960868835449, "train_time": 0.06284036355860093, "train_loss": 5.197024345397949, "train_v_loss": 1.606345295906067, "train_policy_loss": 2.594388246536255, "train_reward_loss": 0.19632631540298462, "train_chance_loss": 1.3144752301741391e-05, "train_q_loss": 0.7784412503242493, "train_vae_loss": 2.1276503048284212e-06, "train_lr": 0.0038238447159528732, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:12", "episode_count": 261, "remote_memory": 4430, "train_count": 4189, "episode_step": 5.0, "episode_time": 0.7130727767944336, "eval_reward0": 0.760000005364418, "episode_reward0": 0.8400000035762787, "step_time": 0.07551226615905762, "train_time": 0.06613202095031738, "train_loss": 5.395346164703369, "train_v_loss": 1.716239333152771, "train_policy_loss": 2.6409544944763184, "train_reward_loss": 0.1949467957019806, "train_chance_loss": 9.922775461745914e-06, "train_q_loss": 0.8216298222541809, "train_vae_loss": 2.1224796000751667e-06, "train_lr": 0.0038141696713864803, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:13", "episode_count": 262, "remote_memory": 4436, "train_count": 4195, "episode_step": 6.0, "episode_time": 0.8336567878723145, "eval_reward0": -1.119999997317791, "episode_reward0": -1.1999999955296516, "step_time": 0.07261538505554199, "train_time": 0.06558303038279216, "train_loss": 5.373260021209717, "train_v_loss": 1.6713355779647827, "train_policy_loss": 2.575058937072754, "train_reward_loss": 0.2739225924015045, "train_chance_loss": 9.863437298918143e-06, "train_q_loss": 0.8314465880393982, "train_vae_loss": 2.1198914055275964e-06, "train_lr": 0.0038093423936516047, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:15", "episode_count": 263, "remote_memory": 4449, "train_count": 4208, "episode_step": 13.0, "episode_time": 1.9441447257995605, "eval_reward0": 0.640000008046627, "episode_reward0": 0.5200000107288361, "step_time": 0.0731354493361253, "train_time": 0.07566248453580417, "train_loss": 5.381733417510986, "train_v_loss": 1.7095335721969604, "train_policy_loss": 2.608250617980957, "train_reward_loss": 0.21584783494472504, "train_chance_loss": 1.8899621863965876e-05, "train_q_loss": 0.8266776204109192, "train_vae_loss": 2.1154412479518214e-06, "train_lr": 0.0038010203279554844, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:16", "episode_count": 264, "remote_memory": 4455, "train_count": 4214, "episode_step": 6.0, "episode_time": 0.8415143489837646, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.8000000044703484, "step_time": 0.0750189224878947, "train_time": 0.06445248921712239, "train_loss": 5.164328098297119, "train_v_loss": 1.5766502618789673, "train_policy_loss": 2.6111698150634766, "train_reward_loss": 0.18785159289836884, "train_chance_loss": 1.6463580323033966e-05, "train_q_loss": 0.7671501636505127, "train_vae_loss": 2.1110352008690825e-06, "train_lr": 0.0037927136290818453, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:19", "episode_count": 265, "remote_memory": 4469, "train_count": 4228, "episode_step": 14.0, "episode_time": 1.9403748512268066, "eval_reward0": 0.760000005364418, "episode_reward0": 0.48000001162290573, "step_time": 0.07364371844700404, "train_time": 0.06433767931801933, "train_loss": 5.23883056640625, "train_v_loss": 1.623422622680664, "train_policy_loss": 2.5778157711029053, "train_reward_loss": 0.2328946888446808, "train_chance_loss": 1.1511294360389002e-05, "train_q_loss": 0.7831425070762634, "train_vae_loss": 2.106363581333426e-06, "train_lr": 0.0037839917931705713, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:20", "episode_count": 266, "remote_memory": 4477, "train_count": 4236, "episode_step": 8.0, "episode_time": 1.1232092380523682, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.7200000062584877, "step_time": 0.07455992698669434, "train_time": 0.06521201133728027, "train_loss": 5.422077178955078, "train_v_loss": 1.7422854900360107, "train_policy_loss": 2.614686965942383, "train_reward_loss": 0.2114643156528473, "train_chance_loss": 1.3355368537304457e-05, "train_q_loss": 0.8321255445480347, "train_vae_loss": 2.101277914334787e-06, "train_lr": 0.003774418495595455, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:23", "episode_count": 267, "remote_memory": 4491, "train_count": 4250, "episode_step": 14.0, "episode_time": 1.9261796474456787, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.5199999883770943, "step_time": 0.07278110299791608, "train_time": 0.06414851120540074, "train_loss": 5.346595287322998, "train_v_loss": 1.6988775730133057, "train_policy_loss": 2.586224317550659, "train_reward_loss": 0.21565113961696625, "train_chance_loss": 1.6197844161069952e-05, "train_q_loss": 0.824395477771759, "train_vae_loss": 2.0962020244041923e-06, "train_lr": 0.0037648717407137156, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:25", "episode_count": 268, "remote_memory": 4498, "train_count": 4257, "episode_step": 7.0, "episode_time": 0.9580659866333008, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.760000005364418, "step_time": 0.0736407893044608, "train_time": 0.06254652568272182, "train_loss": 5.434787273406982, "train_v_loss": 1.7195100784301758, "train_policy_loss": 2.606450319290161, "train_reward_loss": 0.24974863231182098, "train_chance_loss": 1.515899202786386e-05, "train_q_loss": 0.8376252055168152, "train_vae_loss": 2.09138647733198e-06, "train_lr": 0.0037557794712483883, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:26", "episode_count": 269, "remote_memory": 4506, "train_count": 4265, "episode_step": 8.0, "episode_time": 1.104884147644043, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.7200000062584877, "step_time": 0.07484805583953857, "train_time": 0.06269648671150208, "train_loss": 5.325230598449707, "train_v_loss": 1.6610260009765625, "train_policy_loss": 2.6380181312561035, "train_reward_loss": 0.21279911696910858, "train_chance_loss": 2.1383606508607045e-05, "train_q_loss": 0.7918037176132202, "train_vae_loss": 2.087974507958279e-06, "train_lr": 0.0037492988631129265, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:29", "episode_count": 270, "remote_memory": 4522, "train_count": 4281, "episode_step": 16.0, "episode_time": 2.2573044300079346, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.4000000134110451, "step_time": 0.0745171457529068, "train_time": 0.0659424215555191, "train_loss": 5.418549060821533, "train_v_loss": 1.7380733489990234, "train_policy_loss": 2.607476234436035, "train_reward_loss": 0.2125750184059143, "train_chance_loss": 2.0807088731089607e-05, "train_q_loss": 0.8387206792831421, "train_vae_loss": 2.082481842080597e-06, "train_lr": 0.0037389551289379597, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:34", "episode_count": 271, "remote_memory": 4551, "train_count": 4310, "episode_step": 29.0, "episode_time": 4.1039183139801025, "eval_reward0": 0.760000005364418, "episode_reward0": -0.1199999749660492, "step_time": 0.07445818802406048, "train_time": 0.06645490383279734, "train_loss": 5.369941234588623, "train_v_loss": 1.6897201538085938, "train_policy_loss": 2.6173055171966553, "train_reward_loss": 0.2183133065700531, "train_chance_loss": 2.145602229575161e-05, "train_q_loss": 0.8229650259017944, "train_vae_loss": 2.072301640509977e-06, "train_lr": 0.003719639265909791, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:35", "episode_count": 272, "remote_memory": 4556, "train_count": 4315, "episode_step": 5.0, "episode_time": 0.6935741901397705, "eval_reward0": -1.3199999928474426, "episode_reward0": 0.8400000035762787, "step_time": 0.07367095947265626, "train_time": 0.0639101505279541, "train_loss": 5.111756324768066, "train_v_loss": 1.5593249797821045, "train_policy_loss": 2.590127944946289, "train_reward_loss": 0.18491554260253906, "train_chance_loss": 1.3163838957552798e-05, "train_q_loss": 0.7557321786880493, "train_vae_loss": 2.0646446046157507e-06, "train_lr": 0.0037051006220281124, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:37", "episode_count": 273, "remote_memory": 4567, "train_count": 4326, "episode_step": 11.0, "episode_time": 1.5226922035217285, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.3999999910593033, "step_time": 0.07372424819252708, "train_time": 0.06391993435946378, "train_loss": 5.237425327301025, "train_v_loss": 1.6262520551681519, "train_policy_loss": 2.580307960510254, "train_reward_loss": 0.21766647696495056, "train_chance_loss": 9.916810085996985e-06, "train_q_loss": 0.79143887758255, "train_vae_loss": 2.061048235191265e-06, "train_lr": 0.003698282642289996, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:38", "episode_count": 274, "remote_memory": 4573, "train_count": 4332, "episode_step": 6.0, "episode_time": 0.8514149188995361, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07552214463551839, "train_time": 0.06557758649190266, "train_loss": 5.303386211395264, "train_v_loss": 1.6904411315917969, "train_policy_loss": 2.5744688510894775, "train_reward_loss": 0.21742580831050873, "train_chance_loss": 1.0699160156946164e-05, "train_q_loss": 0.7992753982543945, "train_vae_loss": 2.0572610992530826e-06, "train_lr": 0.003691050922498107, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:43", "episode_count": 275, "remote_memory": 4599, "train_count": 4358, "episode_step": 26.0, "episode_time": 3.585792064666748, "eval_reward0": 0.760000005364418, "episode_reward0": 2.2351741790771484e-08, "step_time": 0.07326122430654672, "train_time": 0.06400874027839074, "train_loss": 5.310022354125977, "train_v_loss": 1.6827105283737183, "train_policy_loss": 2.574709177017212, "train_reward_loss": 0.22349892556667328, "train_chance_loss": 1.3086557373753749e-05, "train_q_loss": 0.8075186014175415, "train_vae_loss": 2.050158855126938e-06, "train_lr": 0.0036774827167391777, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:46", "episode_count": 276, "remote_memory": 4619, "train_count": 4378, "episode_step": 20.0, "episode_time": 2.7659542560577393, "eval_reward0": 0.760000005364418, "episode_reward0": 0.24000001698732376, "step_time": 0.07282902002334594, "train_time": 0.06482009887695313, "train_loss": 5.273168563842773, "train_v_loss": 1.6313636302947998, "train_policy_loss": 2.6089537143707275, "train_reward_loss": 0.22989635169506073, "train_chance_loss": 1.2094692465325352e-05, "train_q_loss": 0.7815000414848328, "train_vae_loss": 2.04001548809174e-06, "train_lr": 0.0036580567248165607, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:48", "episode_count": 277, "remote_memory": 4634, "train_count": 4393, "episode_step": 15.0, "episode_time": 2.1404263973236084, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.4400000125169754, "step_time": 0.07500961621602377, "train_time": 0.06706226666768392, "train_loss": 5.265267848968506, "train_v_loss": 1.6540071964263916, "train_policy_loss": 2.591421604156494, "train_reward_loss": 0.21233795583248138, "train_chance_loss": 1.0173638656851836e-05, "train_q_loss": 0.7860203981399536, "train_vae_loss": 2.032343218161259e-06, "train_lr": 0.0036433443892747164, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:52", "episode_count": 278, "remote_memory": 4654, "train_count": 4413, "episode_step": 20.0, "episode_time": 2.7589168548583984, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.24000001698732376, "step_time": 0.07278549671173096, "train_time": 0.06444002389907837, "train_loss": 5.278622627258301, "train_v_loss": 1.6531140804290771, "train_policy_loss": 2.587090015411377, "train_reward_loss": 0.2099442183971405, "train_chance_loss": 8.62785782373976e-06, "train_q_loss": 0.8071285486221313, "train_vae_loss": 2.024724835791858e-06, "train_lr": 0.0036286942195147276, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:57", "episode_count": 279, "remote_memory": 4687, "train_count": 4446, "episode_step": 33.0, "episode_time": 4.536549091339111, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.2799999713897705, "step_time": 0.07326143438165839, "train_time": 0.06356981306365042, "train_loss": 5.2460036277771, "train_v_loss": 1.6288635730743408, "train_policy_loss": 2.597925901412964, "train_reward_loss": 0.2083728313446045, "train_chance_loss": 7.818884114385583e-06, "train_q_loss": 0.7894755601882935, "train_vae_loss": 2.013291805269546e-06, "train_lr": 0.003606625599786639, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:06:59", "episode_count": 280, "remote_memory": 4695, "train_count": 4454, "episode_step": 8.0, "episode_time": 1.1228253841400146, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.7200000062584877, "step_time": 0.07326146960258484, "train_time": 0.06647920608520508, "train_loss": 5.364623546600342, "train_v_loss": 1.7169362306594849, "train_policy_loss": 2.621741771697998, "train_reward_loss": 0.17746829986572266, "train_chance_loss": 9.718462933960836e-06, "train_q_loss": 0.8270493149757385, "train_vae_loss": 2.004487896556384e-06, "train_lr": 0.003589632920920849, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:04", "episode_count": 281, "remote_memory": 4732, "train_count": 4491, "episode_step": 37.0, "episode_time": 5.177387475967407, "eval_reward0": 0.8000000044703484, "episode_reward0": -0.4399999678134918, "step_time": 0.0741587071805387, "train_time": 0.06514001537013699, "train_loss": 5.330748558044434, "train_v_loss": 1.698555588722229, "train_policy_loss": 2.5633044242858887, "train_reward_loss": 0.21602977812290192, "train_chance_loss": 1.783980587788392e-05, "train_q_loss": 0.8318561315536499, "train_vae_loss": 1.994942294913926e-06, "train_lr": 0.003571094246581197, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:06", "episode_count": 282, "remote_memory": 4741, "train_count": 4500, "episode_step": 9.0, "episode_time": 1.2690551280975342, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6800000071525574, "step_time": 0.07500203450520833, "train_time": 0.065495941374037, "train_loss": 5.272536754608154, "train_v_loss": 1.6582387685775757, "train_policy_loss": 2.5836374759674072, "train_reward_loss": 0.20273758471012115, "train_chance_loss": 9.920127922669053e-06, "train_q_loss": 0.8068386316299438, "train_vae_loss": 1.9852386685670353e-06, "train_lr": 0.003552221693098545, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:08", "episode_count": 283, "remote_memory": 4749, "train_count": 4508, "episode_step": 8.0, "episode_time": 1.1150779724121094, "eval_reward0": 0.640000008046627, "episode_reward0": -1.2799999937415123, "step_time": 0.07467561960220337, "train_time": 0.06415152549743652, "train_loss": 5.120476245880127, "train_v_loss": 1.553884506225586, "train_policy_loss": 2.594864845275879, "train_reward_loss": 0.20921236276626587, "train_chance_loss": 8.270223588624503e-06, "train_q_loss": 0.7413266897201538, "train_vae_loss": 1.981682544283103e-06, "train_lr": 0.003545275889337063, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:09", "episode_count": 284, "remote_memory": 4757, "train_count": 4516, "episode_step": 8.0, "episode_time": 1.1219260692596436, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.7200000062584877, "step_time": 0.07346737384796143, "train_time": 0.06620970368385315, "train_loss": 5.293385028839111, "train_v_loss": 1.6554721593856812, "train_policy_loss": 2.6147422790527344, "train_reward_loss": 0.19915078580379486, "train_chance_loss": 8.071852789726108e-06, "train_q_loss": 0.8028593063354492, "train_vae_loss": 1.978334694285877e-06, "train_lr": 0.003538751509040594, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:10", "episode_count": 285, "remote_memory": 4762, "train_count": 4521, "episode_step": 5.0, "episode_time": 0.6923940181732178, "eval_reward0": 0.760000005364418, "episode_reward0": -1.1599999964237213, "step_time": 0.07273302078247071, "train_time": 0.06491007804870605, "train_loss": 5.303636074066162, "train_v_loss": 1.6686681509017944, "train_policy_loss": 2.614786386489868, "train_reward_loss": 0.19972436130046844, "train_chance_loss": 7.939401257317513e-06, "train_q_loss": 0.7992832064628601, "train_vae_loss": 1.9756212168431375e-06, "train_lr": 0.0035334588028490543, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:12", "episode_count": 286, "remote_memory": 4771, "train_count": 4530, "episode_step": 9.0, "episode_time": 1.2427027225494385, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6800000071525574, "step_time": 0.07258343696594238, "train_time": 0.0645767052968343, "train_loss": 5.433109760284424, "train_v_loss": 1.7456517219543457, "train_policy_loss": 2.6083438396453857, "train_reward_loss": 0.22170135378837585, "train_chance_loss": 8.809986866253894e-06, "train_q_loss": 0.8363493084907532, "train_vae_loss": 1.9727185645024292e-06, "train_lr": 0.0035277684219181538, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:14", "episode_count": 287, "remote_memory": 4784, "train_count": 4543, "episode_step": 13.0, "episode_time": 1.9744434356689453, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.479999989271164, "step_time": 0.07302733568044809, "train_time": 0.07814236787649301, "train_loss": 5.236944198608398, "train_v_loss": 1.630226969718933, "train_policy_loss": 2.5962283611297607, "train_reward_loss": 0.19653351604938507, "train_chance_loss": 1.4186107364366762e-05, "train_q_loss": 0.7927818894386292, "train_vae_loss": 1.9681581306940643e-06, "train_lr": 0.003518845420330763, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:16", "episode_count": 288, "remote_memory": 4791, "train_count": 4550, "episode_step": 7.0, "episode_time": 0.9579446315765381, "eval_reward0": -1.4399999901652336, "episode_reward0": 0.760000005364418, "step_time": 0.07281603131975446, "train_time": 0.06342625617980957, "train_loss": 5.416861057281494, "train_v_loss": 1.7306525707244873, "train_policy_loss": 2.5860443115234375, "train_reward_loss": 0.22042138874530792, "train_chance_loss": 1.1586837899812963e-05, "train_q_loss": 0.8583762049674988, "train_vae_loss": 1.9640558548417175e-06, "train_lr": 0.0035107508301734924, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:19", "episode_count": 289, "remote_memory": 4806, "train_count": 4565, "episode_step": 15.0, "episode_time": 2.378373384475708, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.4400000125169754, "step_time": 0.07785673141479492, "train_time": 0.07979626655578613, "train_loss": 5.435364723205566, "train_v_loss": 1.7361797094345093, "train_policy_loss": 2.6139252185821533, "train_reward_loss": 0.21908308565616608, "train_chance_loss": 1.7472826584707946e-05, "train_q_loss": 0.8449179530143738, "train_vae_loss": 1.959481323865475e-06, "train_lr": 0.003501871367916465, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:21", "episode_count": 290, "remote_memory": 4815, "train_count": 4574, "episode_step": 9.0, "episode_time": 1.2847981452941895, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.6800000071525574, "step_time": 0.07454135682847765, "train_time": 0.06767998801337348, "train_loss": 5.2875847816467285, "train_v_loss": 1.643633246421814, "train_policy_loss": 2.588625192642212, "train_reward_loss": 0.23549802601337433, "train_chance_loss": 1.9755068933591247e-05, "train_q_loss": 0.7987655401229858, "train_vae_loss": 1.9546328076103237e-06, "train_lr": 0.0034922074992209673, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:25", "episode_count": 291, "remote_memory": 4841, "train_count": 4600, "episode_step": 26.0, "episode_time": 3.6709020137786865, "eval_reward0": 0.8000000044703484, "episode_reward0": 2.2351741790771484e-08, "step_time": 0.07280175502483661, "train_time": 0.06769990921020508, "train_loss": 5.2137274742126465, "train_v_loss": 1.6174334287643433, "train_policy_loss": 2.5894277095794678, "train_reward_loss": 0.21989819407463074, "train_chance_loss": 1.1092894055764191e-05, "train_q_loss": 0.7657870054244995, "train_vae_loss": 1.947439386640326e-06, "train_lr": 0.0034781689755618572, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:27", "episode_count": 292, "remote_memory": 4854, "train_count": 4613, "episode_step": 13.0, "episode_time": 1.7886474132537842, "eval_reward0": 0.760000005364418, "episode_reward0": 0.5200000107288361, "step_time": 0.07262719594515286, "train_time": 0.06429437490609977, "train_loss": 5.344452381134033, "train_v_loss": 1.7008272409439087, "train_policy_loss": 2.579802989959717, "train_reward_loss": 0.23550298810005188, "train_chance_loss": 1.3407217011263128e-05, "train_q_loss": 0.8071860671043396, "train_vae_loss": 1.939567027875455e-06, "train_lr": 0.0034625825937837362, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:30", "episode_count": 293, "remote_memory": 4865, "train_count": 4624, "episode_step": 11.0, "episode_time": 1.5671181678771973, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07531974532387474, "train_time": 0.0663343993100253, "train_loss": 5.256004333496094, "train_v_loss": 1.6585288047790527, "train_policy_loss": 2.5581533908843994, "train_reward_loss": 0.2184065282344818, "train_chance_loss": 9.559859790897463e-06, "train_q_loss": 0.7998529076576233, "train_vae_loss": 1.934697138494812e-06, "train_lr": 0.003453028155490756, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:31", "episode_count": 294, "remote_memory": 4873, "train_count": 4632, "episode_step": 8.0, "episode_time": 1.1476843357086182, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.7200000062584877, "step_time": 0.07410469651222229, "train_time": 0.06876444816589355, "train_loss": 5.1576619148254395, "train_v_loss": 1.5697762966156006, "train_policy_loss": 2.5687196254730225, "train_reward_loss": 0.23352572321891785, "train_chance_loss": 5.321609023667406e-06, "train_q_loss": 0.7646231651306152, "train_vae_loss": 1.930907728819875e-06, "train_lr": 0.0034454825799912214, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:33", "episode_count": 295, "remote_memory": 4878, "train_count": 4637, "episode_step": 5.0, "episode_time": 0.7135894298553467, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.8400000035762787, "step_time": 0.07542581558227539, "train_time": 0.06632504463195801, "train_loss": 5.226269721984863, "train_v_loss": 1.5645616054534912, "train_policy_loss": 2.614774227142334, "train_reward_loss": 0.2656824290752411, "train_chance_loss": 5.291435627441388e-06, "train_q_loss": 0.7602967023849487, "train_vae_loss": 1.9283302208350506e-06, "train_lr": 0.0034403293393552303, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:34", "episode_count": 296, "remote_memory": 4883, "train_count": 4642, "episode_step": 5.0, "episode_time": 0.6908197402954102, "eval_reward0": 0.760000005364418, "episode_reward0": 0.8400000035762787, "step_time": 0.07387886047363282, "train_time": 0.06343331336975097, "train_loss": 5.434821605682373, "train_v_loss": 1.7806167602539062, "train_policy_loss": 2.553380250930786, "train_reward_loss": 0.21277479827404022, "train_chance_loss": 6.040973858034704e-06, "train_q_loss": 0.8671358823776245, "train_vae_loss": 1.9263120520918164e-06, "train_lr": 0.003436370985582471, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:36", "episode_count": 297, "remote_memory": 4897, "train_count": 4656, "episode_step": 14.0, "episode_time": 2.008439064025879, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.48000001162290573, "step_time": 0.07661111014229911, "train_time": 0.06619296755109515, "train_loss": 5.158276557922363, "train_v_loss": 1.5954252481460571, "train_policy_loss": 2.5844757556915283, "train_reward_loss": 0.1881406307220459, "train_chance_loss": 8.87745864019962e-06, "train_q_loss": 0.7694011926651001, "train_vae_loss": 1.9224985408072826e-06, "train_lr": 0.003428863361477852, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:39", "episode_count": 298, "remote_memory": 4913, "train_count": 4672, "episode_step": 16.0, "episode_time": 2.274839401245117, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.4000000134110451, "step_time": 0.07375052571296692, "train_time": 0.06751871109008789, "train_loss": 5.340209007263184, "train_v_loss": 1.6840168237686157, "train_policy_loss": 2.608081579208374, "train_reward_loss": 0.22415411472320557, "train_chance_loss": 1.0856583685381338e-05, "train_q_loss": 0.803130030632019, "train_vae_loss": 1.9165518096997403e-06, "train_lr": 0.0034170416183769703, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:43", "episode_count": 299, "remote_memory": 4930, "train_count": 4689, "episode_step": 17.0, "episode_time": 2.34857177734375, "eval_reward0": -1.7599999830126762, "episode_reward0": -1.6399999856948853, "step_time": 0.07236943525426529, "train_time": 0.06525789990144618, "train_loss": 5.370692729949951, "train_v_loss": 1.685744047164917, "train_policy_loss": 2.605020761489868, "train_reward_loss": 0.24812278151512146, "train_chance_loss": 2.7866575692314655e-05, "train_q_loss": 0.8112862706184387, "train_vae_loss": 1.910054152176599e-06, "train_lr": 0.003404084127396345, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:46", "episode_count": 300, "remote_memory": 4947, "train_count": 4706, "episode_step": 17.0, "episode_time": 2.385660171508789, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.36000001430511475, "step_time": 0.07332463825450224, "train_time": 0.06625484017764821, "train_loss": 5.397942066192627, "train_v_loss": 1.7315254211425781, "train_policy_loss": 2.6002492904663086, "train_reward_loss": 0.20889995992183685, "train_chance_loss": 2.4232096620835364e-05, "train_q_loss": 0.8365989923477173, "train_vae_loss": 1.9033808484891779e-06, "train_lr": 0.0033907850738614798, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:47", "episode_count": 301, "remote_memory": 4956, "train_count": 4715, "episode_step": 9.0, "episode_time": 1.2687039375305176, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6800000071525574, "step_time": 0.07384014129638672, "train_time": 0.06659041510687934, "train_loss": 5.389837741851807, "train_v_loss": 1.7091498374938965, "train_policy_loss": 2.618330955505371, "train_reward_loss": 0.20355744659900665, "train_chance_loss": 2.009967647609301e-05, "train_q_loss": 0.8380927443504333, "train_vae_loss": 1.8982977962878067e-06, "train_lr": 0.003380649024620652, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:50", "episode_count": 302, "remote_memory": 4970, "train_count": 4729, "episode_step": 14.0, "episode_time": 1.9065687656402588, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.48000001162290573, "step_time": 0.07224198750087193, "train_time": 0.06331016336168561, "train_loss": 5.2996625900268555, "train_v_loss": 1.649378776550293, "train_policy_loss": 2.605844497680664, "train_reward_loss": 0.22257204353809357, "train_chance_loss": 1.9237866581534036e-05, "train_q_loss": 0.8012453317642212, "train_vae_loss": 1.8938278572022682e-06, "train_lr": 0.003371709957718849, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:52", "episode_count": 303, "remote_memory": 4980, "train_count": 4739, "episode_step": 10.0, "episode_time": 1.426274061203003, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.359999991953373, "step_time": 0.07412281036376953, "train_time": 0.06759505271911621, "train_loss": 5.3440446853637695, "train_v_loss": 1.6910734176635742, "train_policy_loss": 2.5962023735046387, "train_reward_loss": 0.23377370834350586, "train_chance_loss": 2.0093913917662576e-05, "train_q_loss": 0.8024009466171265, "train_vae_loss": 1.8891963691203273e-06, "train_lr": 0.0033624053467065096, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:55", "episode_count": 304, "remote_memory": 5000, "train_count": 4759, "episode_step": 20.0, "episode_time": 2.762277364730835, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.24000001698732376, "step_time": 0.07239140272140503, "train_time": 0.06498830318450928, "train_loss": 5.353591442108154, "train_v_loss": 1.7064186334609985, "train_policy_loss": 2.584712266921997, "train_reward_loss": 0.21699240803718567, "train_chance_loss": 1.95242500922177e-05, "train_q_loss": 0.8249461054801941, "train_vae_loss": 1.8833852664101869e-06, "train_lr": 0.003350814338773489, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:57", "episode_count": 305, "remote_memory": 5008, "train_count": 4767, "episode_step": 8.0, "episode_time": 1.093963623046875, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.7200000062584877, "step_time": 0.07283616065979004, "train_time": 0.06334435939788818, "train_loss": 5.317399024963379, "train_v_loss": 1.6910068988800049, "train_policy_loss": 2.611513137817383, "train_reward_loss": 0.1835155487060547, "train_chance_loss": 1.3584425687440671e-05, "train_q_loss": 0.8108332753181458, "train_vae_loss": 1.878021976153832e-06, "train_lr": 0.0033400277607142925, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:07:59", "episode_count": 306, "remote_memory": 5017, "train_count": 4776, "episode_step": 9.0, "episode_time": 1.253796100616455, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6800000071525574, "step_time": 0.07315503226386176, "train_time": 0.06516607602437337, "train_loss": 5.374566078186035, "train_v_loss": 1.6916636228561401, "train_policy_loss": 2.5873236656188965, "train_reward_loss": 0.2557479739189148, "train_chance_loss": 8.455656825390179e-06, "train_q_loss": 0.8192007541656494, "train_vae_loss": 1.8747731473922613e-06, "train_lr": 0.003333497093990445, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:00", "episode_count": 307, "remote_memory": 5027, "train_count": 4786, "episode_step": 10.0, "episode_time": 1.3542485237121582, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.359999991953373, "step_time": 0.07174110412597656, "train_time": 0.06317965984344483, "train_loss": 5.4438982009887695, "train_v_loss": 1.7276582717895508, "train_policy_loss": 2.624525785446167, "train_reward_loss": 0.22280892729759216, "train_chance_loss": 8.238172085839324e-06, "train_q_loss": 0.8482820391654968, "train_vae_loss": 1.8711523352976656e-06, "train_lr": 0.003326213452965021, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:01", "episode_count": 308, "remote_memory": 5032, "train_count": 4791, "episode_step": 5.0, "episode_time": 0.7152485847473145, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.8400000035762787, "step_time": 0.07430586814880372, "train_time": 0.06782064437866211, "train_loss": 5.101501941680908, "train_v_loss": 1.5797697305679321, "train_policy_loss": 2.519840955734253, "train_reward_loss": 0.21609556674957275, "train_chance_loss": 9.934712579706684e-06, "train_q_loss": 0.765234112739563, "train_vae_loss": 1.8683240341488272e-06, "train_lr": 0.0033204734791070223, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:07", "episode_count": 309, "remote_memory": 5070, "train_count": 4829, "episode_step": 38.0, "episode_time": 5.282812118530273, "eval_reward0": 0.8000000044703484, "episode_reward0": -0.47999996691942215, "step_time": 0.07261771904794793, "train_time": 0.06582324128401906, "train_loss": 5.276455402374268, "train_v_loss": 1.6767797470092773, "train_policy_loss": 2.575263261795044, "train_reward_loss": 0.19637319445610046, "train_chance_loss": 9.11724509933265e-06, "train_q_loss": 0.807476282119751, "train_vae_loss": 1.860185079749499e-06, "train_lr": 0.003304086159914732, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:09", "episode_count": 310, "remote_memory": 5080, "train_count": 4839, "episode_step": 10.0, "episode_time": 1.3776121139526367, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.640000008046627, "step_time": 0.07345666885375976, "train_time": 0.06339449882507324, "train_loss": 5.295870780944824, "train_v_loss": 1.6760555505752563, "train_policy_loss": 2.570345640182495, "train_reward_loss": 0.2307373285293579, "train_chance_loss": 1.1502366760396399e-05, "train_q_loss": 0.7981961369514465, "train_vae_loss": 1.851195747804013e-06, "train_lr": 0.003285867627710104, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:11", "episode_count": 311, "remote_memory": 5091, "train_count": 4850, "episode_step": 11.0, "episode_time": 1.5333056449890137, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07427048683166504, "train_time": 0.0642542839050293, "train_loss": 5.306550979614258, "train_v_loss": 1.6635277271270752, "train_policy_loss": 2.5960099697113037, "train_reward_loss": 0.23914460837841034, "train_chance_loss": 1.0480386663402896e-05, "train_q_loss": 0.7873926162719727, "train_vae_loss": 1.8472578631190117e-06, "train_lr": 0.003277933457866311, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:15", "episode_count": 312, "remote_memory": 5110, "train_count": 4869, "episode_step": 19.0, "episode_time": 2.604454278945923, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.2800000160932541, "step_time": 0.07193390946639211, "train_time": 0.06444808056480006, "train_loss": 5.220343112945557, "train_v_loss": 1.6265935897827148, "train_policy_loss": 2.5723390579223633, "train_reward_loss": 0.2263946533203125, "train_chance_loss": 1.042465737555176e-05, "train_q_loss": 0.7745919823646545, "train_vae_loss": 1.8416865259496262e-06, "train_lr": 0.003266633255407214, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:19", "episode_count": 313, "remote_memory": 5133, "train_count": 4892, "episode_step": 23.0, "episode_time": 3.4866323471069336, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.12000001966953278, "step_time": 0.07392781713734502, "train_time": 0.0769152019334876, "train_loss": 5.276120185852051, "train_v_loss": 1.6626107692718506, "train_policy_loss": 2.574627637863159, "train_reward_loss": 0.2107589989900589, "train_chance_loss": 1.5014445125416387e-05, "train_q_loss": 0.8076686859130859, "train_vae_loss": 1.8339418375035166e-06, "train_lr": 0.003250876907259226, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:21", "episode_count": 314, "remote_memory": 5151, "train_count": 4910, "episode_step": 18.0, "episode_time": 2.541173219680786, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.3200000151991844, "step_time": 0.07355381382836236, "train_time": 0.06710057788425022, "train_loss": 5.387871742248535, "train_v_loss": 1.7216994762420654, "train_policy_loss": 2.5764048099517822, "train_reward_loss": 0.22885733842849731, "train_chance_loss": 1.7219846995431e-05, "train_q_loss": 0.8406307101249695, "train_vae_loss": 1.8264288428326836e-06, "train_lr": 0.0032355664297938347, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:25", "episode_count": 315, "remote_memory": 5171, "train_count": 4930, "episode_step": 20.0, "episode_time": 2.825810194015503, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.24000001698732376, "step_time": 0.07460919618606568, "train_time": 0.06593981981277466, "train_loss": 5.26398229598999, "train_v_loss": 1.6544421911239624, "train_policy_loss": 2.5644564628601074, "train_reward_loss": 0.22015292942523956, "train_chance_loss": 1.5052637536427937e-05, "train_q_loss": 0.8046805262565613, "train_vae_loss": 1.8194845097241341e-06, "train_lr": 0.0032214424572885036, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:27", "episode_count": 316, "remote_memory": 5182, "train_count": 4941, "episode_step": 11.0, "episode_time": 1.5417141914367676, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.3999999910593033, "step_time": 0.07379063692959872, "train_time": 0.06554410674355247, "train_loss": 5.405904769897461, "train_v_loss": 1.722771406173706, "train_policy_loss": 2.606640100479126, "train_reward_loss": 0.2327648103237152, "train_chance_loss": 1.9855506252497435e-05, "train_q_loss": 0.8234062194824219, "train_vae_loss": 1.8138945279133623e-06, "train_lr": 0.0032099636737257242, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:28", "episode_count": 317, "remote_memory": 5189, "train_count": 4948, "episode_step": 7.0, "episode_time": 0.9717669486999512, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.760000005364418, "step_time": 0.07371272359575544, "train_time": 0.0644963128226144, "train_loss": 5.237907409667969, "train_v_loss": 1.6262098550796509, "train_policy_loss": 2.5671043395996094, "train_reward_loss": 0.23227658867835999, "train_chance_loss": 1.9851884644594975e-05, "train_q_loss": 0.791981041431427, "train_vae_loss": 1.8106131847162032e-06, "train_lr": 0.003203317988663912, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:30", "episode_count": 318, "remote_memory": 5194, "train_count": 4953, "episode_step": 5.0, "episode_time": 0.7050378322601318, "eval_reward0": 0.640000008046627, "episode_reward0": -1.1599999964237213, "step_time": 0.07351565361022949, "train_time": 0.06658005714416504, "train_loss": 5.265076637268066, "train_v_loss": 1.6287873983383179, "train_policy_loss": 2.605297565460205, "train_reward_loss": 0.21763458847999573, "train_chance_loss": 2.4849718101904728e-05, "train_q_loss": 0.7930717468261719, "train_vae_loss": 1.8084763269143878e-06, "train_lr": 0.0031988956034183502, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:34", "episode_count": 319, "remote_memory": 5224, "train_count": 4983, "episode_step": 30.0, "episode_time": 4.170398473739624, "eval_reward0": 0.8000000044703484, "episode_reward0": -0.15999997407197952, "step_time": 0.07304004033406576, "train_time": 0.06536965370178223, "train_loss": 5.350010871887207, "train_v_loss": 1.6984657049179077, "train_policy_loss": 2.5736355781555176, "train_reward_loss": 0.23605915904045105, "train_chance_loss": 1.887065445771441e-05, "train_q_loss": 0.8217264413833618, "train_vae_loss": 1.8022068388745538e-06, "train_lr": 0.003186037065461278, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:39", "episode_count": 320, "remote_memory": 5254, "train_count": 5013, "episode_step": 30.0, "episode_time": 4.055847883224487, "eval_reward0": 0.760000005364418, "episode_reward0": -0.15999997407197952, "step_time": 0.07209481398264567, "train_time": 0.06253100236256917, "train_loss": 5.254453659057617, "train_v_loss": 1.6420031785964966, "train_policy_loss": 2.570617198944092, "train_reward_loss": 0.23266683518886566, "train_chance_loss": 1.1975204870395828e-05, "train_q_loss": 0.789157509803772, "train_vae_loss": 1.7915310763783054e-06, "train_lr": 0.0031641051173210144, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:41", "episode_count": 321, "remote_memory": 5267, "train_count": 5026, "episode_step": 13.0, "episode_time": 1.82511305809021, "eval_reward0": 0.760000005364418, "episode_reward0": 0.5200000107288361, "step_time": 0.07364164865933932, "train_time": 0.06608423819908729, "train_loss": 5.275040626525879, "train_v_loss": 1.6466639041900635, "train_policy_loss": 2.5968058109283447, "train_reward_loss": 0.20981264114379883, "train_chance_loss": 9.996473636419978e-06, "train_q_loss": 0.8019108176231384, "train_vae_loss": 1.7839518022810807e-06, "train_lr": 0.0031484742648899555, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:45", "episode_count": 322, "remote_memory": 5285, "train_count": 5044, "episode_step": 18.0, "episode_time": 2.5281805992126465, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.3200000151991844, "step_time": 0.07373311784532335, "train_time": 0.06589280234442817, "train_loss": 5.365379333496094, "train_v_loss": 1.6846166849136353, "train_policy_loss": 2.6108357906341553, "train_reward_loss": 0.2323741316795349, "train_chance_loss": 1.1123001968371682e-05, "train_q_loss": 0.8178433775901794, "train_vae_loss": 1.778508362804132e-06, "train_lr": 0.003137258579954505, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:47", "episode_count": 323, "remote_memory": 5301, "train_count": 5060, "episode_step": 16.0, "episode_time": 2.1737194061279297, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.4000000134110451, "step_time": 0.07239390909671783, "train_time": 0.06292149424552917, "train_loss": 5.1846513748168945, "train_v_loss": 1.6272692680358887, "train_policy_loss": 2.5534451007843018, "train_reward_loss": 0.1932361125946045, "train_chance_loss": 9.767822120920755e-06, "train_q_loss": 0.790978193283081, "train_vae_loss": 1.7725784573485726e-06, "train_lr": 0.0031250016763806343, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:48", "episode_count": 324, "remote_memory": 5307, "train_count": 5066, "episode_step": 6.0, "episode_time": 0.86505126953125, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.8000000044703484, "step_time": 0.07445947329203288, "train_time": 0.0689930518468221, "train_loss": 5.092403411865234, "train_v_loss": 1.5659703016281128, "train_policy_loss": 2.5869548320770264, "train_reward_loss": 0.17864888906478882, "train_chance_loss": 9.447435331821907e-06, "train_q_loss": 0.7410652041435242, "train_vae_loss": 1.7687729041426792e-06, "train_lr": 0.0031170949805527925, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:51", "episode_count": 325, "remote_memory": 5317, "train_count": 5076, "episode_step": 10.0, "episode_time": 1.4271931648254395, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.640000008046627, "step_time": 0.07555081844329833, "train_time": 0.06628425121307373, "train_loss": 5.167837619781494, "train_v_loss": 1.605089545249939, "train_policy_loss": 2.570685625076294, "train_reward_loss": 0.1986246407032013, "train_chance_loss": 8.159211574820802e-06, "train_q_loss": 0.7736271023750305, "train_vae_loss": 1.7659925788393593e-06, "train_lr": 0.003111358964815736, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:53", "episode_count": 326, "remote_memory": 5328, "train_count": 5087, "episode_step": 11.0, "episode_time": 1.5210483074188232, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6000000089406967, "step_time": 0.07353821667757901, "train_time": 0.06395994533192027, "train_loss": 5.179895401000977, "train_v_loss": 1.6175564527511597, "train_policy_loss": 2.543718099594116, "train_reward_loss": 0.20793332159519196, "train_chance_loss": 1.0050946912087966e-05, "train_q_loss": 0.7909435033798218, "train_vae_loss": 1.762371198310575e-06, "train_lr": 0.0031038455199450254, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:58", "episode_count": 327, "remote_memory": 5361, "train_count": 5120, "episode_step": 33.0, "episode_time": 4.528034448623657, "eval_reward0": 0.8000000044703484, "episode_reward0": -0.2799999713897705, "step_time": 0.0730296481739391, "train_time": 0.06354924404259885, "train_loss": 5.302378177642822, "train_v_loss": 1.6802500486373901, "train_policy_loss": 2.557457685470581, "train_reward_loss": 0.2370203733444214, "train_chance_loss": 1.459343548049219e-05, "train_q_loss": 0.8080514669418335, "train_vae_loss": 1.7548143205203814e-06, "train_lr": 0.0030881690327078104, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:08:59", "episode_count": 328, "remote_memory": 5368, "train_count": 5127, "episode_step": 7.0, "episode_time": 0.9825301170349121, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.07475321633475167, "train_time": 0.06495472363063268, "train_loss": 5.293997764587402, "train_v_loss": 1.6576826572418213, "train_policy_loss": 2.5801196098327637, "train_reward_loss": 0.22641180455684662, "train_chance_loss": 2.195088927692268e-05, "train_q_loss": 0.8102809190750122, "train_vae_loss": 1.7480155065641156e-06, "train_lr": 0.0030739731155335903, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:02", "episode_count": 329, "remote_memory": 5381, "train_count": 5140, "episode_step": 13.0, "episode_time": 1.7973124980926514, "eval_reward0": 0.640000008046627, "episode_reward0": 0.5200000107288361, "step_time": 0.07331497852618878, "train_time": 0.06425171632033128, "train_loss": 5.2831501960754395, "train_v_loss": 1.6558233499526978, "train_policy_loss": 2.592602252960205, "train_reward_loss": 0.21498224139213562, "train_chance_loss": 1.9824614355457015e-05, "train_q_loss": 0.8002159595489502, "train_vae_loss": 1.7446001265852829e-06, "train_lr": 0.0030669039115309715, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:04", "episode_count": 330, "remote_memory": 5392, "train_count": 5151, "episode_step": 11.0, "episode_time": 1.5263478755950928, "eval_reward0": -1.6399999856948853, "episode_reward0": 0.6000000089406967, "step_time": 0.07341757687655362, "train_time": 0.06448925625194203, "train_loss": 5.202645301818848, "train_v_loss": 1.6039551496505737, "train_policy_loss": 2.572499990463257, "train_reward_loss": 0.2318304032087326, "train_chance_loss": 1.8349059246247634e-05, "train_q_loss": 0.7748878002166748, "train_vae_loss": 1.740541961225972e-06, "train_lr": 0.0030584412161260843, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:07", "episode_count": 331, "remote_memory": 5408, "train_count": 5167, "episode_step": 16.0, "episode_time": 2.233121395111084, "eval_reward0": 0.760000005364418, "episode_reward0": 0.4000000134110451, "step_time": 0.07380585372447968, "train_time": 0.065151646733284, "train_loss": 5.404586315155029, "train_v_loss": 1.7350554466247559, "train_policy_loss": 2.5858397483825684, "train_reward_loss": 0.2270667850971222, "train_chance_loss": 1.572095789015293e-05, "train_q_loss": 0.8371292948722839, "train_vae_loss": 1.7360034689772874e-06, "train_lr": 0.003048949409276247, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:09", "episode_count": 332, "remote_memory": 5417, "train_count": 5176, "episode_step": 9.0, "episode_time": 1.258878231048584, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6800000071525574, "step_time": 0.07551492585076226, "train_time": 0.06348027123345269, "train_loss": 5.232048988342285, "train_v_loss": 1.6658297777175903, "train_policy_loss": 2.547987222671509, "train_reward_loss": 0.1940145492553711, "train_chance_loss": 1.3373977708397433e-05, "train_q_loss": 0.8046268820762634, "train_vae_loss": 1.7317953506790218e-06, "train_lr": 0.0030401854310184717, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:11", "episode_count": 333, "remote_memory": 5431, "train_count": 5190, "episode_step": 14.0, "episode_time": 1.9566116333007812, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.48000001162290573, "step_time": 0.07372823783329555, "train_time": 0.06524785927363805, "train_loss": 5.2545928955078125, "train_v_loss": 1.6360094547271729, "train_policy_loss": 2.6073086261749268, "train_reward_loss": 0.2070898711681366, "train_chance_loss": 9.26328903005924e-06, "train_q_loss": 0.7845280766487122, "train_vae_loss": 1.7279829762628651e-06, "train_lr": 0.0030321464873850346, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:13", "episode_count": 334, "remote_memory": 5437, "train_count": 5196, "episode_step": 6.0, "episode_time": 0.8268492221832275, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.8000000044703484, "step_time": 0.07388341426849365, "train_time": 0.0631856123606364, "train_loss": 5.02876615524292, "train_v_loss": 1.5488510131835938, "train_policy_loss": 2.53633713722229, "train_reward_loss": 0.19308634102344513, "train_chance_loss": 8.154728675435763e-06, "train_q_loss": 0.7308799624443054, "train_vae_loss": 1.7246139805138228e-06, "train_lr": 0.0030251715797930956, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:14", "episode_count": 335, "remote_memory": 5447, "train_count": 5206, "episode_step": 10.0, "episode_time": 1.3671138286590576, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.640000008046627, "step_time": 0.0726388692855835, "train_time": 0.0636213779449463, "train_loss": 5.244160175323486, "train_v_loss": 1.6683984994888306, "train_policy_loss": 2.557904005050659, "train_reward_loss": 0.2125260829925537, "train_chance_loss": 1.0998664947692305e-05, "train_q_loss": 0.7856647372245789, "train_vae_loss": 1.7219733763340628e-06, "train_lr": 0.003019605064764619, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:17", "episode_count": 336, "remote_memory": 5461, "train_count": 5220, "episode_step": 14.0, "episode_time": 1.9531960487365723, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.5199999883770943, "step_time": 0.07311247076307024, "train_time": 0.0657425948551723, "train_loss": 5.377832889556885, "train_v_loss": 1.718794822692871, "train_policy_loss": 2.581632137298584, "train_reward_loss": 0.23622430860996246, "train_chance_loss": 1.2558667549456004e-05, "train_q_loss": 0.8215063810348511, "train_vae_loss": 1.7180219629153726e-06, "train_lr": 0.003011273220181465, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:18", "episode_count": 337, "remote_memory": 5467, "train_count": 5226, "episode_step": 6.0, "episode_time": 0.8420238494873047, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.8000000044703484, "step_time": 0.07404061158498128, "train_time": 0.06551969051361084, "train_loss": 5.341800212860107, "train_v_loss": 1.6667653322219849, "train_policy_loss": 2.571582794189453, "train_reward_loss": 0.2704450190067291, "train_chance_loss": 1.8635477317729965e-05, "train_q_loss": 0.813452959060669, "train_vae_loss": 1.7146998061434715e-06, "train_lr": 0.003004346741363406, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:23", "episode_count": 338, "remote_memory": 5491, "train_count": 5250, "episode_step": 24.0, "episode_time": 3.474975109100342, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.08000002056360245, "step_time": 0.07407260934511821, "train_time": 0.06996805469195048, "train_loss": 5.220122814178467, "train_v_loss": 1.6396675109863281, "train_policy_loss": 2.5557873249053955, "train_reward_loss": 0.21347610652446747, "train_chance_loss": 1.9693790818564594e-05, "train_q_loss": 0.7916811108589172, "train_vae_loss": 1.7097785303121782e-06, "train_lr": 0.0029939913656562567, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:24", "episode_count": 339, "remote_memory": 5498, "train_count": 5257, "episode_step": 7.0, "episode_time": 0.9679632186889648, "eval_reward0": -1.239999994635582, "episode_reward0": 0.760000005364418, "step_time": 0.07511769022260394, "train_time": 0.0625239440373012, "train_loss": 5.479759693145752, "train_v_loss": 1.7982033491134644, "train_policy_loss": 2.6023595333099365, "train_reward_loss": 0.20293357968330383, "train_chance_loss": 1.5493167666136287e-05, "train_q_loss": 0.8567380309104919, "train_vae_loss": 1.7047219671439962e-06, "train_lr": 0.002983321202918887, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:25", "episode_count": 340, "remote_memory": 5505, "train_count": 5264, "episode_step": 7.0, "episode_time": 1.0123746395111084, "eval_reward0": 0.760000005364418, "episode_reward0": 0.760000005364418, "step_time": 0.0776528971535819, "train_time": 0.0661982808794294, "train_loss": 5.341560363769531, "train_v_loss": 1.7084283828735352, "train_policy_loss": 2.568727493286133, "train_reward_loss": 0.20882181823253632, "train_chance_loss": 1.9492128558340482e-05, "train_q_loss": 0.8361387252807617, "train_vae_loss": 1.7024136695908965e-06, "train_lr": 0.002978516975417733, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:26", "episode_count": 341, "remote_memory": 5513, "train_count": 5272, "episode_step": 8.0, "episode_time": 1.0840070247650146, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.7200000062584877, "step_time": 0.07244294881820679, "train_time": 0.06250327825546265, "train_loss": 5.340403079986572, "train_v_loss": 1.7084295749664307, "train_policy_loss": 2.5952086448669434, "train_reward_loss": 0.20658530294895172, "train_chance_loss": 1.6229445463977754e-05, "train_q_loss": 0.8107852339744568, "train_vae_loss": 1.7000135130729177e-06, "train_lr": 0.0029733774717897177, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:29", "episode_count": 342, "remote_memory": 5521, "train_count": 5280, "episode_step": 8.0, "episode_time": 1.1128931045532227, "eval_reward0": 0.4000000134110451, "episode_reward0": 0.7200000062584877, "step_time": 0.07400625944137573, "train_time": 0.06454804539680481, "train_loss": 5.188871383666992, "train_v_loss": 1.6148426532745361, "train_policy_loss": 2.5818166732788086, "train_reward_loss": 0.19143232703208923, "train_chance_loss": 1.1398576134524774e-05, "train_q_loss": 0.7813044190406799, "train_vae_loss": 1.6973849596979562e-06, "train_lr": 0.0029679052531719208, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:31", "episode_count": 343, "remote_memory": 5535, "train_count": 5294, "episode_step": 14.0, "episode_time": 1.8916995525360107, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.48000001162290573, "step_time": 0.07229491642543248, "train_time": 0.062188540186200826, "train_loss": 5.3139777183532715, "train_v_loss": 1.7263180017471313, "train_policy_loss": 2.5594639778137207, "train_reward_loss": 0.180977463722229, "train_chance_loss": 7.73909778217785e-06, "train_q_loss": 0.8276821970939636, "train_vae_loss": 1.6938445241976297e-06, "train_lr": 0.0029603985603898764, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:37", "episode_count": 344, "remote_memory": 5563, "train_count": 5322, "episode_step": 28.0, "episode_time": 3.8242008686065674, "eval_reward0": 0.08000002056360245, "episode_reward0": -0.07999997586011887, "step_time": 0.07201385498046875, "train_time": 0.06391306434358869, "train_loss": 5.380190372467041, "train_v_loss": 1.722814679145813, "train_policy_loss": 2.5899174213409424, "train_reward_loss": 0.22184717655181885, "train_chance_loss": 1.1545359484443907e-05, "train_q_loss": 0.8262391090393066, "train_vae_loss": 1.6870789067979786e-06, "train_lr": 0.002946122083812952, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:39", "episode_count": 345, "remote_memory": 5576, "train_count": 5335, "episode_step": 13.0, "episode_time": 1.7811830043792725, "eval_reward0": 0.760000005364418, "episode_reward0": -1.479999989271164, "step_time": 0.07188105583190918, "train_time": 0.0644983328305758, "train_loss": 5.281326770782471, "train_v_loss": 1.6706538200378418, "train_policy_loss": 2.583134889602661, "train_reward_loss": 0.2026912271976471, "train_chance_loss": 1.0806344107550103e-05, "train_q_loss": 0.8054279685020447, "train_vae_loss": 1.6805449831736041e-06, "train_lr": 0.002932244213297963, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:41", "episode_count": 346, "remote_memory": 5584, "train_count": 5343, "episode_step": 8.0, "episode_time": 1.1312904357910156, "eval_reward0": 0.760000005364418, "episode_reward0": -1.2799999937415123, "step_time": 0.07384660840034485, "train_time": 0.06690219044685364, "train_loss": 5.400034427642822, "train_v_loss": 1.7335866689682007, "train_policy_loss": 2.5722146034240723, "train_reward_loss": 0.24452680349349976, "train_chance_loss": 1.1913644812011626e-05, "train_q_loss": 0.830344557762146, "train_vae_loss": 1.677190994087141e-06, "train_lr": 0.0029251629021018744, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:43", "episode_count": 347, "remote_memory": 5598, "train_count": 5357, "episode_step": 14.0, "episode_time": 1.972151279449463, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.48000001162290573, "step_time": 0.07405897549220494, "train_time": 0.0661501373563494, "train_loss": 5.362275123596191, "train_v_loss": 1.7184752225875854, "train_policy_loss": 2.5652718544006348, "train_reward_loss": 0.22368226945400238, "train_chance_loss": 1.4200481928128283e-05, "train_q_loss": 0.8356925845146179, "train_vae_loss": 1.6737233181629563e-06, "train_lr": 0.002917764475569129, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:44", "episode_count": 348, "remote_memory": 5603, "train_count": 5362, "episode_step": 5.0, "episode_time": 0.7161960601806641, "eval_reward0": 0.640000008046627, "episode_reward0": 0.8400000035762787, "step_time": 0.07450313568115234, "train_time": 0.06775913238525391, "train_loss": 5.3472371101379395, "train_v_loss": 1.708298921585083, "train_policy_loss": 2.5580968856811523, "train_reward_loss": 0.24156400561332703, "train_chance_loss": 1.6401949324063025e-05, "train_q_loss": 0.8202970623970032, "train_vae_loss": 1.6707266468074522e-06, "train_lr": 0.002911387477070093, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:49", "episode_count": 349, "remote_memory": 5620, "train_count": 5379, "episode_step": 17.0, "episode_time": 2.3141868114471436, "eval_reward0": -0.2799999713897705, "episode_reward0": 0.36000001430511475, "step_time": 0.07230852631961598, "train_time": 0.06308254073647891, "train_loss": 5.294222831726074, "train_v_loss": 1.6629009246826172, "train_policy_loss": 2.5613155364990234, "train_reward_loss": 0.24991077184677124, "train_chance_loss": 1.6060195775935426e-05, "train_q_loss": 0.801127552986145, "train_vae_loss": 1.6672222500346834e-06, "train_lr": 0.002904024673625827, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:51", "episode_count": 350, "remote_memory": 5627, "train_count": 5386, "episode_step": 7.0, "episode_time": 1.001450777053833, "eval_reward0": 0.760000005364418, "episode_reward0": 0.760000005364418, "step_time": 0.07430846350533622, "train_time": 0.06801124981471471, "train_loss": 5.38167142868042, "train_v_loss": 1.7243794202804565, "train_policy_loss": 2.579620122909546, "train_reward_loss": 0.2207096666097641, "train_chance_loss": 1.0540544280956965e-05, "train_q_loss": 0.8379701375961304, "train_vae_loss": 1.6634952544336556e-06, "train_lr": 0.0028960101772099733, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:53", "episode_count": 351, "remote_memory": 5636, "train_count": 5395, "episode_step": 9.0, "episode_time": 1.2668251991271973, "eval_reward0": 0.4000000134110451, "episode_reward0": 0.6800000071525574, "step_time": 0.07506884468926324, "train_time": 0.06477668550279406, "train_loss": 5.2905097007751465, "train_v_loss": 1.6478655338287354, "train_policy_loss": 2.5959177017211914, "train_reward_loss": 0.22359201312065125, "train_chance_loss": 8.924220310291275e-06, "train_q_loss": 0.804178774356842, "train_vae_loss": 1.660957877902547e-06, "train_lr": 0.002890680218115449, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:57", "episode_count": 352, "remote_memory": 5658, "train_count": 5417, "episode_step": 22.0, "episode_time": 3.0273585319519043, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.1600000187754631, "step_time": 0.07236719131469727, "train_time": 0.06465050307187167, "train_loss": 5.260474681854248, "train_v_loss": 1.642961859703064, "train_policy_loss": 2.5633676052093506, "train_reward_loss": 0.23742324113845825, "train_chance_loss": 1.0985687367792707e-05, "train_q_loss": 0.7976898550987244, "train_vae_loss": 1.6561400570935803e-06, "train_lr": 0.0028803846798837185, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:09:58", "episode_count": 353, "remote_memory": 5665, "train_count": 5424, "episode_step": 7.0, "episode_time": 0.9736859798431396, "eval_reward0": 0.760000005364418, "episode_reward0": 0.760000005364418, "step_time": 0.0743093490600586, "train_time": 0.06417662756783622, "train_loss": 5.371895790100098, "train_v_loss": 1.7343990802764893, "train_policy_loss": 2.5870730876922607, "train_reward_loss": 0.20217712223529816, "train_chance_loss": 1.1170703146490268e-05, "train_q_loss": 0.8291690945625305, "train_vae_loss": 1.6516921732545597e-06, "train_lr": 0.0028707808814942837, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:03", "episode_count": 354, "remote_memory": 5690, "train_count": 5449, "episode_step": 25.0, "episode_time": 3.48587965965271, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.04000002145767212, "step_time": 0.07368106842041015, "train_time": 0.06507739067077636, "train_loss": 5.1772050857543945, "train_v_loss": 1.6327098608016968, "train_policy_loss": 2.5405654907226562, "train_reward_loss": 0.201766699552536, "train_chance_loss": 1.0785583981487434e-05, "train_q_loss": 0.7831065654754639, "train_vae_loss": 1.6466979104734492e-06, "train_lr": 0.0028602275997400284, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:06", "episode_count": 355, "remote_memory": 5714, "train_count": 5473, "episode_step": 24.0, "episode_time": 3.229045867919922, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.08000002056360245, "step_time": 0.07203121980031331, "train_time": 0.06198700269063314, "train_loss": 5.161702632904053, "train_v_loss": 1.5908282995224, "train_policy_loss": 2.5741183757781982, "train_reward_loss": 0.21532778441905975, "train_chance_loss": 9.902550118567888e-06, "train_q_loss": 0.7623246312141418, "train_vae_loss": 1.6391746839872212e-06, "train_lr": 0.0028441371396183968, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:08", "episode_count": 356, "remote_memory": 5727, "train_count": 5486, "episode_step": 13.0, "episode_time": 1.79665207862854, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.5200000107288361, "step_time": 0.07311556889460637, "train_time": 0.06433857404268704, "train_loss": 5.285159587860107, "train_v_loss": 1.6869231462478638, "train_policy_loss": 2.5612058639526367, "train_reward_loss": 0.1982967108488083, "train_chance_loss": 1.3792931895295624e-05, "train_q_loss": 0.8196367025375366, "train_vae_loss": 1.6335520740540233e-06, "train_lr": 0.0028320448473095894, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:11", "episode_count": 357, "remote_memory": 5746, "train_count": 5505, "episode_step": 19.0, "episode_time": 2.6259446144104004, "eval_reward0": 0.760000005364418, "episode_reward0": 0.2800000160932541, "step_time": 0.0728110388705605, "train_time": 0.06472775810643246, "train_loss": 5.228674411773682, "train_v_loss": 1.6292333602905273, "train_policy_loss": 2.562243700027466, "train_reward_loss": 0.2298755645751953, "train_chance_loss": 1.5452302250196226e-05, "train_q_loss": 0.7883636951446533, "train_vae_loss": 1.6286901427520206e-06, "train_lr": 0.0028216319624334574, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:15", "episode_count": 358, "remote_memory": 5765, "train_count": 5524, "episode_step": 19.0, "episode_time": 2.661886215209961, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.2800000160932541, "step_time": 0.07349430887322676, "train_time": 0.06587988451907509, "train_loss": 5.285307884216309, "train_v_loss": 1.6823328733444214, "train_policy_loss": 2.572932004928589, "train_reward_loss": 0.20972689986228943, "train_chance_loss": 1.4237829418561887e-05, "train_q_loss": 0.80141681432724, "train_vae_loss": 1.6229421362368157e-06, "train_lr": 0.0028093140572309494, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:18", "episode_count": 359, "remote_memory": 5783, "train_count": 5542, "episode_step": 18.0, "episode_time": 2.5562963485717773, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.3200000151991844, "step_time": 0.07451421684688991, "train_time": 0.06670671039157444, "train_loss": 5.174993515014648, "train_v_loss": 1.6341551542282104, "train_policy_loss": 2.5375003814697266, "train_reward_loss": 0.2052573412656784, "train_chance_loss": 1.2277451787667815e-05, "train_q_loss": 0.7790921926498413, "train_vae_loss": 1.6174064967344748e-06, "train_lr": 0.002797372406348586, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:22", "episode_count": 360, "remote_memory": 5815, "train_count": 5574, "episode_step": 32.0, "episode_time": 4.592495679855347, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.23999997228384018, "step_time": 0.07481356710195541, "train_time": 0.06814459711313248, "train_loss": 5.259378433227539, "train_v_loss": 1.6731138229370117, "train_policy_loss": 2.555375099182129, "train_reward_loss": 0.2096875011920929, "train_chance_loss": 1.169872484751977e-05, "train_q_loss": 0.8021816611289978, "train_vae_loss": 1.6099581898743054e-06, "train_lr": 0.0027813201304525137, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:25", "episode_count": 361, "remote_memory": 5831, "train_count": 5590, "episode_step": 16.0, "episode_time": 2.229759454727173, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.599999986588955, "step_time": 0.07312144339084625, "train_time": 0.06561075150966644, "train_loss": 5.1994524002075195, "train_v_loss": 1.6117480993270874, "train_policy_loss": 2.5635833740234375, "train_reward_loss": 0.22281260788440704, "train_chance_loss": 1.4088302123127505e-05, "train_q_loss": 0.7822903990745544, "train_vae_loss": 1.602863108018937e-06, "train_lr": 0.0027659875340759754, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:27", "episode_count": 362, "remote_memory": 5844, "train_count": 5603, "episode_step": 13.0, "episode_time": 1.824228286743164, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.5200000107288361, "step_time": 0.07387161254882812, "train_time": 0.06573189221895658, "train_loss": 5.129046440124512, "train_v_loss": 1.5920952558517456, "train_policy_loss": 2.5006608963012695, "train_reward_loss": 0.23522138595581055, "train_chance_loss": 1.630499173188582e-05, "train_q_loss": 0.7821675539016724, "train_vae_loss": 1.59857472681324e-06, "train_lr": 0.002756767440587282, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:30", "episode_count": 363, "remote_memory": 5860, "train_count": 5619, "episode_step": 16.0, "episode_time": 2.2134366035461426, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.07288208603858948, "train_time": 0.06484478712081909, "train_loss": 5.358743667602539, "train_v_loss": 1.7228223085403442, "train_policy_loss": 2.546165943145752, "train_reward_loss": 0.2198142409324646, "train_chance_loss": 2.279464933963027e-05, "train_q_loss": 0.8511205315589905, "train_vae_loss": 1.594334094079386e-06, "train_lr": 0.002747579477727413, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:33", "episode_count": 364, "remote_memory": 5878, "train_count": 5637, "episode_step": 18.0, "episode_time": 2.5036141872406006, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.3200000151991844, "step_time": 0.07317597336239284, "train_time": 0.06518273883395725, "train_loss": 5.279855728149414, "train_v_loss": 1.659278154373169, "train_policy_loss": 2.5947108268737793, "train_reward_loss": 0.19684329628944397, "train_chance_loss": 1.9592589524108917e-05, "train_q_loss": 0.8103328943252563, "train_vae_loss": 1.5893913314357633e-06, "train_lr": 0.0027368455193936825, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:34", "episode_count": 365, "remote_memory": 5885, "train_count": 5644, "episode_step": 7.0, "episode_time": 1.0087780952453613, "eval_reward0": 0.760000005364418, "episode_reward0": -1.239999994635582, "step_time": 0.07495488439287458, "train_time": 0.06841795785086495, "train_loss": 5.262485027313232, "train_v_loss": 1.6447906494140625, "train_policy_loss": 2.58699107170105, "train_reward_loss": 0.2107093334197998, "train_chance_loss": 1.4994007869972847e-05, "train_q_loss": 0.8012161254882812, "train_vae_loss": 1.5857812059039134e-06, "train_lr": 0.0027289781719446182, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:37", "episode_count": 366, "remote_memory": 5899, "train_count": 5658, "episode_step": 14.0, "episode_time": 1.9773633480072021, "eval_reward0": 0.760000005364418, "episode_reward0": 0.48000001162290573, "step_time": 0.07371536323002406, "train_time": 0.06687818254743304, "train_loss": 5.314426898956299, "train_v_loss": 1.6857608556747437, "train_policy_loss": 2.593731641769409, "train_reward_loss": 0.1963619887828827, "train_chance_loss": 1.0083972483698744e-05, "train_q_loss": 0.8196597099304199, "train_vae_loss": 1.5827206425456097e-06, "train_lr": 0.00272238883189857, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:39", "episode_count": 367, "remote_memory": 5909, "train_count": 5668, "episode_step": 10.0, "episode_time": 1.3887939453125, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.359999991953373, "step_time": 0.07251102924346924, "train_time": 0.06542572975158692, "train_loss": 5.434566974639893, "train_v_loss": 1.751965880393982, "train_policy_loss": 2.5944457054138184, "train_reward_loss": 0.24473047256469727, "train_chance_loss": 1.0769185792014468e-05, "train_q_loss": 0.8244360089302063, "train_vae_loss": 1.5792817293913686e-06, "train_lr": 0.0027148767840117216, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:40", "episode_count": 368, "remote_memory": 5914, "train_count": 5673, "episode_step": 5.0, "episode_time": 0.7093093395233154, "eval_reward0": 0.760000005364418, "episode_reward0": 0.8400000035762787, "step_time": 0.07431378364562988, "train_time": 0.06672177314758301, "train_loss": 5.43295955657959, "train_v_loss": 1.7670520544052124, "train_policy_loss": 2.5716710090637207, "train_reward_loss": 0.21300768852233887, "train_chance_loss": 1.4716582882101648e-05, "train_q_loss": 0.862278938293457, "train_vae_loss": 1.5771154266985832e-06, "train_lr": 0.0027101917658001184, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:44", "episode_count": 369, "remote_memory": 5937, "train_count": 5696, "episode_step": 23.0, "episode_time": 3.1790058612823486, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.8799999803304672, "step_time": 0.07300697202267854, "train_time": 0.06461765455163043, "train_loss": 5.301987171173096, "train_v_loss": 1.6751819849014282, "train_policy_loss": 2.577670097351074, "train_reward_loss": 0.2139098197221756, "train_chance_loss": 1.7158608898171224e-05, "train_q_loss": 0.816448450088501, "train_vae_loss": 1.5731113762740279e-06, "train_lr": 0.002701472258195281, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:48", "episode_count": 370, "remote_memory": 5966, "train_count": 5725, "episode_step": 29.0, "episode_time": 4.021638870239258, "eval_reward0": 0.8000000044703484, "episode_reward0": -0.1199999749660492, "step_time": 0.07410324853042076, "train_time": 0.0639421035503519, "train_loss": 5.340454578399658, "train_v_loss": 1.708571195602417, "train_policy_loss": 2.572084665298462, "train_reward_loss": 0.20857149362564087, "train_chance_loss": 1.1437788089097012e-05, "train_q_loss": 0.8324508666992188, "train_vae_loss": 1.565706952533219e-06, "train_lr": 0.002685349667444825, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:50", "episode_count": 371, "remote_memory": 5977, "train_count": 5736, "episode_step": 11.0, "episode_time": 1.505418062210083, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.0728980844671076, "train_time": 0.06317047639326616, "train_loss": 5.300485134124756, "train_v_loss": 1.6740800142288208, "train_policy_loss": 2.573385238647461, "train_reward_loss": 0.21664738655090332, "train_chance_loss": 1.0442419807077385e-05, "train_q_loss": 0.817781388759613, "train_vae_loss": 1.5600580809405074e-06, "train_lr": 0.00267300708219409, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:53", "episode_count": 372, "remote_memory": 5992, "train_count": 5751, "episode_step": 15.0, "episode_time": 2.077929973602295, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.4400000125169754, "step_time": 0.07323228518168132, "train_time": 0.0647150198618571, "train_loss": 5.158051013946533, "train_v_loss": 1.5916727781295776, "train_policy_loss": 2.5555343627929688, "train_reward_loss": 0.22676950693130493, "train_chance_loss": 1.0149770787393209e-05, "train_q_loss": 0.7655729055404663, "train_vae_loss": 1.5563761053272174e-06, "train_lr": 0.002665018429979682, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:55", "episode_count": 373, "remote_memory": 6005, "train_count": 5764, "episode_step": 13.0, "episode_time": 1.863464117050171, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.5200000107288361, "step_time": 0.07485710657559909, "train_time": 0.06778927949758676, "train_loss": 5.311984539031982, "train_v_loss": 1.6798895597457886, "train_policy_loss": 2.561732292175293, "train_reward_loss": 0.2292591780424118, "train_chance_loss": 8.749361768423114e-06, "train_q_loss": 0.8225335478782654, "train_vae_loss": 1.5524826721957652e-06, "train_lr": 0.0026564409490674734, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:10:59", "episode_count": 374, "remote_memory": 6023, "train_count": 5782, "episode_step": 18.0, "episode_time": 2.595123291015625, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.6799999848008156, "step_time": 0.07666099071502686, "train_time": 0.0667688184314304, "train_loss": 5.2600998878479, "train_v_loss": 1.655038595199585, "train_policy_loss": 2.565800666809082, "train_reward_loss": 0.2236340343952179, "train_chance_loss": 1.1820473446277902e-05, "train_q_loss": 0.7971832156181335, "train_vae_loss": 1.5481468835787382e-06, "train_lr": 0.002646978013217449, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:00", "episode_count": 375, "remote_memory": 6030, "train_count": 5789, "episode_step": 7.0, "episode_time": 0.9845409393310547, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.07425805500575475, "train_time": 0.06571156638009208, "train_loss": 5.3205342292785645, "train_v_loss": 1.704426884651184, "train_policy_loss": 2.566182851791382, "train_reward_loss": 0.2080778330564499, "train_chance_loss": 8.657643775222823e-06, "train_q_loss": 0.8233298063278198, "train_vae_loss": 1.5446585166500881e-06, "train_lr": 0.0026393686421215534, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:02", "episode_count": 376, "remote_memory": 6041, "train_count": 5800, "episode_step": 11.0, "episode_time": 1.516061544418335, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.3999999910593033, "step_time": 0.07189867713234642, "train_time": 0.06509490446610884, "train_loss": 5.188337326049805, "train_v_loss": 1.616775631904602, "train_policy_loss": 2.5730645656585693, "train_reward_loss": 0.20560003817081451, "train_chance_loss": 8.246498509834055e-06, "train_q_loss": 0.7743951678276062, "train_vae_loss": 1.5421802572745946e-06, "train_lr": 0.0026339052710682154, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:05", "episode_count": 377, "remote_memory": 6058, "train_count": 5817, "episode_step": 17.0, "episode_time": 2.332127332687378, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.6399999856948853, "step_time": 0.07105013903449564, "train_time": 0.06541219879599179, "train_loss": 5.217404842376709, "train_v_loss": 1.6176625490188599, "train_policy_loss": 2.5625011920928955, "train_reward_loss": 0.21356923878192902, "train_chance_loss": 1.0976999874401372e-05, "train_q_loss": 0.8052269220352173, "train_vae_loss": 1.538325818728481e-06, "train_lr": 0.0026254290714859962, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:06", "episode_count": 378, "remote_memory": 6066, "train_count": 5825, "episode_step": 8.0, "episode_time": 1.0981683731079102, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.7200000062584877, "step_time": 0.07343697547912598, "train_time": 0.06320950388908386, "train_loss": 5.189908027648926, "train_v_loss": 1.6057047843933105, "train_policy_loss": 2.54587984085083, "train_reward_loss": 0.23936861753463745, "train_chance_loss": 1.3047972970525734e-05, "train_q_loss": 0.7805962562561035, "train_vae_loss": 1.5348841770901345e-06, "train_lr": 0.0026178820990025997, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:08", "episode_count": 379, "remote_memory": 6073, "train_count": 5832, "episode_step": 7.0, "episode_time": 0.9391593933105469, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.760000005364418, "step_time": 0.07205874579293388, "train_time": 0.06152282442365374, "train_loss": 5.250587463378906, "train_v_loss": 1.6692367792129517, "train_policy_loss": 2.5503649711608887, "train_reward_loss": 0.22657833993434906, "train_chance_loss": 1.7501670299679972e-05, "train_q_loss": 0.7860288619995117, "train_vae_loss": 1.5328349718402023e-06, "train_lr": 0.002613364951685071, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:10", "episode_count": 380, "remote_memory": 6080, "train_count": 5839, "episode_step": 7.0, "episode_time": 0.9668409824371338, "eval_reward0": 0.24000001698732376, "episode_reward0": -1.239999994635582, "step_time": 0.07163957187107631, "train_time": 0.06588843890598842, "train_loss": 5.445774078369141, "train_v_loss": 1.7823257446289062, "train_policy_loss": 2.541647434234619, "train_reward_loss": 0.24743211269378662, "train_chance_loss": 1.870867890829686e-05, "train_q_loss": 0.8559980392456055, "train_vae_loss": 1.530910367364413e-06, "train_lr": 0.00260915607213974, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:16", "episode_count": 381, "remote_memory": 6118, "train_count": 5877, "episode_step": 38.0, "episode_time": 5.227917432785034, "eval_reward0": 0.8400000035762787, "episode_reward0": -0.47999996691942215, "step_time": 0.07249099957315545, "train_time": 0.06451388409263209, "train_loss": 5.269435405731201, "train_v_loss": 1.6558104753494263, "train_policy_loss": 2.552130699157715, "train_reward_loss": 0.24043452739715576, "train_chance_loss": 1.7813601516536437e-05, "train_q_loss": 0.8028826713562012, "train_vae_loss": 1.5247850342348102e-06, "train_lr": 0.0025956809986382723, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:18", "episode_count": 382, "remote_memory": 6128, "train_count": 5887, "episode_step": 10.0, "episode_time": 1.3430752754211426, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.640000008046627, "step_time": 0.07160675525665283, "train_time": 0.061814618110656736, "train_loss": 5.405603408813477, "train_v_loss": 1.7625911235809326, "train_policy_loss": 2.573289394378662, "train_reward_loss": 0.20595505833625793, "train_chance_loss": 1.2717527170025278e-05, "train_q_loss": 0.8457167744636536, "train_vae_loss": 1.5182773722699494e-06, "train_lr": 0.002581368898972869, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:20", "episode_count": 383, "remote_memory": 6145, "train_count": 5904, "episode_step": 17.0, "episode_time": 2.3650588989257812, "eval_reward0": 0.5600000098347664, "episode_reward0": 0.36000001430511475, "step_time": 0.07370187254513011, "train_time": 0.06486974043004654, "train_loss": 5.253666400909424, "train_v_loss": 1.6466541290283203, "train_policy_loss": 2.5788938999176025, "train_reward_loss": 0.2122020572423935, "train_chance_loss": 1.2617462743946817e-05, "train_q_loss": 0.7979560494422913, "train_vae_loss": 1.5146732721404987e-06, "train_lr": 0.0025733583606779575, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:22", "episode_count": 384, "remote_memory": 6153, "train_count": 5912, "episode_step": 8.0, "episode_time": 1.1321368217468262, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.7200000062584877, "step_time": 0.07599669694900513, "train_time": 0.0649203360080719, "train_loss": 5.293413162231445, "train_v_loss": 1.6981585025787354, "train_policy_loss": 2.5743227005004883, "train_reward_loss": 0.17907601594924927, "train_chance_loss": 1.1569014532142319e-05, "train_q_loss": 0.8238441944122314, "train_vae_loss": 1.5112560731722624e-06, "train_lr": 0.0025659610982984304, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:23", "episode_count": 385, "remote_memory": 6158, "train_count": 5917, "episode_step": 5.0, "episode_time": 0.7194290161132812, "eval_reward0": 0.760000005364418, "episode_reward0": 0.8400000035762787, "step_time": 0.0751370906829834, "train_time": 0.06784310340881347, "train_loss": 5.325049877166748, "train_v_loss": 1.7249031066894531, "train_policy_loss": 2.533923625946045, "train_reward_loss": 0.22637979686260223, "train_chance_loss": 1.0478596777829807e-05, "train_q_loss": 0.8217899203300476, "train_vae_loss": 1.509562252977048e-06, "train_lr": 0.00256212311796844, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:25", "episode_count": 386, "remote_memory": 6168, "train_count": 5927, "episode_step": 10.0, "episode_time": 1.3853468894958496, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.640000008046627, "step_time": 0.07455320358276367, "train_time": 0.06312398910522461, "train_loss": 5.323173522949219, "train_v_loss": 1.6895363330841064, "train_policy_loss": 2.5795350074768066, "train_reward_loss": 0.21930952370166779, "train_chance_loss": 7.784421541146003e-06, "train_q_loss": 0.816730797290802, "train_vae_loss": 1.5075760302352137e-06, "train_lr": 0.0025577028281986713, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:27", "episode_count": 387, "remote_memory": 6179, "train_count": 5938, "episode_step": 11.0, "episode_time": 1.482060194015503, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07221195914528587, "train_time": 0.06210938366976651, "train_loss": 5.231258869171143, "train_v_loss": 1.6400532722473145, "train_policy_loss": 2.586482048034668, "train_reward_loss": 0.2186434119939804, "train_chance_loss": 7.871257366787177e-06, "train_q_loss": 0.7680249810218811, "train_vae_loss": 1.5047659189804108e-06, "train_lr": 0.002551526762545109, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:30", "episode_count": 388, "remote_memory": 6200, "train_count": 5959, "episode_step": 21.0, "episode_time": 3.1007401943206787, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.20000001788139343, "step_time": 0.0734319913954962, "train_time": 0.07356362115769159, "train_loss": 5.220574378967285, "train_v_loss": 1.6318951845169067, "train_policy_loss": 2.5737485885620117, "train_reward_loss": 0.20396623015403748, "train_chance_loss": 8.873361366568133e-06, "train_q_loss": 0.7928123474121094, "train_vae_loss": 1.5005280147306621e-06, "train_lr": 0.0025421457830816507, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:32", "episode_count": 389, "remote_memory": 6206, "train_count": 5965, "episode_step": 6.0, "episode_time": 0.8222286701202393, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.8000000044703484, "step_time": 0.07295600573221843, "train_time": 0.06334646542867024, "train_loss": 5.255194187164307, "train_v_loss": 1.5867277383804321, "train_policy_loss": 2.609487771987915, "train_reward_loss": 0.26280221343040466, "train_chance_loss": 8.232959771703463e-06, "train_q_loss": 0.7780424952507019, "train_vae_loss": 1.4969859876146074e-06, "train_lr": 0.002534253289923072, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:33", "episode_count": 390, "remote_memory": 6211, "train_count": 5970, "episode_step": 5.0, "episode_time": 0.6976101398468018, "eval_reward0": 0.760000005364418, "episode_reward0": 0.8400000035762787, "step_time": 0.0741809368133545, "train_time": 0.06450877189636231, "train_loss": 5.3589277267456055, "train_v_loss": 1.7322676181793213, "train_policy_loss": 2.562300205230713, "train_reward_loss": 0.22729019820690155, "train_chance_loss": 9.642642908147536e-06, "train_q_loss": 0.8190056085586548, "train_vae_loss": 1.495535229878442e-06, "train_lr": 0.00253104604780674, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:35", "episode_count": 391, "remote_memory": 6222, "train_count": 5981, "episode_step": 11.0, "episode_time": 1.5502257347106934, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6000000089406967, "step_time": 0.0759225541895086, "train_time": 0.06425580111416904, "train_loss": 5.280423641204834, "train_v_loss": 1.6805481910705566, "train_policy_loss": 2.5763113498687744, "train_reward_loss": 0.20321913063526154, "train_chance_loss": 1.2788048479706049e-05, "train_q_loss": 0.8023353815078735, "train_vae_loss": 1.493436911914614e-06, "train_lr": 0.002526388270780444, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:37", "episode_count": 392, "remote_memory": 6231, "train_count": 5990, "episode_step": 9.0, "episode_time": 1.256932020187378, "eval_reward0": 0.4400000125169754, "episode_reward0": 0.6800000071525574, "step_time": 0.07435353597005208, "train_time": 0.06471806102328831, "train_loss": 5.065296649932861, "train_v_loss": 1.5819042921066284, "train_policy_loss": 2.498835563659668, "train_reward_loss": 0.21279634535312653, "train_chance_loss": 1.1519554391270503e-05, "train_q_loss": 0.7536923289299011, "train_vae_loss": 1.4908102912158938e-06, "train_lr": 0.0025205775164067745, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:40", "episode_count": 393, "remote_memory": 6244, "train_count": 6003, "episode_step": 13.0, "episode_time": 1.8337664604187012, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.479999989271164, "step_time": 0.07491060403677133, "train_time": 0.06540689101585975, "train_loss": 5.052680015563965, "train_v_loss": 1.5779564380645752, "train_policy_loss": 2.485779047012329, "train_reward_loss": 0.21166890859603882, "train_chance_loss": 1.2752676411764696e-05, "train_q_loss": 0.7591571807861328, "train_vae_loss": 1.4879283298796508e-06, "train_lr": 0.0025142019148916006, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:42", "episode_count": 394, "remote_memory": 6254, "train_count": 6013, "episode_step": 10.0, "episode_time": 1.4219610691070557, "eval_reward0": 0.640000008046627, "episode_reward0": 0.640000008046627, "step_time": 0.07562205791473389, "train_time": 0.0655940294265747, "train_loss": 5.226798057556152, "train_v_loss": 1.6366277933120728, "train_policy_loss": 2.5824217796325684, "train_reward_loss": 0.1876235157251358, "train_chance_loss": 1.2689235518337227e-05, "train_q_loss": 0.8019814491271973, "train_vae_loss": 1.4849342733214144e-06, "train_lr": 0.002507552970200777, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:45", "episode_count": 395, "remote_memory": 6267, "train_count": 6026, "episode_step": 13.0, "episode_time": 1.781963586807251, "eval_reward0": -1.4399999901652336, "episode_reward0": 0.5200000107288361, "step_time": 0.07243420527531551, "train_time": 0.06394092853252704, "train_loss": 5.25695276260376, "train_v_loss": 1.6632137298583984, "train_policy_loss": 2.5443408489227295, "train_reward_loss": 0.2114812433719635, "train_chance_loss": 1.3734465028392151e-05, "train_q_loss": 0.8198877573013306, "train_vae_loss": 1.4819502212048974e-06, "train_lr": 0.002500922419130802, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:47", "episode_count": 396, "remote_memory": 6280, "train_count": 6039, "episode_step": 13.0, "episode_time": 1.7962756156921387, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.5200000107288361, "step_time": 0.07458725342383751, "train_time": 0.06293014379648063, "train_loss": 5.275230884552002, "train_v_loss": 1.6678611040115356, "train_policy_loss": 2.571439266204834, "train_reward_loss": 0.2175971120595932, "train_chance_loss": 1.538108153908979e-05, "train_q_loss": 0.800503671169281, "train_vae_loss": 1.4785838402531226e-06, "train_lr": 0.0024934469256550074, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:51", "episode_count": 397, "remote_memory": 6304, "train_count": 6063, "episode_step": 24.0, "episode_time": 3.3157758712768555, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.08000002056360245, "step_time": 0.07288151979446411, "train_time": 0.06471022963523865, "train_loss": 5.290224552154541, "train_v_loss": 1.6835269927978516, "train_policy_loss": 2.558950185775757, "train_reward_loss": 0.2149890661239624, "train_chance_loss": 1.5719379007350653e-05, "train_q_loss": 0.8147463202476501, "train_vae_loss": 1.4738416211912408e-06, "train_lr": 0.0024828503374010324, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:53", "episode_count": 398, "remote_memory": 6316, "train_count": 6075, "episode_step": 12.0, "episode_time": 1.639122724533081, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.5600000098347664, "step_time": 0.07374370098114014, "train_time": 0.062131146589914955, "train_loss": 5.1827073097229, "train_v_loss": 1.6049951314926147, "train_policy_loss": 2.5824553966522217, "train_reward_loss": 0.20434634387493134, "train_chance_loss": 1.1308850844216067e-05, "train_q_loss": 0.772621214389801, "train_vae_loss": 1.4692230934088002e-06, "train_lr": 0.0024725787807255983, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:54", "episode_count": 399, "remote_memory": 6323, "train_count": 6082, "episode_step": 7.0, "episode_time": 0.989574670791626, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.760000005364418, "step_time": 0.07361340522766113, "train_time": 0.06711724826267787, "train_loss": 5.335376739501953, "train_v_loss": 1.723318099975586, "train_policy_loss": 2.572409152984619, "train_reward_loss": 0.18426330387592316, "train_chance_loss": 1.2287192475923803e-05, "train_q_loss": 0.8370382189750671, "train_vae_loss": 1.4668008816443034e-06, "train_lr": 0.002467175479978323, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:11:56", "episode_count": 400, "remote_memory": 6329, "train_count": 6088, "episode_step": 6.0, "episode_time": 0.8438756465911865, "eval_reward0": -1.2799999937415123, "episode_reward0": -1.1999999955296516, "step_time": 0.07248632113138835, "train_time": 0.06743359565734863, "train_loss": 5.303483963012695, "train_v_loss": 1.6095738410949707, "train_policy_loss": 2.6072633266448975, "train_reward_loss": 0.24951189756393433, "train_chance_loss": 1.2469921784941107e-05, "train_q_loss": 0.818779468536377, "train_vae_loss": 1.4651576520918752e-06, "train_lr": 0.0024634855799376965, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:00", "episode_count": 401, "remote_memory": 6354, "train_count": 6113, "episode_step": 25.0, "episode_time": 3.4606878757476807, "eval_reward0": 0.640000008046627, "episode_reward0": 0.04000002145767212, "step_time": 0.07314116477966309, "train_time": 0.06459228515625, "train_loss": 5.351435661315918, "train_v_loss": 1.7322136163711548, "train_policy_loss": 2.5396692752838135, "train_reward_loss": 0.21433573961257935, "train_chance_loss": 1.5942945537972264e-05, "train_q_loss": 0.8469188809394836, "train_vae_loss": 1.4612061249863473e-06, "train_lr": 0.002454712288454175, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:04", "episode_count": 402, "remote_memory": 6373, "train_count": 6132, "episode_step": 19.0, "episode_time": 2.7394604682922363, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.2800000160932541, "step_time": 0.07292310815108449, "train_time": 0.07057981742055792, "train_loss": 5.244019985198975, "train_v_loss": 1.6638473272323608, "train_policy_loss": 2.548943519592285, "train_reward_loss": 0.2099219411611557, "train_chance_loss": 1.3259812476462685e-05, "train_q_loss": 0.8031785488128662, "train_vae_loss": 1.4556671885657124e-06, "train_lr": 0.002442307537421584, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:05", "episode_count": 403, "remote_memory": 6382, "train_count": 6141, "episode_step": 9.0, "episode_time": 1.265024185180664, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6800000071525574, "step_time": 0.07480888896518284, "train_time": 0.06520387861463758, "train_loss": 5.236637592315674, "train_v_loss": 1.6684716939926147, "train_policy_loss": 2.539797782897949, "train_reward_loss": 0.20886534452438354, "train_chance_loss": 8.966435416368768e-06, "train_q_loss": 0.8013709187507629, "train_vae_loss": 1.452149149372417e-06, "train_lr": 0.0024344457779079676, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:07", "episode_count": 404, "remote_memory": 6394, "train_count": 6153, "episode_step": 12.0, "episode_time": 1.6776540279388428, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.5600000098347664, "step_time": 0.07410051425298055, "train_time": 0.06495630741119385, "train_loss": 5.230044841766357, "train_v_loss": 1.6620835065841675, "train_policy_loss": 2.5010054111480713, "train_reward_loss": 0.2447161227464676, "train_chance_loss": 8.640257874503732e-06, "train_q_loss": 0.8042054176330566, "train_vae_loss": 1.4495581126539037e-06, "train_lr": 0.002428567036986351, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:09", "episode_count": 405, "remote_memory": 6406, "train_count": 6165, "episode_step": 12.0, "episode_time": 1.6726176738739014, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.5600000098347664, "step_time": 0.07365479071935017, "train_time": 0.06488907337188721, "train_loss": 5.362271785736084, "train_v_loss": 1.7492218017578125, "train_policy_loss": 2.54620099067688, "train_reward_loss": 0.20939452946186066, "train_chance_loss": 1.5195652849797625e-05, "train_q_loss": 0.8395385146141052, "train_vae_loss": 1.4465146023212583e-06, "train_lr": 0.0024218664038926363, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:11", "episode_count": 406, "remote_memory": 6413, "train_count": 6172, "episode_step": 7.0, "episode_time": 0.9899828433990479, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.07457358496529716, "train_time": 0.06610931668962751, "train_loss": 5.244177341461182, "train_v_loss": 1.6568777561187744, "train_policy_loss": 2.5687012672424316, "train_reward_loss": 0.20141346752643585, "train_chance_loss": 1.537071875645779e-05, "train_q_loss": 0.7992035746574402, "train_vae_loss": 1.4442370002143434e-06, "train_lr": 0.0024165736977010965, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:13", "episode_count": 407, "remote_memory": 6427, "train_count": 6186, "episode_step": 14.0, "episode_time": 1.9648616313934326, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.48000001162290573, "step_time": 0.07386572020394462, "train_time": 0.06580676351274763, "train_loss": 5.3495612144470215, "train_v_loss": 1.6856005191802979, "train_policy_loss": 2.565636396408081, "train_reward_loss": 0.26322847604751587, "train_chance_loss": 9.12383256945759e-06, "train_q_loss": 0.8169693946838379, "train_vae_loss": 1.4415639952858328e-06, "train_lr": 0.002410739194601774, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:15", "episode_count": 408, "remote_memory": 6434, "train_count": 6193, "episode_step": 7.0, "episode_time": 0.981715202331543, "eval_reward0": 0.760000005364418, "episode_reward0": 0.760000005364418, "step_time": 0.07296974318368095, "train_time": 0.06652014596121651, "train_loss": 5.127182960510254, "train_v_loss": 1.5704940557479858, "train_policy_loss": 2.5155274868011475, "train_reward_loss": 0.25601717829704285, "train_chance_loss": 1.0594827472232282e-05, "train_q_loss": 0.767021656036377, "train_vae_loss": 1.4389612488230341e-06, "train_lr": 0.002404916798695922, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:17", "episode_count": 409, "remote_memory": 6449, "train_count": 6208, "episode_step": 15.0, "episode_time": 2.090961217880249, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.4400000125169754, "step_time": 0.07301222483317057, "train_time": 0.06568522453308105, "train_loss": 5.120711326599121, "train_v_loss": 1.597192645072937, "train_policy_loss": 2.522866725921631, "train_reward_loss": 0.2155909538269043, "train_chance_loss": 1.0438368917675689e-05, "train_q_loss": 0.7668845057487488, "train_vae_loss": 1.4362526599143166e-06, "train_lr": 0.002398834330961108, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:21", "episode_count": 410, "remote_memory": 6466, "train_count": 6225, "episode_step": 17.0, "episode_time": 2.285464286804199, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.36000001430511475, "step_time": 0.07152232001809512, "train_time": 0.06221692702349495, "train_loss": 5.238942623138428, "train_v_loss": 1.6230908632278442, "train_policy_loss": 2.5688440799713135, "train_reward_loss": 0.24870236217975616, "train_chance_loss": 1.2103377230232581e-05, "train_q_loss": 0.7801169157028198, "train_vae_loss": 1.4323693449114216e-06, "train_lr": 0.0023900133091956377, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:23", "episode_count": 411, "remote_memory": 6483, "train_count": 6242, "episode_step": 17.0, "episode_time": 2.3337621688842773, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.36000001430511475, "step_time": 0.07307170419132009, "train_time": 0.0636893300449147, "train_loss": 5.111688613891602, "train_v_loss": 1.572449803352356, "train_policy_loss": 2.5344691276550293, "train_reward_loss": 0.22401946783065796, "train_chance_loss": 1.1102353710157331e-05, "train_q_loss": 0.7626054286956787, "train_vae_loss": 1.4281786206993274e-06, "train_lr": 0.002380675869062543, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:26", "episode_count": 412, "remote_memory": 6494, "train_count": 6253, "episode_step": 11.0, "episode_time": 1.523705005645752, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07398113337430087, "train_time": 0.06375778805125844, "train_loss": 5.300360202789307, "train_v_loss": 1.6908851861953735, "train_policy_loss": 2.5520005226135254, "train_reward_loss": 0.2261473685503006, "train_chance_loss": 1.2419587619660888e-05, "train_q_loss": 0.8131412267684937, "train_vae_loss": 1.4247980288928375e-06, "train_lr": 0.0023730131797492504, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:28", "episode_count": 413, "remote_memory": 6506, "train_count": 6265, "episode_step": 12.0, "episode_time": 1.6629891395568848, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.5600000098347664, "step_time": 0.07305586338043213, "train_time": 0.06481520334879558, "train_loss": 5.418436050415039, "train_v_loss": 1.7435470819473267, "train_policy_loss": 2.541231632232666, "train_reward_loss": 0.2504160404205322, "train_chance_loss": 1.2970379430043977e-05, "train_q_loss": 0.8650543093681335, "train_vae_loss": 1.4219918966773548e-06, "train_lr": 0.0023667376954108477, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:30", "episode_count": 414, "remote_memory": 6519, "train_count": 6278, "episode_step": 13.0, "episode_time": 1.8260424137115479, "eval_reward0": 0.760000005364418, "episode_reward0": 0.5200000107288361, "step_time": 0.07303485503563514, "train_time": 0.06671944031348595, "train_loss": 5.237762451171875, "train_v_loss": 1.6354396343231201, "train_policy_loss": 2.5477731227874756, "train_reward_loss": 0.23288656771183014, "train_chance_loss": 1.6632215192657895e-05, "train_q_loss": 0.8036385178565979, "train_vae_loss": 1.4189906778483419e-06, "train_lr": 0.0023599355481565, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:32", "episode_count": 415, "remote_memory": 6529, "train_count": 6288, "episode_step": 10.0, "episode_time": 1.4958021640777588, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.359999991953373, "step_time": 0.07202687263488769, "train_time": 0.07663204669952392, "train_loss": 5.318892478942871, "train_v_loss": 1.66012704372406, "train_policy_loss": 2.5823986530303955, "train_reward_loss": 0.2349422425031662, "train_chance_loss": 1.2663886082009412e-05, "train_q_loss": 0.8233916163444519, "train_vae_loss": 1.4162056913846754e-06, "train_lr": 0.002353694522753358, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:33", "episode_count": 416, "remote_memory": 6536, "train_count": 6295, "episode_step": 7.0, "episode_time": 1.0052616596221924, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.0739912646157401, "train_time": 0.06889568056379046, "train_loss": 5.355551719665527, "train_v_loss": 1.7292054891586304, "train_policy_loss": 2.5353169441223145, "train_reward_loss": 0.24269859492778778, "train_chance_loss": 1.5224913113343064e-05, "train_q_loss": 0.8303810954093933, "train_vae_loss": 1.4141845667836606e-06, "train_lr": 0.002349092159420252, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:36", "episode_count": 417, "remote_memory": 6551, "train_count": 6310, "episode_step": 15.0, "episode_time": 2.054704427719116, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.4400000125169754, "step_time": 0.07229913075764974, "train_time": 0.06405423482259115, "train_loss": 5.306578636169434, "train_v_loss": 1.6918319463729858, "train_policy_loss": 2.550642251968384, "train_reward_loss": 0.23774071037769318, "train_chance_loss": 1.4241218195820693e-05, "train_q_loss": 0.8084418773651123, "train_vae_loss": 1.4115355497779092e-06, "train_lr": 0.0023431507870554924, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:40", "episode_count": 418, "remote_memory": 6567, "train_count": 6326, "episode_step": 16.0, "episode_time": 2.246316432952881, "eval_reward0": 0.3200000151991844, "episode_reward0": 0.4000000134110451, "step_time": 0.07445287704467773, "train_time": 0.06512570381164551, "train_loss": 5.229543209075928, "train_v_loss": 1.6487122774124146, "train_policy_loss": 2.552791118621826, "train_reward_loss": 0.21968728303909302, "train_chance_loss": 9.433915693080053e-06, "train_q_loss": 0.7904002666473389, "train_vae_loss": 1.407843001288711e-06, "train_lr": 0.0023348028771579266, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:42", "episode_count": 419, "remote_memory": 6579, "train_count": 6338, "episode_step": 12.0, "episode_time": 1.6491694450378418, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.5600000098347664, "step_time": 0.07283981641133626, "train_time": 0.06390500068664551, "train_loss": 5.374271869659424, "train_v_loss": 1.7397189140319824, "train_policy_loss": 2.565901517868042, "train_reward_loss": 0.1975851207971573, "train_chance_loss": 1.1756527783290949e-05, "train_q_loss": 0.8531752228736877, "train_vae_loss": 1.4045194802747574e-06, "train_lr": 0.002327288268133998, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:49", "episode_count": 420, "remote_memory": 6619, "train_count": 6378, "episode_step": 40.0, "episode_time": 5.498944044113159, "eval_reward0": -0.23999997228384018, "episode_reward0": -0.5599999651312828, "step_time": 0.07204710841178893, "train_time": 0.064857017993927, "train_loss": 5.280855655670166, "train_v_loss": 1.675574541091919, "train_policy_loss": 2.5602993965148926, "train_reward_loss": 0.2141367495059967, "train_chance_loss": 1.5751482351333834e-05, "train_q_loss": 0.8131868243217468, "train_vae_loss": 1.3983852795718121e-06, "train_lr": 0.0023134041111916304, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:52", "episode_count": 421, "remote_memory": 6628, "train_count": 6387, "episode_step": 9.0, "episode_time": 1.262465000152588, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6800000071525574, "step_time": 0.07413856188456218, "train_time": 0.06516851319207086, "train_loss": 5.146289348602295, "train_v_loss": 1.5756765604019165, "train_policy_loss": 2.6095876693725586, "train_reward_loss": 0.18481633067131042, "train_chance_loss": 9.330684406450018e-06, "train_q_loss": 0.7585780024528503, "train_vae_loss": 1.3926538713349146e-06, "train_lr": 0.0023003825917840004, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:54", "episode_count": 422, "remote_memory": 6644, "train_count": 6403, "episode_step": 16.0, "episode_time": 2.194633722305298, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.4000000134110451, "step_time": 0.0735175758600235, "train_time": 0.06311655044555664, "train_loss": 5.186241626739502, "train_v_loss": 1.6557841300964355, "train_policy_loss": 2.5172059535980225, "train_reward_loss": 0.19382894039154053, "train_chance_loss": 7.00313103152439e-06, "train_q_loss": 0.8017849326133728, "train_vae_loss": 1.3897220014769118e-06, "train_lr": 0.002293771831318736, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:56", "episode_count": 423, "remote_memory": 6654, "train_count": 6413, "episode_step": 10.0, "episode_time": 1.3556745052337646, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.640000008046627, "step_time": 0.07235090732574463, "train_time": 0.06242856979370117, "train_loss": 5.278199195861816, "train_v_loss": 1.664449691772461, "train_policy_loss": 2.5238986015319824, "train_reward_loss": 0.26480135321617126, "train_chance_loss": 1.0511384061828721e-05, "train_q_loss": 0.8075096011161804, "train_vae_loss": 1.3866927019989816e-06, "train_lr": 0.002286915434524417, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:57", "episode_count": 424, "remote_memory": 6661, "train_count": 6420, "episode_step": 7.0, "episode_time": 0.9468169212341309, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.07340257508414132, "train_time": 0.06126931735447475, "train_loss": 5.317203998565674, "train_v_loss": 1.6771972179412842, "train_policy_loss": 2.58420729637146, "train_reward_loss": 0.2244921773672104, "train_chance_loss": 1.064804382622242e-05, "train_q_loss": 0.813850998878479, "train_vae_loss": 1.3847072750650113e-06, "train_lr": 0.0022824432235211134, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:12:59", "episode_count": 425, "remote_memory": 6672, "train_count": 6431, "episode_step": 11.0, "episode_time": 1.5286037921905518, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07379302111538974, "train_time": 0.06433148817582564, "train_loss": 5.268185615539551, "train_v_loss": 1.6803432703018188, "train_policy_loss": 2.5446410179138184, "train_reward_loss": 0.21346759796142578, "train_chance_loss": 1.3904975276091136e-05, "train_q_loss": 0.8123564124107361, "train_vae_loss": 1.3826662552673952e-06, "train_lr": 0.0022777188569307327, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:01", "episode_count": 426, "remote_memory": 6685, "train_count": 6444, "episode_step": 13.0, "episode_time": 1.7851228713989258, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.479999989271164, "step_time": 0.07198401597829965, "train_time": 0.06464044864361103, "train_loss": 5.29475736618042, "train_v_loss": 1.704417109489441, "train_policy_loss": 2.5441854000091553, "train_reward_loss": 0.20263297855854034, "train_chance_loss": 1.076505668606842e-05, "train_q_loss": 0.8261598348617554, "train_vae_loss": 1.3798679674437153e-06, "train_lr": 0.002271434059366584, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:04", "episode_count": 427, "remote_memory": 6700, "train_count": 6459, "episode_step": 15.0, "episode_time": 2.054175615310669, "eval_reward0": 0.2800000160932541, "episode_reward0": 0.4400000125169754, "step_time": 0.07263542811075846, "train_time": 0.06373262405395508, "train_loss": 5.312403202056885, "train_v_loss": 1.7054966688156128, "train_policy_loss": 2.5405077934265137, "train_reward_loss": 0.22035305202007294, "train_chance_loss": 1.058688030752819e-05, "train_q_loss": 0.8286510109901428, "train_vae_loss": 1.3766738220510888e-06, "train_lr": 0.002264124108478427, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:08", "episode_count": 428, "remote_memory": 6723, "train_count": 6482, "episode_step": 23.0, "episode_time": 3.1796345710754395, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.12000001966953278, "step_time": 0.07274153958196225, "train_time": 0.06490873253863791, "train_loss": 5.28621768951416, "train_v_loss": 1.6845914125442505, "train_policy_loss": 2.5358290672302246, "train_reward_loss": 0.23951499164104462, "train_chance_loss": 1.282063931284938e-05, "train_q_loss": 0.8089656829833984, "train_vae_loss": 1.3723271194976405e-06, "train_lr": 0.002254241844639182, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:10", "episode_count": 429, "remote_memory": 6732, "train_count": 6491, "episode_step": 9.0, "episode_time": 1.2126977443695068, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6800000071525574, "step_time": 0.07268563906351726, "train_time": 0.061183028750949435, "train_loss": 5.221807956695557, "train_v_loss": 1.65248441696167, "train_policy_loss": 2.556788682937622, "train_reward_loss": 0.20515680313110352, "train_chance_loss": 1.0305895557394251e-05, "train_q_loss": 0.7900415658950806, "train_vae_loss": 1.368699258819106e-06, "train_lr": 0.002245950046926737, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:11", "episode_count": 430, "remote_memory": 6743, "train_count": 6502, "episode_step": 11.0, "episode_time": 1.4656732082366943, "eval_reward0": 0.760000005364418, "episode_reward0": -1.3999999910593033, "step_time": 0.07223432714288885, "train_time": 0.06062176010825417, "train_loss": 5.336426734924316, "train_v_loss": 1.7292784452438354, "train_policy_loss": 2.490644931793213, "train_reward_loss": 0.2462858259677887, "train_chance_loss": 9.924927326210309e-06, "train_q_loss": 0.8528606295585632, "train_vae_loss": 1.3663978961631074e-06, "train_lr": 0.002240784466266632, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:16", "episode_count": 431, "remote_memory": 6767, "train_count": 6526, "episode_step": 24.0, "episode_time": 3.4844295978546143, "eval_reward0": 0.4000000134110451, "episode_reward0": -1.9199999794363976, "step_time": 0.07123744487762451, "train_time": 0.07328048348426819, "train_loss": 5.239628314971924, "train_v_loss": 1.6512404680252075, "train_policy_loss": 2.5743274688720703, "train_reward_loss": 0.20891451835632324, "train_chance_loss": 1.1837851161544677e-05, "train_q_loss": 0.7878134846687317, "train_vae_loss": 1.3624663779410184e-06, "train_lr": 0.002231775550171733, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:18", "episode_count": 432, "remote_memory": 6778, "train_count": 6537, "episode_step": 11.0, "episode_time": 1.5095131397247314, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07246704535050826, "train_time": 0.06397750160910866, "train_loss": 5.195002555847168, "train_v_loss": 1.628991961479187, "train_policy_loss": 2.5703604221343994, "train_reward_loss": 0.2020101398229599, "train_chance_loss": 1.0810232197400182e-05, "train_q_loss": 0.7762245535850525, "train_vae_loss": 1.3585319038611487e-06, "train_lr": 0.002222798764705658, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:19", "episode_count": 433, "remote_memory": 6783, "train_count": 6542, "episode_step": 5.0, "episode_time": 0.710517406463623, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.8400000035762787, "step_time": 0.07491831779479981, "train_time": 0.06621050834655762, "train_loss": 5.555371284484863, "train_v_loss": 1.8396899700164795, "train_policy_loss": 2.587730646133423, "train_reward_loss": 0.1974138766527176, "train_chance_loss": 1.2430713468347676e-05, "train_q_loss": 0.9131004214286804, "train_vae_loss": 1.3567521364166168e-06, "train_lr": 0.0022187072318047285, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:22", "episode_count": 434, "remote_memory": 6793, "train_count": 6552, "episode_step": 10.0, "episode_time": 1.430300235748291, "eval_reward0": 0.760000005364418, "episode_reward0": 0.640000008046627, "step_time": 0.07648050785064697, "train_time": 0.0656125545501709, "train_loss": 5.210559844970703, "train_v_loss": 1.6430095434188843, "train_policy_loss": 2.545961856842041, "train_reward_loss": 0.20768503844738007, "train_chance_loss": 1.1422622264944948e-05, "train_q_loss": 0.7965120077133179, "train_vae_loss": 1.3550830999520258e-06, "train_lr": 0.0022148792631924152, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:24", "episode_count": 435, "remote_memory": 6806, "train_count": 6565, "episode_step": 13.0, "episode_time": 1.7672011852264404, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.5200000107288361, "step_time": 0.07199384615971492, "train_time": 0.06329545607933632, "train_loss": 5.123130798339844, "train_v_loss": 1.5863744020462036, "train_policy_loss": 2.5160939693450928, "train_reward_loss": 0.23571684956550598, "train_chance_loss": 1.0619482054607943e-05, "train_q_loss": 0.7676100134849548, "train_vae_loss": 1.3524945643439423e-06, "train_lr": 0.002209022641181946, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:26", "episode_count": 436, "remote_memory": 6824, "train_count": 6583, "episode_step": 18.0, "episode_time": 2.4324543476104736, "eval_reward0": 0.8400000035762787, "episode_reward0": -1.6799999848008156, "step_time": 0.07202144463857015, "train_time": 0.06260809633466932, "train_loss": 5.225092887878418, "train_v_loss": 1.670959711074829, "train_policy_loss": 2.5455431938171387, "train_reward_loss": 0.1942543089389801, "train_chance_loss": 1.2164451618446037e-05, "train_q_loss": 0.797074019908905, "train_vae_loss": 1.349064746136719e-06, "train_lr": 0.0022011534310877323, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:31", "episode_count": 437, "remote_memory": 6849, "train_count": 6608, "episode_step": 25.0, "episode_time": 3.5218148231506348, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.04000002145767212, "step_time": 0.07338542938232422, "train_time": 0.06672646522521973, "train_loss": 5.316570281982422, "train_v_loss": 1.687037467956543, "train_policy_loss": 2.560347080230713, "train_reward_loss": 0.25057169795036316, "train_chance_loss": 1.3196910913393367e-05, "train_q_loss": 0.8014872074127197, "train_vae_loss": 1.3443142279356834e-06, "train_lr": 0.0021902848966419697, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:34", "episode_count": 438, "remote_memory": 6871, "train_count": 6630, "episode_step": 22.0, "episode_time": 3.0990095138549805, "eval_reward0": 0.760000005364418, "episode_reward0": 0.1600000187754631, "step_time": 0.07437195561148903, "train_time": 0.06588159907947887, "train_loss": 5.275894641876221, "train_v_loss": 1.6665148735046387, "train_policy_loss": 2.5401880741119385, "train_reward_loss": 0.23717285692691803, "train_chance_loss": 1.3483316251949873e-05, "train_q_loss": 0.8151088953018188, "train_vae_loss": 1.339139771516784e-06, "train_lr": 0.0021784643176943064, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:36", "episode_count": 439, "remote_memory": 6882, "train_count": 6641, "episode_step": 11.0, "episode_time": 1.7329137325286865, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6000000089406967, "step_time": 0.07357863946394487, "train_time": 0.0831316817890514, "train_loss": 5.182306289672852, "train_v_loss": 1.6133102178573608, "train_policy_loss": 2.5676236152648926, "train_reward_loss": 0.22176875174045563, "train_chance_loss": 1.1708355486916844e-05, "train_q_loss": 0.7626262903213501, "train_vae_loss": 1.3355867167774704e-06, "train_lr": 0.002170201623812318, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:37", "episode_count": 440, "remote_memory": 6888, "train_count": 6647, "episode_step": 6.0, "episode_time": 0.809363842010498, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.8000000044703484, "step_time": 0.0733402172724406, "train_time": 0.06085944175720215, "train_loss": 5.10746955871582, "train_v_loss": 1.581690788269043, "train_policy_loss": 2.5472896099090576, "train_reward_loss": 0.1887010931968689, "train_chance_loss": 1.0453252798470203e-05, "train_q_loss": 0.7727065682411194, "train_vae_loss": 1.3337416930880863e-06, "train_lr": 0.0021659580525010824, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:38", "episode_count": 441, "remote_memory": 6893, "train_count": 6652, "episode_step": 5.0, "episode_time": 0.7059731483459473, "eval_reward0": 0.760000005364418, "episode_reward0": 0.8400000035762787, "step_time": 0.07444376945495605, "train_time": 0.06577754020690918, "train_loss": 5.329533576965332, "train_v_loss": 1.6742851734161377, "train_policy_loss": 2.566934108734131, "train_reward_loss": 0.24426054954528809, "train_chance_loss": 9.127033990807831e-06, "train_q_loss": 0.8269166946411133, "train_vae_loss": 1.332494662165118e-06, "train_lr": 0.0021632167045027018, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:42", "episode_count": 442, "remote_memory": 6910, "train_count": 6669, "episode_step": 17.0, "episode_time": 2.3371329307556152, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.36000001430511475, "step_time": 0.07305192947387695, "train_time": 0.06366743760950425, "train_loss": 5.2133049964904785, "train_v_loss": 1.648127555847168, "train_policy_loss": 2.54995059967041, "train_reward_loss": 0.2015426903963089, "train_chance_loss": 9.416300599696115e-06, "train_q_loss": 0.7965765595436096, "train_vae_loss": 1.33012190417503e-06, "train_lr": 0.002157745882868767, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:43", "episode_count": 443, "remote_memory": 6921, "train_count": 6680, "episode_step": 11.0, "episode_time": 1.5052464008331299, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.3999999910593033, "step_time": 0.0723265517841686, "train_time": 0.0640970143404874, "train_loss": 5.319932460784912, "train_v_loss": 1.7595587968826294, "train_policy_loss": 2.491826057434082, "train_reward_loss": 0.21174722909927368, "train_chance_loss": 1.4192171875038184e-05, "train_q_loss": 0.8397810459136963, "train_vae_loss": 1.327064410361345e-06, "train_lr": 0.002150800311937928, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:45", "episode_count": 444, "remote_memory": 6928, "train_count": 6687, "episode_step": 7.0, "episode_time": 0.9696452617645264, "eval_reward0": -1.5599999874830246, "episode_reward0": 0.760000005364418, "step_time": 0.07374266215733119, "train_time": 0.06415690694536481, "train_loss": 5.222541809082031, "train_v_loss": 1.6382144689559937, "train_policy_loss": 2.5629429817199707, "train_reward_loss": 0.20645438134670258, "train_chance_loss": 1.607324338692706e-05, "train_q_loss": 0.7979570627212524, "train_vae_loss": 1.3252114285933203e-06, "train_lr": 0.0021463476587086916, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:47", "episode_count": 445, "remote_memory": 6935, "train_count": 6694, "episode_step": 7.0, "episode_time": 0.9841201305389404, "eval_reward0": -1.119999997317791, "episode_reward0": 0.760000005364418, "step_time": 0.07477545738220215, "train_time": 0.06515475681849889, "train_loss": 5.250287055969238, "train_v_loss": 1.6449459791183472, "train_policy_loss": 2.5767149925231934, "train_reward_loss": 0.2196570485830307, "train_chance_loss": 1.5678360796300694e-05, "train_q_loss": 0.7920397520065308, "train_vae_loss": 1.3236005997896427e-06, "train_lr": 0.0021428908221423626, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:48", "episode_count": 446, "remote_memory": 6941, "train_count": 6700, "episode_step": 6.0, "episode_time": 0.8387739658355713, "eval_reward0": 0.760000005364418, "episode_reward0": 0.8000000044703484, "step_time": 0.07453044255574544, "train_time": 0.06455107529958089, "train_loss": 5.118106842041016, "train_v_loss": 1.5846666097640991, "train_policy_loss": 2.5559792518615723, "train_reward_loss": 0.2021305412054062, "train_chance_loss": 1.011548829410458e-05, "train_q_loss": 0.7584366798400879, "train_vae_loss": 1.3222806956036948e-06, "train_lr": 0.0021396861411631107, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:51", "episode_count": 447, "remote_memory": 6958, "train_count": 6717, "episode_step": 17.0, "episode_time": 2.3565356731414795, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.36000001430511475, "step_time": 0.07257914543151855, "train_time": 0.0652154613943661, "train_loss": 5.205326080322266, "train_v_loss": 1.6377633810043335, "train_policy_loss": 2.554360866546631, "train_reward_loss": 0.20131191611289978, "train_chance_loss": 8.555522981623653e-06, "train_q_loss": 0.7949644327163696, "train_vae_loss": 1.3197995940572582e-06, "train_lr": 0.002134028822183609, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:53", "episode_count": 448, "remote_memory": 6969, "train_count": 6728, "episode_step": 11.0, "episode_time": 1.5215461254119873, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6000000089406967, "step_time": 0.07330036163330078, "train_time": 0.06399752876975319, "train_loss": 5.175836086273193, "train_v_loss": 1.629289984703064, "train_policy_loss": 2.5538454055786133, "train_reward_loss": 0.18987371027469635, "train_chance_loss": 9.43319082580274e-06, "train_q_loss": 0.785834550857544, "train_vae_loss": 1.3168240684535704e-06, "train_lr": 0.0021271598525345325, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:55", "episode_count": 449, "remote_memory": 6977, "train_count": 6736, "episode_step": 8.0, "episode_time": 1.1143214702606201, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.7200000062584877, "step_time": 0.07374066114425659, "train_time": 0.06488826870918274, "train_loss": 5.337615013122559, "train_v_loss": 1.6929059028625488, "train_policy_loss": 2.5432348251342773, "train_reward_loss": 0.2643275558948517, "train_chance_loss": 1.0412288247607648e-05, "train_q_loss": 0.8201956748962402, "train_vae_loss": 1.314799419560586e-06, "train_lr": 0.0021225116215646267, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:57", "episode_count": 450, "remote_memory": 6988, "train_count": 6747, "episode_step": 11.0, "episode_time": 1.5284488201141357, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.6000000089406967, "step_time": 0.07298510724847967, "train_time": 0.0651190931146795, "train_loss": 5.3565263748168945, "train_v_loss": 1.7141051292419434, "train_policy_loss": 2.5631892681121826, "train_reward_loss": 0.2267373502254486, "train_chance_loss": 1.2693897588178515e-05, "train_q_loss": 0.8356636166572571, "train_vae_loss": 1.3127865940987249e-06, "train_lr": 0.0021178738679736853, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:13:58", "episode_count": 451, "remote_memory": 6995, "train_count": 6754, "episode_step": 7.0, "episode_time": 0.9611680507659912, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.760000005364418, "step_time": 0.07406578745160784, "train_time": 0.06260865075247628, "train_loss": 5.254676818847656, "train_v_loss": 1.6585255861282349, "train_policy_loss": 2.5559022426605225, "train_reward_loss": 0.23453448712825775, "train_chance_loss": 1.3130185834597796e-05, "train_q_loss": 0.788989245891571, "train_vae_loss": 1.3109017800161382e-06, "train_lr": 0.0021134892012923956, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:01", "episode_count": 452, "remote_memory": 7009, "train_count": 6768, "episode_step": 14.0, "episode_time": 1.953474521636963, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.5199999883770943, "step_time": 0.07311975955963135, "train_time": 0.06572129045213972, "train_loss": 5.240612030029297, "train_v_loss": 1.681508183479309, "train_policy_loss": 2.5301759243011475, "train_reward_loss": 0.19649121165275574, "train_chance_loss": 9.492648132436443e-06, "train_q_loss": 0.8157148361206055, "train_vae_loss": 1.3086755643598735e-06, "train_lr": 0.0021083862520754337, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:03", "episode_count": 453, "remote_memory": 7019, "train_count": 6778, "episode_step": 10.0, "episode_time": 1.4104657173156738, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.640000008046627, "step_time": 0.07336306571960449, "train_time": 0.06681866645812988, "train_loss": 5.182708740234375, "train_v_loss": 1.6561119556427002, "train_policy_loss": 2.539604425430298, "train_reward_loss": 0.17431604862213135, "train_chance_loss": 1.0141062375623733e-05, "train_q_loss": 0.795978844165802, "train_vae_loss": 1.3061322761132033e-06, "train_lr": 0.002102568047121167, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:05", "episode_count": 454, "remote_memory": 7033, "train_count": 6792, "episode_step": 14.0, "episode_time": 1.9051685333251953, "eval_reward0": 0.760000005364418, "episode_reward0": 0.48000001162290573, "step_time": 0.07325235434940883, "train_time": 0.062194381441388814, "train_loss": 5.167914867401123, "train_v_loss": 1.597302794456482, "train_policy_loss": 2.5610835552215576, "train_reward_loss": 0.2151075303554535, "train_chance_loss": 1.0188751730311196e-05, "train_q_loss": 0.777702271938324, "train_vae_loss": 1.3036215023021214e-06, "train_lr": 0.002096767071634531, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:07", "episode_count": 455, "remote_memory": 7042, "train_count": 6801, "episode_step": 9.0, "episode_time": 1.253793716430664, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.3199999928474426, "step_time": 0.07496301333109538, "train_time": 0.06385429700215657, "train_loss": 5.135028839111328, "train_v_loss": 1.5639989376068115, "train_policy_loss": 2.5633957386016846, "train_reward_loss": 0.21633873879909515, "train_chance_loss": 1.142929704656126e-05, "train_q_loss": 0.7746425867080688, "train_vae_loss": 1.3012532917855424e-06, "train_lr": 0.002091221744194627, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:08", "episode_count": 456, "remote_memory": 7049, "train_count": 6808, "episode_step": 7.0, "episode_time": 0.9915735721588135, "eval_reward0": 0.760000005364418, "episode_reward0": 0.760000005364418, "step_time": 0.07499384880065918, "train_time": 0.06592120443071638, "train_loss": 5.159168243408203, "train_v_loss": 1.6293672323226929, "train_policy_loss": 2.4830405712127686, "train_reward_loss": 0.25156038999557495, "train_chance_loss": 1.2655472346523311e-05, "train_q_loss": 0.7786389589309692, "train_vae_loss": 1.2995334373044898e-06, "train_lr": 0.0020873730536550283, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:11", "episode_count": 457, "remote_memory": 7069, "train_count": 6828, "episode_step": 20.0, "episode_time": 2.7961111068725586, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.24000001698732376, "step_time": 0.073745596408844, "train_time": 0.06541094779968262, "train_loss": 5.145510673522949, "train_v_loss": 1.6008892059326172, "train_policy_loss": 2.5431582927703857, "train_reward_loss": 0.20821264386177063, "train_chance_loss": 1.3872755516786128e-05, "train_q_loss": 0.7767437696456909, "train_vae_loss": 1.2967632301297272e-06, "train_lr": 0.0020808959379792213, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:14", "episode_count": 458, "remote_memory": 7076, "train_count": 6835, "episode_step": 7.0, "episode_time": 0.9890406131744385, "eval_reward0": 0.1600000187754631, "episode_reward0": 0.760000005364418, "step_time": 0.07477882930210658, "train_time": 0.06588574818202428, "train_loss": 5.40778112411499, "train_v_loss": 1.7508741617202759, "train_policy_loss": 2.5515644550323486, "train_reward_loss": 0.25061365962028503, "train_chance_loss": 9.772044904821087e-06, "train_q_loss": 0.8382291793823242, "train_vae_loss": 1.2939723319504992e-06, "train_lr": 0.0020744360517710447, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:17", "episode_count": 459, "remote_memory": 7093, "train_count": 6852, "episode_step": 17.0, "episode_time": 2.287571430206299, "eval_reward0": 0.7200000062584877, "episode_reward0": 0.36000001430511475, "step_time": 0.07199565102072324, "train_time": 0.061849299599142635, "train_loss": 5.243129730224609, "train_v_loss": 1.6685806512832642, "train_policy_loss": 2.5203630924224854, "train_reward_loss": 0.23369118571281433, "train_chance_loss": 1.2741943464789074e-05, "train_q_loss": 0.8040371537208557, "train_vae_loss": 1.2914900935356854e-06, "train_lr": 0.0020687133073806763, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:20", "episode_count": 460, "remote_memory": 7111, "train_count": 6870, "episode_step": 18.0, "episode_time": 2.509760618209839, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.3200000151991844, "step_time": 0.07336644331614177, "train_time": 0.06557006306118435, "train_loss": 5.344266414642334, "train_v_loss": 1.7130441665649414, "train_policy_loss": 2.569911241531372, "train_reward_loss": 0.220804825425148, "train_chance_loss": 1.264998263650341e-05, "train_q_loss": 0.8240657448768616, "train_vae_loss": 1.2878851975983707e-06, "train_lr": 0.00206039403565228, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:22", "episode_count": 461, "remote_memory": 7125, "train_count": 6884, "episode_step": 14.0, "episode_time": 1.9425876140594482, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.48000001162290573, "step_time": 0.07300831590379987, "train_time": 0.06507011822291783, "train_loss": 5.223938941955566, "train_v_loss": 1.6728079319000244, "train_policy_loss": 2.5275514125823975, "train_reward_loss": 0.1941985785961151, "train_chance_loss": 1.0760330951598007e-05, "train_q_loss": 0.8128727674484253, "train_vae_loss": 1.284651148125704e-06, "train_lr": 0.0020528167951852083, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:23", "episode_count": 462, "remote_memory": 7131, "train_count": 6890, "episode_step": 6.0, "episode_time": 0.8301169872283936, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07441786924997966, "train_time": 0.0632174015045166, "train_loss": 5.033718585968018, "train_v_loss": 1.5395088195800781, "train_policy_loss": 2.491950035095215, "train_reward_loss": 0.23436470329761505, "train_chance_loss": 9.276050150219817e-06, "train_q_loss": 0.7513445019721985, "train_vae_loss": 1.2825935300497804e-06, "train_lr": 0.0020480945240706205, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:25", "episode_count": 463, "remote_memory": 7137, "train_count": 6896, "episode_step": 6.0, "episode_time": 0.8239688873291016, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07275235652923584, "train_time": 0.06385922431945801, "train_loss": 5.1963958740234375, "train_v_loss": 1.6413511037826538, "train_policy_loss": 2.5447099208831787, "train_reward_loss": 0.1927497237920761, "train_chance_loss": 8.439082193945069e-06, "train_q_loss": 0.8010335564613342, "train_vae_loss": 1.2813447938242462e-06, "train_lr": 0.002045267028734088, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:26", "episode_count": 464, "remote_memory": 7144, "train_count": 6903, "episode_step": 7.0, "episode_time": 0.9987249374389648, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.07376994405473981, "train_time": 0.06817858559744698, "train_loss": 5.246551036834717, "train_v_loss": 1.6818746328353882, "train_policy_loss": 2.520872116088867, "train_reward_loss": 0.2299913614988327, "train_chance_loss": 8.993988558358978e-06, "train_q_loss": 0.7973057627677917, "train_vae_loss": 1.2800765034626238e-06, "train_lr": 0.002042208332568407, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:30", "episode_count": 465, "remote_memory": 7168, "train_count": 6927, "episode_step": 24.0, "episode_time": 3.395040273666382, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.08000002056360245, "step_time": 0.07485295335451762, "train_time": 0.06585439046223958, "train_loss": 5.192907810211182, "train_v_loss": 1.6495596170425415, "train_policy_loss": 2.5306503772735596, "train_reward_loss": 0.2036566585302353, "train_chance_loss": 1.0276925422658678e-05, "train_q_loss": 0.7925954461097717, "train_vae_loss": 1.2769072554874583e-06, "train_lr": 0.002034934936091304, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:34", "episode_count": 466, "remote_memory": 7187, "train_count": 6946, "episode_step": 19.0, "episode_time": 2.6204540729522705, "eval_reward0": 0.760000005364418, "episode_reward0": 0.2800000160932541, "step_time": 0.07291104919032047, "train_time": 0.06430546860945852, "train_loss": 5.290089130401611, "train_v_loss": 1.6866191625595093, "train_policy_loss": 2.5551464557647705, "train_reward_loss": 0.20899030566215515, "train_chance_loss": 9.57642805587966e-06, "train_q_loss": 0.8228518962860107, "train_vae_loss": 1.2725882925224141e-06, "train_lr": 0.002024884568527341, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:35", "episode_count": 467, "remote_memory": 7192, "train_count": 6951, "episode_step": 5.0, "episode_time": 0.6909501552581787, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.8400000035762787, "step_time": 0.0733269214630127, "train_time": 0.06401219367980956, "train_loss": 5.1124444007873535, "train_v_loss": 1.6081132888793945, "train_policy_loss": 2.4942784309387207, "train_reward_loss": 0.23481006920337677, "train_chance_loss": 1.1991081009909976e-05, "train_q_loss": 0.7588500380516052, "train_vae_loss": 1.2701850664598169e-06, "train_lr": 0.0020192961674183607, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:36", "episode_count": 468, "remote_memory": 7199, "train_count": 6958, "episode_step": 7.0, "episode_time": 0.960350513458252, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.760000005364418, "step_time": 0.07337229592459542, "train_time": 0.06320343698774065, "train_loss": 5.249228477478027, "train_v_loss": 1.6732702255249023, "train_policy_loss": 2.5746407508850098, "train_reward_loss": 0.20725037157535553, "train_chance_loss": 1.389549743180396e-05, "train_q_loss": 0.7776976227760315, "train_vae_loss": 1.2689685036093579e-06, "train_lr": 0.002016508486121893, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:39", "episode_count": 469, "remote_memory": 7213, "train_count": 6972, "episode_step": 14.0, "episode_time": 1.9400386810302734, "eval_reward0": 0.6000000089406967, "episode_reward0": 0.48000001162290573, "step_time": 0.07299486228397914, "train_time": 0.0649702889578683, "train_loss": 5.225853443145752, "train_v_loss": 1.6452693939208984, "train_policy_loss": 2.5597426891326904, "train_reward_loss": 0.2187500298023224, "train_chance_loss": 1.2960956155438907e-05, "train_q_loss": 0.7856834530830383, "train_vae_loss": 1.266873482563824e-06, "train_lr": 0.002011639531701803, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:41", "episode_count": 470, "remote_memory": 7222, "train_count": 6981, "episode_step": 9.0, "episode_time": 1.2540838718414307, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6800000071525574, "step_time": 0.07311744160122341, "train_time": 0.06516607602437337, "train_loss": 5.345692157745361, "train_v_loss": 1.7136157751083374, "train_policy_loss": 2.512176990509033, "train_reward_loss": 0.2544975280761719, "train_chance_loss": 1.4508097592624836e-05, "train_q_loss": 0.8489882349967957, "train_vae_loss": 1.2646002005567425e-06, "train_lr": 0.0020063193514943123, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:42", "episode_count": 471, "remote_memory": 7230, "train_count": 6989, "episode_step": 8.0, "episode_time": 1.1068170070648193, "eval_reward0": 0.7200000062584877, "episode_reward0": -1.2799999937415123, "step_time": 0.072241872549057, "train_time": 0.06550869345664978, "train_loss": 5.132879257202148, "train_v_loss": 1.5683064460754395, "train_policy_loss": 2.57968807220459, "train_reward_loss": 0.20231309533119202, "train_chance_loss": 1.1167592674610205e-05, "train_q_loss": 0.7662270069122314, "train_vae_loss": 1.2629014918275061e-06, "train_lr": 0.002002396620810032, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:44", "episode_count": 472, "remote_memory": 7236, "train_count": 6995, "episode_step": 6.0, "episode_time": 0.9147703647613525, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.0815574328104655, "train_time": 0.06997581322987874, "train_loss": 5.3692626953125, "train_v_loss": 1.7446317672729492, "train_policy_loss": 2.48526930809021, "train_reward_loss": 0.2870897948741913, "train_chance_loss": 9.695774679130409e-06, "train_q_loss": 0.8359666466712952, "train_vae_loss": 1.261509737560118e-06, "train_lr": 0.0019991714507341385, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:47", "episode_count": 473, "remote_memory": 7254, "train_count": 7013, "episode_step": 18.0, "episode_time": 2.7209155559539795, "eval_reward0": 0.8000000044703484, "episode_reward0": -1.6799999848008156, "step_time": 0.07405434714423285, "train_time": 0.07635162936316596, "train_loss": 5.248626708984375, "train_v_loss": 1.6706743240356445, "train_policy_loss": 2.556917190551758, "train_reward_loss": 0.1924823671579361, "train_chance_loss": 9.299226803705096e-06, "train_q_loss": 0.8122461438179016, "train_vae_loss": 1.259145278709184e-06, "train_lr": 0.0019936563912779093, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:49", "episode_count": 474, "remote_memory": 7263, "train_count": 7022, "episode_step": 9.0, "episode_time": 1.2269678115844727, "eval_reward0": 0.760000005364418, "episode_reward0": 0.6800000071525574, "step_time": 0.07274927033318414, "train_time": 0.0630394352806939, "train_loss": 5.21427059173584, "train_v_loss": 1.6384724378585815, "train_policy_loss": 2.545163869857788, "train_reward_loss": 0.21917051076889038, "train_chance_loss": 1.063705076376209e-05, "train_q_loss": 0.7950886487960815, "train_vae_loss": 1.256499331248051e-06, "train_lr": 0.0019874677527695894, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:50", "episode_count": 475, "remote_memory": 7271, "train_count": 7030, "episode_step": 8.0, "episode_time": 1.1086316108703613, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.7200000062584877, "step_time": 0.07450076937675476, "train_time": 0.06352972984313965, "train_loss": 5.28053092956543, "train_v_loss": 1.6998517513275146, "train_policy_loss": 2.4740753173828125, "train_reward_loss": 0.25079792737960815, "train_chance_loss": 1.2581371265696362e-05, "train_q_loss": 0.8394474983215332, "train_vae_loss": 1.2548231325126835e-06, "train_lr": 0.0019835815764963627, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:54", "episode_count": 476, "remote_memory": 7296, "train_count": 7055, "episode_step": 25.0, "episode_time": 3.4207098484039307, "eval_reward0": 0.760000005364418, "episode_reward0": 0.04000002145767212, "step_time": 0.07239190101623535, "train_time": 0.0637727451324463, "train_loss": 5.1874823570251465, "train_v_loss": 1.643763780593872, "train_policy_loss": 2.516836404800415, "train_reward_loss": 0.21674706041812897, "train_chance_loss": 1.284135851165047e-05, "train_q_loss": 0.7938997149467468, "train_vae_loss": 1.2515915841504466e-06, "train_lr": 0.0019760620780289173, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:55", "episode_count": 477, "remote_memory": 7301, "train_count": 7060, "episode_step": 5.0, "episode_time": 0.6905226707458496, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.8400000035762787, "step_time": 0.07431678771972657, "train_time": 0.06292624473571777, "train_loss": 5.393957138061523, "train_v_loss": 1.7196124792099, "train_policy_loss": 2.5828967094421387, "train_reward_loss": 0.24804869294166565, "train_chance_loss": 1.12251473183278e-05, "train_q_loss": 0.8272390365600586, "train_vae_loss": 1.2486590321714175e-06, "train_lr": 0.001969246193766594, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:57", "episode_count": 478, "remote_memory": 7307, "train_count": 7066, "episode_step": 6.0, "episode_time": 0.8379306793212891, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.8000000044703484, "step_time": 0.07508456707000732, "train_time": 0.06369821230570476, "train_loss": 5.363948345184326, "train_v_loss": 1.7361230850219727, "train_policy_loss": 2.503645896911621, "train_reward_loss": 0.2506850063800812, "train_chance_loss": 1.4167423614708241e-05, "train_q_loss": 0.8573444485664368, "train_vae_loss": 1.2475935591282905e-06, "train_lr": 0.001966753974556923, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:14:59", "episode_count": 479, "remote_memory": 7318, "train_count": 7077, "episode_step": 11.0, "episode_time": 1.5559298992156982, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.6000000089406967, "step_time": 0.07373332977294922, "train_time": 0.06690467487681996, "train_loss": 5.2020745277404785, "train_v_loss": 1.6218056678771973, "train_policy_loss": 2.5661935806274414, "train_reward_loss": 0.21700306236743927, "train_chance_loss": 1.1319570148771163e-05, "train_q_loss": 0.7809376120567322, "train_vae_loss": 1.2459466915970552e-06, "train_lr": 0.0019629087764769793, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:02", "episode_count": 480, "remote_memory": 7333, "train_count": 7092, "episode_step": 15.0, "episode_time": 2.0664193630218506, "eval_reward0": 0.5200000107288361, "episode_reward0": 0.4400000125169754, "step_time": 0.07280116081237793, "train_time": 0.0643175443013509, "train_loss": 5.2516188621521, "train_v_loss": 1.6616625785827637, "train_policy_loss": 2.5446829795837402, "train_reward_loss": 0.22009041905403137, "train_chance_loss": 8.721220183360856e-06, "train_q_loss": 0.8090044856071472, "train_vae_loss": 1.2434468317223946e-06, "train_lr": 0.0019570423755794764, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:05", "episode_count": 481, "remote_memory": 7353, "train_count": 7112, "episode_step": 20.0, "episode_time": 2.7958550453186035, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.24000001698732376, "step_time": 0.0736240029335022, "train_time": 0.06544866561889648, "train_loss": 5.228602409362793, "train_v_loss": 1.6730263233184814, "train_policy_loss": 2.5268337726593018, "train_reward_loss": 0.20844683051109314, "train_chance_loss": 8.182292731362395e-06, "train_q_loss": 0.8040984272956848, "train_vae_loss": 1.2400540754242684e-06, "train_lr": 0.001949173049069941, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:09", "episode_count": 482, "remote_memory": 7370, "train_count": 7129, "episode_step": 17.0, "episode_time": 2.398747205734253, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.36000001430511475, "step_time": 0.0735938689287971, "train_time": 0.06670776535482968, "train_loss": 5.405938625335693, "train_v_loss": 1.741939663887024, "train_policy_loss": 2.5504355430603027, "train_reward_loss": 0.2531135082244873, "train_chance_loss": 1.0381829270045273e-05, "train_q_loss": 0.8442776203155518, "train_vae_loss": 1.2365341035547317e-06, "train_lr": 0.001940887188538909, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:11", "episode_count": 483, "remote_memory": 7380, "train_count": 7139, "episode_step": 10.0, "episode_time": 1.4478797912597656, "eval_reward0": 0.760000005364418, "episode_reward0": 0.640000008046627, "step_time": 0.07679359912872315, "train_time": 0.0671184778213501, "train_loss": 5.292946815490723, "train_v_loss": 1.68361496925354, "train_policy_loss": 2.5707993507385254, "train_reward_loss": 0.20187091827392578, "train_chance_loss": 1.2559581591631286e-05, "train_q_loss": 0.8205550909042358, "train_vae_loss": 1.2339372688074945e-06, "train_lr": 0.0019348623463883996, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:12", "episode_count": 484, "remote_memory": 7386, "train_count": 7145, "episode_step": 6.0, "episode_time": 0.8288521766662598, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07354875405629475, "train_time": 0.0638349453608195, "train_loss": 5.428595066070557, "train_v_loss": 1.7470240592956543, "train_policy_loss": 2.5846221446990967, "train_reward_loss": 0.23378993570804596, "train_chance_loss": 1.4655473933089525e-05, "train_q_loss": 0.8470490574836731, "train_vae_loss": 1.2323981763984193e-06, "train_lr": 0.0019313013181090355, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:13", "episode_count": 485, "remote_memory": 7394, "train_count": 7153, "episode_step": 8.0, "episode_time": 1.129586935043335, "eval_reward0": 0.760000005364418, "episode_reward0": -1.2799999937415123, "step_time": 0.07308799028396606, "train_time": 0.06751009821891785, "train_loss": 5.215054988861084, "train_v_loss": 1.644049882888794, "train_policy_loss": 2.5493969917297363, "train_reward_loss": 0.215226411819458, "train_chance_loss": 1.5657604308216833e-05, "train_q_loss": 0.7902594804763794, "train_vae_loss": 1.2310954389249673e-06, "train_lr": 0.0019281910499557853, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:14", "episode_count": 486, "remote_memory": 7400, "train_count": 7159, "episode_step": 6.0, "episode_time": 0.9252510070800781, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07446467876434326, "train_time": 0.0789112647374471, "train_loss": 5.1881422996521, "train_v_loss": 1.6280728578567505, "train_policy_loss": 2.548454523086548, "train_reward_loss": 0.20847052335739136, "train_chance_loss": 1.2096141290385276e-05, "train_q_loss": 0.787009060382843, "train_vae_loss": 1.229769964083971e-06, "train_lr": 0.00192508555483073, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:18", "episode_count": 487, "remote_memory": 7422, "train_count": 7181, "episode_step": 22.0, "episode_time": 2.96945858001709, "eval_reward0": 0.6800000071525574, "episode_reward0": -1.839999981224537, "step_time": 0.07202590595592152, "train_time": 0.06235455382953991, "train_loss": 5.262779712677002, "train_v_loss": 1.6731849908828735, "train_policy_loss": 2.53952956199646, "train_reward_loss": 0.2286980152130127, "train_chance_loss": 9.998424502555281e-06, "train_q_loss": 0.8052383065223694, "train_vae_loss": 1.2271112836970133e-06, "train_lr": 0.001918891561217606, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:19", "episode_count": 488, "remote_memory": 7429, "train_count": 7188, "episode_step": 7.0, "episode_time": 0.9847195148468018, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.760000005364418, "step_time": 0.074148348399571, "train_time": 0.06592355455671038, "train_loss": 5.378269672393799, "train_v_loss": 1.763546347618103, "train_policy_loss": 2.5345263481140137, "train_reward_loss": 0.2107945829629898, "train_chance_loss": 1.055650591297308e-05, "train_q_loss": 0.8532881736755371, "train_vae_loss": 1.2244245226611383e-06, "train_lr": 0.001912493840791285, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:22", "episode_count": 489, "remote_memory": 7438, "train_count": 7197, "episode_step": 9.0, "episode_time": 1.3010389804840088, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6800000071525574, "step_time": 0.07745382520887586, "train_time": 0.06603474087185329, "train_loss": 5.344102382659912, "train_v_loss": 1.6765140295028687, "train_policy_loss": 2.563793182373047, "train_reward_loss": 0.2841404676437378, "train_chance_loss": 1.047064688464161e-05, "train_q_loss": 0.8036081194877625, "train_vae_loss": 1.2228856576257385e-06, "train_lr": 0.0019089742563664913, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:23", "episode_count": 490, "remote_memory": 7448, "train_count": 7207, "episode_step": 10.0, "episode_time": 1.3768446445465088, "eval_reward0": 0.760000005364418, "episode_reward0": 0.640000008046627, "step_time": 0.07312598228454589, "train_time": 0.06408746242523193, "train_loss": 5.187386512756348, "train_v_loss": 1.6336513757705688, "train_policy_loss": 2.497457981109619, "train_reward_loss": 0.23511235415935516, "train_chance_loss": 1.0381738320575096e-05, "train_q_loss": 0.8051937818527222, "train_vae_loss": 1.221090997205465e-06, "train_lr": 0.0019048030953854322, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:26", "episode_count": 491, "remote_memory": 7466, "train_count": 7225, "episode_step": 18.0, "episode_time": 2.490626811981201, "eval_reward0": 0.48000001162290573, "episode_reward0": 0.3200000151991844, "step_time": 0.07471304469638401, "train_time": 0.0629146761364407, "train_loss": 5.172791004180908, "train_v_loss": 1.6156926155090332, "train_policy_loss": 2.518604278564453, "train_reward_loss": 0.23030278086662292, "train_chance_loss": 1.0989711881848052e-05, "train_q_loss": 0.7922284603118896, "train_vae_loss": 1.2184972320028464e-06, "train_lr": 0.0018986737122759223, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:29", "episode_count": 492, "remote_memory": 7478, "train_count": 7237, "episode_step": 12.0, "episode_time": 1.6068129539489746, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.5600000098347664, "step_time": 0.07222930590311687, "train_time": 0.06099909543991089, "train_loss": 5.232870578765869, "train_v_loss": 1.6290045976638794, "train_policy_loss": 2.553797960281372, "train_reward_loss": 0.2480052262544632, "train_chance_loss": 1.2171894013590645e-05, "train_q_loss": 0.7859777808189392, "train_vae_loss": 1.2156721140854643e-06, "train_lr": 0.0018921265145763755, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:30", "episode_count": 493, "remote_memory": 7486, "train_count": 7245, "episode_step": 8.0, "episode_time": 1.0982310771942139, "eval_reward0": 0.760000005364418, "episode_reward0": 0.7200000062584877, "step_time": 0.07242709398269653, "train_time": 0.06432011723518372, "train_loss": 5.301578998565674, "train_v_loss": 1.7374544143676758, "train_policy_loss": 2.520071268081665, "train_reward_loss": 0.19623664021492004, "train_chance_loss": 1.4536264643538743e-05, "train_q_loss": 0.8316730856895447, "train_vae_loss": 1.2138450529164402e-06, "train_lr": 0.0018877743277698755, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:33", "episode_count": 494, "remote_memory": 7499, "train_count": 7258, "episode_step": 13.0, "episode_time": 1.8116374015808105, "eval_reward0": 0.6800000071525574, "episode_reward0": 0.5200000107288361, "step_time": 0.07140262310321514, "train_time": 0.06732474840604342, "train_loss": 5.115894794464111, "train_v_loss": 1.6307698488235474, "train_policy_loss": 2.479863166809082, "train_reward_loss": 0.19013531506061554, "train_chance_loss": 1.1797253137046937e-05, "train_q_loss": 0.7989643812179565, "train_vae_loss": 1.21190453228337e-06, "train_lr": 0.001883216085843742, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:35", "episode_count": 495, "remote_memory": 7509, "train_count": 7268, "episode_step": 10.0, "episode_time": 1.3762767314910889, "eval_reward0": 0.8000000044703484, "episode_reward0": 0.640000008046627, "step_time": 0.07261548042297364, "train_time": 0.06412804126739502, "train_loss": 5.334641456604004, "train_v_loss": 1.678013563156128, "train_policy_loss": 2.5811524391174316, "train_reward_loss": 0.25025758147239685, "train_chance_loss": 1.0913715414062608e-05, "train_q_loss": 0.8090990781784058, "train_vae_loss": 1.2097779062969494e-06, "train_lr": 0.0018782358383759856, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:37", "episode_count": 496, "remote_memory": 7525, "train_count": 7284, "episode_step": 16.0, "episode_time": 2.1542305946350098, "eval_reward0": 0.640000008046627, "episode_reward0": 0.4000000134110451, "step_time": 0.07166719436645508, "train_time": 0.06236937642097473, "train_loss": 5.375317573547363, "train_v_loss": 1.7503085136413574, "train_policy_loss": 2.5330758094787598, "train_reward_loss": 0.2286975383758545, "train_chance_loss": 9.920073352986947e-06, "train_q_loss": 0.8471900820732117, "train_vae_loss": 1.207389004775905e-06, "train_lr": 0.0018726226408034563, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:39", "episode_count": 497, "remote_memory": 7531, "train_count": 7290, "episode_step": 6.0, "episode_time": 0.9927716255187988, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.8000000044703484, "step_time": 0.07360323270161946, "train_time": 0.09108249346415202, "train_loss": 5.333527088165283, "train_v_loss": 1.7285727262496948, "train_policy_loss": 2.53705096244812, "train_reward_loss": 0.20644117891788483, "train_chance_loss": 9.032664820551872e-06, "train_q_loss": 0.8454949259757996, "train_vae_loss": 1.2053636737618945e-06, "train_lr": 0.0018678844207897782, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:43", "episode_count": 498, "remote_memory": 7556, "train_count": 7315, "episode_step": 25.0, "episode_time": 3.3631174564361572, "eval_reward0": 0.4000000134110451, "episode_reward0": 0.04000002145767212, "step_time": 0.07149067878723145, "train_time": 0.06236160278320312, "train_loss": 5.256306171417236, "train_v_loss": 1.6585512161254883, "train_policy_loss": 2.5693962574005127, "train_reward_loss": 0.20611049234867096, "train_chance_loss": 9.923962352331728e-06, "train_q_loss": 0.8062509298324585, "train_vae_loss": 1.202541966449644e-06, "train_lr": 0.0018612322164699435, "work0_v_min": -1.0, "work0_v_max": 1.0}
{"date": "2022/11/10 03:15:45", "episode_count": 499, "remote_memory": 7567, "train_count": 7326, "episode_step": 11.0, "episode_time": 1.4796595573425293, "eval_reward0": 0.8400000035762787, "episode_reward0": 0.6000000089406967, "step_time": 0.07135397737676447, "train_time": 0.06241765889254483, "train_loss": 5.224576950073242, "train_v_loss": 1.6637314558029175, "train_policy_loss": 2.502871513366699, "train_reward_loss": 0.23596587777137756, "train_chance_loss": 1.2785319086106028e-05, "train_q_loss": 0.8061200976371765, "train_vae_loss": 1.1992582358288928e-06, "train_lr": 0.0018535320414230227, "work0_v_min": -1.0, "work0_v_max": 1.0}
